{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bbd76d4335234228aa6501b2664c2cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29b9af5c15754ab68b41f24151a5c372",
              "IPY_MODEL_e34fb111f61f44b894180d12582ff6c4",
              "IPY_MODEL_0f6ae85543de4e309e15ee68f6dcf969"
            ],
            "layout": "IPY_MODEL_3a296a5dc6a34e87ab6055de2af324cb"
          }
        },
        "29b9af5c15754ab68b41f24151a5c372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38bdb102e8eb413fb22f821e369ef05d",
            "placeholder": "​",
            "style": "IPY_MODEL_52f1cd0992a447e38c5c5d62dbb28d30",
            "value": "Downloading data: 100%"
          }
        },
        "e34fb111f61f44b894180d12582ff6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85b9d1ebf8fc494185b918635b446b83",
            "max": 22616233652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72328cb445f740aa81d34984f1ba9690",
            "value": 22616233652
          }
        },
        "0f6ae85543de4e309e15ee68f6dcf969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a34a220eb1a44d7fbaf99f875c73d2ed",
            "placeholder": "​",
            "style": "IPY_MODEL_8b84ccc17ebe40efb9f8835aa79a75fa",
            "value": " 22.6G/22.6G [06:48&lt;00:00, 60.9MB/s]"
          }
        },
        "3a296a5dc6a34e87ab6055de2af324cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38bdb102e8eb413fb22f821e369ef05d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52f1cd0992a447e38c5c5d62dbb28d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85b9d1ebf8fc494185b918635b446b83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72328cb445f740aa81d34984f1ba9690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a34a220eb1a44d7fbaf99f875c73d2ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b84ccc17ebe40efb9f8835aa79a75fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62df3bd4341a417fa77ddf76656fd690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea679773020a42808bedca707a57d61a",
              "IPY_MODEL_7a7f22fcb216439787e568c40a8b7f12",
              "IPY_MODEL_03bd040823db42cb886a038a7351362a"
            ],
            "layout": "IPY_MODEL_b0c244559e264b278455caee09b10adc"
          }
        },
        "ea679773020a42808bedca707a57d61a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b605936e6512453ca6fb644a4362e9b8",
            "placeholder": "​",
            "style": "IPY_MODEL_095ef2777521425fae4b817645864514",
            "value": "Generating full split: "
          }
        },
        "7a7f22fcb216439787e568c40a8b7f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_910586bf22df4153aa28367d30220213",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52f9814bf63145ed866fb36c192de3b2",
            "value": 1
          }
        },
        "03bd040823db42cb886a038a7351362a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b3848be5bf04fa3999c6ab20d4329dd",
            "placeholder": "​",
            "style": "IPY_MODEL_f881013f43d141bba183d4d8c228be00",
            "value": " 43886944/0 [15:46&lt;00:00, 61437.88 examples/s]"
          }
        },
        "b0c244559e264b278455caee09b10adc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b605936e6512453ca6fb644a4362e9b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "095ef2777521425fae4b817645864514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "910586bf22df4153aa28367d30220213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "52f9814bf63145ed866fb36c192de3b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b3848be5bf04fa3999c6ab20d4329dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f881013f43d141bba183d4d8c228be00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e2ddf587387451dbed8a5bd181e0a8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecabb2a55a4d4715bd3ac391801b30ed",
              "IPY_MODEL_bcaaa43c724e4493bef7a3d61ef59b6b",
              "IPY_MODEL_19804a00b76044cca3268196d10e3fb4"
            ],
            "layout": "IPY_MODEL_1ae8c7f8fea7499b9533c9773e698a2d"
          }
        },
        "ecabb2a55a4d4715bd3ac391801b30ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52bb7c02b4894a7a94075fc245d3747d",
            "placeholder": "​",
            "style": "IPY_MODEL_4fb850eaf44548af8315aa8a6dd9f3c3",
            "value": "Downloading data: 100%"
          }
        },
        "bcaaa43c724e4493bef7a3d61ef59b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8691bf5eb2244d798d479c71083e9e08",
            "max": 326611506,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e80088514a1e41609e79e5d0ac6cbd24",
            "value": 326611506
          }
        },
        "19804a00b76044cca3268196d10e3fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82ed001ea0ea4302946f6da13a6303de",
            "placeholder": "​",
            "style": "IPY_MODEL_f696bf41992f45e287d1f290fa413e2f",
            "value": " 327M/327M [00:05&lt;00:00, 46.3MB/s]"
          }
        },
        "1ae8c7f8fea7499b9533c9773e698a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52bb7c02b4894a7a94075fc245d3747d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb850eaf44548af8315aa8a6dd9f3c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8691bf5eb2244d798d479c71083e9e08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e80088514a1e41609e79e5d0ac6cbd24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82ed001ea0ea4302946f6da13a6303de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f696bf41992f45e287d1f290fa413e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7b3f3aa2e0640958e38afa2a442b499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05c885c1db5148b0a2856ef66c7daee3",
              "IPY_MODEL_79d36e476b3a45c5a4d8795be6545e35",
              "IPY_MODEL_b2889cbba23f4599aa65e89ac3da2c20"
            ],
            "layout": "IPY_MODEL_f78ad141c1ec457eb07a0ae8ee0eb4a5"
          }
        },
        "05c885c1db5148b0a2856ef66c7daee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63a632d0754149618a67c5f1915d6cbc",
            "placeholder": "​",
            "style": "IPY_MODEL_fafa924eec8842059a4edc72beb092b8",
            "value": "Generating full split: "
          }
        },
        "79d36e476b3a45c5a4d8795be6545e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3201b8387b84959a501c7b97cbe0073",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f43faa5be421415b8b3e2cc03166d9dd",
            "value": 1
          }
        },
        "b2889cbba23f4599aa65e89ac3da2c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfaeac3d8f76452aa80dfa9646941072",
            "placeholder": "​",
            "style": "IPY_MODEL_8f6c20720dc24b7d9371e93253f6e7d4",
            "value": " 701528/0 [00:14&lt;00:00, 39459.33 examples/s]"
          }
        },
        "f78ad141c1ec457eb07a0ae8ee0eb4a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63a632d0754149618a67c5f1915d6cbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fafa924eec8842059a4edc72beb092b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3201b8387b84959a501c7b97cbe0073": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f43faa5be421415b8b3e2cc03166d9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfaeac3d8f76452aa80dfa9646941072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f6c20720dc24b7d9371e93253f6e7d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1e548e5060d485dae21d1ae8ca6bb43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8791771770bc4d72a4353d0516160d52",
              "IPY_MODEL_41780eb4b3164ff2ae34787eb8157bd1",
              "IPY_MODEL_6194e4eaca96453a8ea1f754b14968d4"
            ],
            "layout": "IPY_MODEL_1531e22563c444978063f416ceb2d800"
          }
        },
        "8791771770bc4d72a4353d0516160d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f3f12dcc2e34f189c881f776c8537ea",
            "placeholder": "​",
            "style": "IPY_MODEL_147312915fcf43edbc50757c491ea60f",
            "value": "Downloading readme: 100%"
          }
        },
        "41780eb4b3164ff2ae34787eb8157bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4466658d88d340ceb1366c5c45ff9d36",
            "max": 734,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_180fabc72825457d9dca3c92136b1a99",
            "value": 734
          }
        },
        "6194e4eaca96453a8ea1f754b14968d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_812036b7ef2548b8a5df9748697fe544",
            "placeholder": "​",
            "style": "IPY_MODEL_56a43818738e4ea391fd729ff7f59ae7",
            "value": " 734/734 [00:00&lt;00:00, 52.6kB/s]"
          }
        },
        "1531e22563c444978063f416ceb2d800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f3f12dcc2e34f189c881f776c8537ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "147312915fcf43edbc50757c491ea60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4466658d88d340ceb1366c5c45ff9d36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "180fabc72825457d9dca3c92136b1a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "812036b7ef2548b8a5df9748697fe544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a43818738e4ea391fd729ff7f59ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# A/B TESTING FRAMEWORK\n",
        "## Advanced statistical methods for A/B testing\n",
        "\n",
        "### Author: Peter Chika ozo-ogueji"
      ],
      "metadata": {
        "id": "jKQKQOHhpKv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Web Analytics & Optimization Project - Dataset Downloader\n",
        "# For Google Colab Environment - REAL DATASETS ONLY\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import requests\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1: SETUP KAGGLE API IN GOOGLE COLAB\n",
        "# =============================================================================\n",
        "\n",
        "def setup_kaggle_api():\n",
        "    \"\"\"Setup Kaggle API credentials in Google Colab\"\"\"\n",
        "\n",
        "    # Your Kaggle credentials\n",
        "    kaggle_credentials = {\n",
        "        \"username\": \"peterchikaozoogueji\",\n",
        "        \"key\": \"f2b5ae97165cf3eef611db7624db7192\"\n",
        "    }\n",
        "\n",
        "    # Create .kaggle directory\n",
        "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "\n",
        "    # Write credentials to kaggle.json\n",
        "    with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
        "        json.dump(kaggle_credentials, f)\n",
        "\n",
        "    # Set proper permissions\n",
        "    os.chmod('/root/.kaggle/kaggle.json', 0o600)\n",
        "\n",
        "    print(\"✅ Kaggle API credentials setup complete!\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: INSTALL REQUIRED PACKAGES\n",
        "# =============================================================================\n",
        "\n",
        "def install_packages():\n",
        "    \"\"\"Install required packages for the project\"\"\"\n",
        "    packages = [\n",
        "        'kaggle',\n",
        "        'plotly',\n",
        "        'streamlit',\n",
        "        'scipy',\n",
        "        'scikit-learn',\n",
        "        'seaborn',\n",
        "        'openpyxl',  # For Excel file support\n",
        "        'datasets',  # For Hugging Face datasets\n",
        "        'timeout-decorator'  # For handling timeouts\n",
        "    ]\n",
        "\n",
        "    for package in packages:\n",
        "        os.system(f'pip install {package}')\n",
        "\n",
        "    print(\"✅ All packages installed!\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: DEFINE WORKING DATASETS (VERIFIED REAL DATASETS)\n",
        "# =============================================================================\n",
        "\n",
        "# Primary datasets that work\n",
        "WORKING_DATASETS = {\n",
        "    # E-commerce Transaction Data (VERIFIED WORKING)\n",
        "    'olist_ecommerce': 'olistbr/brazilian-ecommerce',\n",
        "    'online_retail': 'lakshmi25npathi/online-retail-dataset',\n",
        "\n",
        "    # A/B Testing Data (VERIFIED WORKING)\n",
        "    'ab_testing': 'amirmotefaker/ab-testing-dataset',\n",
        "    'cookie_cats': 'yufengsui/mobile-games-ab-testing',\n",
        "\n",
        "    # Marketing & Campaign Data (VERIFIED WORKING)\n",
        "    'marketing_campaign': 'rodsaldanha/arketing-campaign',\n",
        "    'customer_personality': 'imakash3011/customer-personality-analysis',\n",
        "\n",
        "    # Product Data (VERIFIED WORKING)\n",
        "    'amazon_products': 'asaniczka/amazon-products-dataset-2023-1-4m-products',\n",
        "    'ecommerce_behavior': 'mkechinov/ecommerce-behavior-data-from-multi-category-store',\n",
        "\n",
        "    # Retail Analytics (VERIFIED WORKING)\n",
        "    'retail_analytics': 'manjeetsingh/retaildataset'\n",
        "}\n",
        "\n",
        "# High-quality replacement datasets for problematic ones (VERIFIED WORKING)\n",
        "REPLACEMENT_DATASETS = {\n",
        "    # Web Analytics & Session Data Replacements (WORKING)\n",
        "    'digital_ads_real': 'loveall/clicks-conversion-tracking',\n",
        "    'ecommerce_events': 'mkechinov/ecommerce-events-history-in-cosmetics-shop',\n",
        "\n",
        "    # Additional Working Datasets\n",
        "    'ecommerce_sales': 'carrie1/ecommerce-data',\n",
        "    'online_sales': 'mohammadtalib786/retail-sales-dataset',\n",
        "    'customer_shopping': 'mehmettahiraslan/customer-shopping-dataset',\n",
        "    'web_classification': 'ruchi798/website-classification',\n",
        "    'facebook_ads': 'madislemsalu/facebook-ad-campaign-dataset',\n",
        "    'advertising_data': 'sazid28/advertising-dataset',\n",
        "    'retail_sales': 'ankitbansal06/retail-orders',\n",
        "    'user_behavior': 'henrysue/e-commerce-user-behavior-dataset',\n",
        "    'shopping_trends': 'iamsouravbanerjee/customer-shopping-trends-dataset'\n",
        "}\n",
        "\n",
        "# GitHub datasets (direct download) - WORKING URLS\n",
        "GITHUB_DATASETS = {\n",
        "    'ecommerce_github': 'https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/Ecdat/Clothing.csv',\n",
        "    'retail_transactions': 'https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/Ecdat/Fair.csv',\n",
        "    'consumer_data': 'https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/Ecdat/BudgetFood.csv'\n",
        "}\n",
        "\n",
        "# Hugging Face datasets (using datasets library)\n",
        "HUGGINGFACE_DATASETS = {\n",
        "    'ecommerce_hf': 'ecommerce_behavior',\n",
        "    'retail_hf': 'retail_rocket',\n",
        "    'web_analytics_hf': 'web_clicks'\n",
        "}\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: DOWNLOAD FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def download_kaggle_dataset(dataset_name, dataset_path, folder_name):\n",
        "    \"\"\"Download a specific Kaggle dataset\"\"\"\n",
        "    try:\n",
        "        print(f\"📥 Downloading {dataset_name}...\")\n",
        "\n",
        "        # Create directory for dataset\n",
        "        os.makedirs(f'/content/datasets/{folder_name}', exist_ok=True)\n",
        "\n",
        "        # Download dataset\n",
        "        os.system(f'kaggle datasets download -d {dataset_path} -p /content/datasets/{folder_name}')\n",
        "\n",
        "        # Extract if zip file exists\n",
        "        zip_files = list(Path(f'/content/datasets/{folder_name}').glob('*.zip'))\n",
        "        for zip_file in zip_files:\n",
        "            with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "                zip_ref.extractall(f'/content/datasets/{folder_name}')\n",
        "            # Remove zip file after extraction\n",
        "            os.remove(zip_file)\n",
        "\n",
        "        print(f\"✅ {dataset_name} downloaded successfully!\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to download {dataset_name}: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def download_github_dataset(dataset_name, url, filename):\n",
        "    \"\"\"Download dataset directly from GitHub\"\"\"\n",
        "    try:\n",
        "        print(f\"📥 Downloading {dataset_name} from GitHub...\")\n",
        "\n",
        "        os.makedirs(f'/content/datasets/{dataset_name}', exist_ok=True)\n",
        "\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        file_path = f'/content/datasets/{dataset_name}/{filename}'\n",
        "        with open(file_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "\n",
        "        print(f\"✅ {dataset_name} downloaded from GitHub!\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to download {dataset_name} from GitHub: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def download_all_working_datasets():\n",
        "    \"\"\"Download all verified working datasets\"\"\"\n",
        "    print(\"🚀 Starting download of WORKING datasets...\\n\")\n",
        "\n",
        "    success_count = 0\n",
        "    total_datasets = len(WORKING_DATASETS)\n",
        "\n",
        "    for dataset_name, dataset_path in WORKING_DATASETS.items():\n",
        "        success = download_kaggle_dataset(dataset_name, dataset_path, dataset_name)\n",
        "        if success:\n",
        "            success_count += 1\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    print(f\"\\n📊 Working Datasets Summary: {success_count}/{total_datasets} downloaded successfully\")\n",
        "    return success_count\n",
        "\n",
        "def download_replacement_datasets():\n",
        "    \"\"\"Download high-quality replacement datasets\"\"\"\n",
        "    print(\"\\n🔄 Downloading replacement datasets for better web analytics...\\n\")\n",
        "\n",
        "    success_count = 0\n",
        "    total_datasets = len(REPLACEMENT_DATASETS)\n",
        "\n",
        "    for dataset_name, dataset_path in REPLACEMENT_DATASETS.items():\n",
        "        success = download_kaggle_dataset(dataset_name, dataset_path, dataset_name)\n",
        "        if success:\n",
        "            success_count += 1\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "    print(f\"\\n📊 Replacement Datasets Summary: {success_count}/{total_datasets} downloaded successfully\")\n",
        "    return success_count\n",
        "\n",
        "def download_github_datasets():\n",
        "    \"\"\"Download datasets from GitHub\"\"\"\n",
        "    print(\"\\n🐙 Downloading datasets from GitHub...\\n\")\n",
        "\n",
        "    success_count = 0\n",
        "\n",
        "    # Download clothing data (already working)\n",
        "    if download_github_dataset('clothing_github',\n",
        "                             'https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/Ecdat/Clothing.csv',\n",
        "                             'clothing_data.csv'):\n",
        "        success_count += 1\n",
        "\n",
        "    # Download Fair dataset (economics/consumer behavior)\n",
        "    if download_github_dataset('consumer_github',\n",
        "                             'https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/Ecdat/Fair.csv',\n",
        "                             'consumer_data.csv'):\n",
        "        success_count += 1\n",
        "\n",
        "    # Download BudgetFood dataset (consumer spending)\n",
        "    if download_github_dataset('budget_github',\n",
        "                             'https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/Ecdat/BudgetFood.csv',\n",
        "                             'budget_data.csv'):\n",
        "        success_count += 1\n",
        "\n",
        "    print(f\"\\n📊 GitHub Datasets Summary: {success_count} downloaded successfully\")\n",
        "    return success_count\n",
        "\n",
        "def download_huggingface_dataset(dataset_name, hf_dataset_id):\n",
        "    \"\"\"Download dataset from Hugging Face\"\"\"\n",
        "    try:\n",
        "        print(f\"🤗 Downloading {dataset_name} from Hugging Face...\")\n",
        "\n",
        "        from datasets import load_dataset\n",
        "\n",
        "        # Load dataset\n",
        "        dataset = load_dataset(hf_dataset_id, split='train')\n",
        "\n",
        "        # Convert to pandas DataFrame\n",
        "        df = dataset.to_pandas()\n",
        "\n",
        "        # Create directory and save\n",
        "        os.makedirs(f'/content/datasets/{dataset_name}', exist_ok=True)\n",
        "        df.to_csv(f'/content/datasets/{dataset_name}/{dataset_name}.csv', index=False)\n",
        "\n",
        "        print(f\"✅ {dataset_name} downloaded from Hugging Face: {df.shape}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to download {dataset_name} from Hugging Face: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def download_huggingface_datasets():\n",
        "    \"\"\"Download datasets from Hugging Face\"\"\"\n",
        "    print(\"\\n🤗 Downloading datasets from Hugging Face...\\n\")\n",
        "\n",
        "    success_count = 0\n",
        "\n",
        "    # Try to download some public datasets with proper configs\n",
        "    hf_datasets = [\n",
        "        ('amazon_electronics', 'McAuley-Lab/Amazon-Reviews-2023', 'raw_review_Electronics'),\n",
        "        ('amazon_beauty', 'McAuley-Lab/Amazon-Reviews-2023', 'raw_review_All_Beauty'),\n",
        "        ('web_nlp', 'SetFit/20_newsgroups', 'default')\n",
        "    ]\n",
        "\n",
        "    for dataset_name, hf_id, config in hf_datasets:\n",
        "        try:\n",
        "            if download_huggingface_dataset_with_config(dataset_name, hf_id, config):\n",
        "                success_count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"❌ {dataset_name} failed: {str(e)}\")\n",
        "\n",
        "    print(f\"\\n📊 Hugging Face Datasets Summary: {success_count} downloaded successfully\")\n",
        "    return success_count\n",
        "\n",
        "def download_huggingface_dataset_with_config(dataset_name, hf_dataset_id, config):\n",
        "    \"\"\"Download dataset from Hugging Face with specific config\"\"\"\n",
        "    try:\n",
        "        print(f\"🤗 Downloading {dataset_name} from Hugging Face...\")\n",
        "\n",
        "        from datasets import load_dataset\n",
        "\n",
        "        # Load dataset with specific config\n",
        "        dataset = load_dataset(hf_dataset_id, config, split='train', streaming=False)\n",
        "\n",
        "        # Convert to pandas DataFrame (limit rows for memory)\n",
        "        df = dataset.to_pandas()\n",
        "        if len(df) > 10000:\n",
        "            df = df.head(10000)  # Limit to 10k rows\n",
        "\n",
        "        # Create directory and save\n",
        "        os.makedirs(f'/content/datasets/{dataset_name}', exist_ok=True)\n",
        "        df.to_csv(f'/content/datasets/{dataset_name}/{dataset_name}.csv', index=False)\n",
        "\n",
        "        print(f\"✅ {dataset_name} downloaded from Hugging Face: {df.shape}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to download {dataset_name} from Hugging Face: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5: SMART CSV READING WITH DELIMITER DETECTION\n",
        "# =============================================================================\n",
        "\n",
        "def smart_read_csv(file_path, nrows=1000):\n",
        "    \"\"\"Intelligently read CSV files with different delimiters\"\"\"\n",
        "    try:\n",
        "        # First, peek at the first few lines to detect delimiter\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            first_line = f.readline()\n",
        "            second_line = f.readline()\n",
        "\n",
        "        # Count potential delimiters in first lines\n",
        "        delimiters = [',', ';', '\\t', '|']\n",
        "        delimiter_counts = {}\n",
        "\n",
        "        for delim in delimiters:\n",
        "            count1 = first_line.count(delim)\n",
        "            count2 = second_line.count(delim) if second_line else 0\n",
        "            # Use delimiter if it appears consistently and more than 0 times\n",
        "            if count1 > 0 and count1 == count2:\n",
        "                delimiter_counts[delim] = count1\n",
        "\n",
        "        # Choose delimiter with highest count, default to comma\n",
        "        best_delimiter = ','\n",
        "        if delimiter_counts:\n",
        "            best_delimiter = max(delimiter_counts, key=delimiter_counts.get)\n",
        "\n",
        "        # Read with detected delimiter\n",
        "        df = pd.read_csv(file_path, delimiter=best_delimiter, nrows=nrows)\n",
        "\n",
        "        # If still only one column and contains semicolons, force semicolon delimiter\n",
        "        if len(df.columns) == 1 and ';' in df.columns[0]:\n",
        "            df = pd.read_csv(file_path, delimiter=';', nrows=nrows)\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        # Try different encodings\n",
        "        for encoding in ['utf-8', 'latin-1', 'cp1252']:\n",
        "            try:\n",
        "                df = pd.read_csv(file_path, encoding=encoding, nrows=nrows)\n",
        "                return df\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        print(f\"    ❌ Error reading file: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6: FILE DISCOVERY AND EXPLORATION\n",
        "# =============================================================================\n",
        "\n",
        "def discover_all_datasets():\n",
        "    \"\"\"Discover all downloaded datasets\"\"\"\n",
        "    print(\"🔍 Discovering all dataset files...\\n\")\n",
        "\n",
        "    all_datasets = {**WORKING_DATASETS, **REPLACEMENT_DATASETS}\n",
        "    file_map = {}\n",
        "\n",
        "    for dataset_name in all_datasets.keys():\n",
        "        folder_path = f'/content/datasets/{dataset_name}'\n",
        "        if os.path.exists(folder_path):\n",
        "            # Check for different file types\n",
        "            csv_files = list(Path(folder_path).glob('*.csv'))\n",
        "            xlsx_files = list(Path(folder_path).glob('*.xlsx'))\n",
        "            json_files = list(Path(folder_path).glob('*.json'))\n",
        "\n",
        "            file_map[dataset_name] = {\n",
        "                'csv': [f.name for f in csv_files],\n",
        "                'xlsx': [f.name for f in xlsx_files],\n",
        "                'json': [f.name for f in json_files]\n",
        "            }\n",
        "\n",
        "            print(f\"📁 {dataset_name}:\")\n",
        "            if csv_files:\n",
        "                for file_name in [f.name for f in csv_files]:\n",
        "                    print(f\"  📄 {file_name}\")\n",
        "            elif xlsx_files:\n",
        "                for file_name in [f.name for f in xlsx_files]:\n",
        "                    print(f\"  📊 {file_name}\")\n",
        "            elif json_files:\n",
        "                for file_name in [f.name for f in json_files]:\n",
        "                    print(f\"  📋 {file_name}\")\n",
        "            else:\n",
        "                print(f\"  ❌ No data files found\")\n",
        "            print()\n",
        "\n",
        "    # Check GitHub datasets\n",
        "    github_datasets = ['clothing_github', 'consumer_github', 'budget_github']\n",
        "    for dataset_name in github_datasets:\n",
        "        folder_path = f'/content/datasets/{dataset_name}'\n",
        "        if os.path.exists(folder_path):\n",
        "            csv_files = list(Path(folder_path).glob('*.csv'))\n",
        "            if csv_files:\n",
        "                file_map[dataset_name] = {'csv': [f.name for f in csv_files]}\n",
        "                print(f\"📁 {dataset_name} (GitHub):\")\n",
        "                for file_name in [f.name for f in csv_files]:\n",
        "                    print(f\"  📄 {file_name}\")\n",
        "                print()\n",
        "\n",
        "    # Check Hugging Face datasets\n",
        "    hf_datasets = ['amazon_electronics', 'amazon_beauty', 'web_nlp']\n",
        "    for dataset_name in hf_datasets:\n",
        "        folder_path = f'/content/datasets/{dataset_name}'\n",
        "        if os.path.exists(folder_path):\n",
        "            csv_files = list(Path(folder_path).glob('*.csv'))\n",
        "            if csv_files:\n",
        "                file_map[dataset_name] = {'csv': [f.name for f in csv_files]}\n",
        "                print(f\"📁 {dataset_name} (Hugging Face):\")\n",
        "                for file_name in [f.name for f in csv_files]:\n",
        "                    print(f\"  📄 {file_name}\")\n",
        "                print()\n",
        "\n",
        "    return file_map\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7: DATA LOADERS FOR WORKING DATASETS\n",
        "# =============================================================================\n",
        "\n",
        "def load_olist_data():\n",
        "    \"\"\"Load Olist e-commerce data (VERIFIED WORKING)\"\"\"\n",
        "    base_path = '/content/datasets/olist_ecommerce'\n",
        "\n",
        "    try:\n",
        "        orders = pd.read_csv(f'{base_path}/olist_orders_dataset.csv')\n",
        "        customers = pd.read_csv(f'{base_path}/olist_customers_dataset.csv')\n",
        "        order_items = pd.read_csv(f'{base_path}/olist_order_items_dataset.csv')\n",
        "        products = pd.read_csv(f'{base_path}/olist_products_dataset.csv')\n",
        "\n",
        "        print(\"✅ Olist data loaded successfully!\")\n",
        "        print(f\"Orders: {orders.shape}, Customers: {customers.shape}\")\n",
        "        print(f\"Order Items: {order_items.shape}, Products: {products.shape}\")\n",
        "\n",
        "        return {'orders': orders, 'customers': customers, 'order_items': order_items, 'products': products}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading Olist data: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def load_online_retail_data():\n",
        "    \"\"\"Load online retail data (Excel format)\"\"\"\n",
        "    try:\n",
        "        # Try Excel format first\n",
        "        retail_data = pd.read_excel('/content/datasets/online_retail/online_retail_II.xlsx')\n",
        "        print(f\"✅ Online retail data loaded: {retail_data.shape}\")\n",
        "        print(f\"Columns: {list(retail_data.columns[:5])}{'...' if len(retail_data.columns) > 5 else ''}\")\n",
        "        return retail_data\n",
        "\n",
        "    except Exception as e:\n",
        "        # Try CSV format as backup\n",
        "        try:\n",
        "            csv_files = list(Path('/content/datasets/online_retail').glob('*.csv'))\n",
        "            if csv_files:\n",
        "                retail_data = smart_read_csv(csv_files[0])\n",
        "                print(f\"✅ Online retail data loaded from CSV: {retail_data.shape}\")\n",
        "                return retail_data\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        print(f\"❌ Error loading online retail data: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def load_ab_testing_data():\n",
        "    \"\"\"Load A/B testing data (VERIFIED WORKING)\"\"\"\n",
        "    try:\n",
        "        control = pd.read_csv('/content/datasets/ab_testing/control_group.csv', delimiter=';')\n",
        "        test = pd.read_csv('/content/datasets/ab_testing/test_group.csv', delimiter=';')\n",
        "\n",
        "        print(f\"✅ A/B testing data loaded successfully!\")\n",
        "        print(f\"Control group: {control.shape}, Test group: {test.shape}\")\n",
        "\n",
        "        return {'control': control, 'test': test}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading A/B testing data: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def load_cookie_cats_data():\n",
        "    \"\"\"Load Cookie Cats A/B testing data (VERIFIED WORKING)\"\"\"\n",
        "    try:\n",
        "        cookie_cats = pd.read_csv('/content/datasets/cookie_cats/cookie_cats.csv')\n",
        "\n",
        "        print(f\"✅ Cookie Cats data loaded: {cookie_cats.shape}\")\n",
        "        print(f\"Columns: {list(cookie_cats.columns)}\")\n",
        "\n",
        "        return cookie_cats\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading Cookie Cats data: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def load_marketing_campaign_data():\n",
        "    \"\"\"Load marketing campaign data (VERIFIED WORKING)\"\"\"\n",
        "    try:\n",
        "        # Force semicolon delimiter since this data uses semicolons\n",
        "        marketing = pd.read_csv('/content/datasets/marketing_campaign/marketing_campaign.csv', delimiter=';')\n",
        "\n",
        "        print(f\"✅ Marketing campaign data loaded: {marketing.shape}\")\n",
        "        print(f\"Columns: {list(marketing.columns[:5])}{'...' if len(marketing.columns) > 5 else ''}\")\n",
        "\n",
        "        return marketing\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading marketing campaign data: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def load_ecommerce_behavior_data():\n",
        "    \"\"\"Load e-commerce behavior data (VERIFIED WORKING)\"\"\"\n",
        "    base_path = '/content/datasets/ecommerce_behavior'\n",
        "\n",
        "    try:\n",
        "        # Load both monthly files with timeout protection\n",
        "        print(\"Loading November 2019 data...\")\n",
        "        nov_data = pd.read_csv(f'{base_path}/2019-Nov.csv', nrows=50000)  # Limit rows to prevent hanging\n",
        "\n",
        "        print(\"Loading October 2019 data...\")\n",
        "        oct_data = pd.read_csv(f'{base_path}/2019-Oct.csv', nrows=50000)  # Limit rows to prevent hanging\n",
        "\n",
        "        print(f\"✅ E-commerce behavior data loaded!\")\n",
        "        print(f\"November 2019: {nov_data.shape}, October 2019: {oct_data.shape}\")\n",
        "        print(f\"Columns: {list(nov_data.columns)}\")\n",
        "\n",
        "        return {'november': nov_data, 'october': oct_data}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading e-commerce behavior data: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def load_amazon_products_data():\n",
        "    \"\"\"Load Amazon products data (VERIFIED WORKING)\"\"\"\n",
        "    base_path = '/content/datasets/amazon_products'\n",
        "\n",
        "    try:\n",
        "        products = pd.read_csv(f'{base_path}/amazon_products.csv')\n",
        "        categories = pd.read_csv(f'{base_path}/amazon_categories.csv')\n",
        "\n",
        "        print(f\"✅ Amazon products data loaded!\")\n",
        "        print(f\"Products: {products.shape}, Categories: {categories.shape}\")\n",
        "\n",
        "        return {'products': products, 'categories': categories}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading Amazon products data: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def load_retail_analytics_data():\n",
        "    \"\"\"Load retail analytics data (VERIFIED WORKING)\"\"\"\n",
        "    base_path = '/content/datasets/retail_analytics'\n",
        "\n",
        "    try:\n",
        "        sales = smart_read_csv(f'{base_path}/sales data-set.csv')\n",
        "        stores = smart_read_csv(f'{base_path}/stores data-set.csv')\n",
        "        features = smart_read_csv(f'{base_path}/Features data set.csv')\n",
        "\n",
        "        print(f\"✅ Retail analytics data loaded!\")\n",
        "        print(f\"Sales: {sales.shape}, Stores: {stores.shape}, Features: {features.shape}\")\n",
        "\n",
        "        return {'sales': sales, 'stores': stores, 'features': features}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading retail analytics data: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 8: REPLACEMENT DATASET LOADERS\n",
        "# =============================================================================\n",
        "\n",
        "def load_digital_ads_data():\n",
        "    \"\"\"Load digital ads conversion data (WORKING)\"\"\"\n",
        "    try:\n",
        "        ads_data = pd.read_csv('/content/datasets/digital_ads_real/KAG_conversion_data.csv')\n",
        "        print(f\"✅ Digital ads data loaded: {ads_data.shape}\")\n",
        "        print(f\"Columns: {list(ads_data.columns)}\")\n",
        "        return ads_data\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading digital ads data: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def load_ecommerce_events_data():\n",
        "    \"\"\"Load e-commerce events data (WORKING)\"\"\"\n",
        "    base_path = '/content/datasets/ecommerce_events'\n",
        "\n",
        "    try:\n",
        "        # Load available monthly files\n",
        "        available_files = list(Path(base_path).glob('*.csv'))\n",
        "        datasets = {}\n",
        "\n",
        "        for file in available_files[:3]:  # Load first 3 files to avoid memory issues\n",
        "            month_name = file.stem\n",
        "            df = pd.read_csv(file, nrows=25000)  # Limit rows\n",
        "            datasets[month_name] = df\n",
        "            print(f\"✅ Loaded {month_name}: {df.shape}\")\n",
        "\n",
        "        print(f\"✅ E-commerce events data loaded: {len(datasets)} files\")\n",
        "        return datasets\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading e-commerce events data: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def load_replacement_datasets():\n",
        "    \"\"\"Load any available replacement datasets\"\"\"\n",
        "    datasets_loaded = {}\n",
        "\n",
        "    # Try customer shopping dataset\n",
        "    try:\n",
        "        shopping_files = list(Path('/content/datasets/customer_shopping').glob('*.csv'))\n",
        "        if shopping_files:\n",
        "            shopping_data = smart_read_csv(shopping_files[0])\n",
        "            datasets_loaded['customer_shopping'] = shopping_data\n",
        "            print(f\"✅ Customer shopping data loaded: {shopping_data.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to load customer shopping: {str(e)}\")\n",
        "\n",
        "    # Try e-commerce sales dataset\n",
        "    try:\n",
        "        sales_files = list(Path('/content/datasets/ecommerce_sales').glob('*.csv'))\n",
        "        if sales_files:\n",
        "            sales_data = smart_read_csv(sales_files[0])\n",
        "            datasets_loaded['ecommerce_sales'] = sales_data\n",
        "            print(f\"✅ E-commerce sales data loaded: {sales_data.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to load e-commerce sales: {str(e)}\")\n",
        "\n",
        "    # Try online sales dataset\n",
        "    try:\n",
        "        online_files = list(Path('/content/datasets/online_sales').glob('*.csv'))\n",
        "        if online_files:\n",
        "            online_data = smart_read_csv(online_files[0])\n",
        "            datasets_loaded['online_sales'] = online_data\n",
        "            print(f\"✅ Online sales data loaded: {online_data.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to load online sales: {str(e)}\")\n",
        "\n",
        "    # Try Facebook ads dataset\n",
        "    try:\n",
        "        fb_files = list(Path('/content/datasets/facebook_ads').glob('*.csv'))\n",
        "        if fb_files:\n",
        "            fb_data = smart_read_csv(fb_files[0])\n",
        "            datasets_loaded['facebook_ads'] = fb_data\n",
        "            print(f\"✅ Facebook ads data loaded: {fb_data.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to load Facebook ads: {str(e)}\")\n",
        "\n",
        "    # Try advertising dataset\n",
        "    try:\n",
        "        ad_files = list(Path('/content/datasets/advertising_data').glob('*.csv'))\n",
        "        if ad_files:\n",
        "            ad_data = smart_read_csv(ad_files[0])\n",
        "            datasets_loaded['advertising'] = ad_data\n",
        "            print(f\"✅ Advertising data loaded: {ad_data.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to load advertising data: {str(e)}\")\n",
        "\n",
        "    return datasets_loaded if datasets_loaded else None\n",
        "\n",
        "def download_additional_backups():\n",
        "    \"\"\"Download additional backup datasets if main ones fail\"\"\"\n",
        "    print(\"\\n🔄 Downloading additional backup datasets...\\n\")\n",
        "\n",
        "    backup_datasets = {\n",
        "        'superstore_sales': 'bravehart101/sample-superstore-dataset',\n",
        "        'website_analytics': 'berkayalan/online-sales-dataset',\n",
        "        'customer_behavior': 'iamsouravbanerjee/customer-shopping-trends-dataset',\n",
        "        'ecommerce_simple': 'carrie1/ecommerce-data',\n",
        "        'digital_marketing_simple': 'fayomi/advertising-prediction-dataset'\n",
        "    }\n",
        "\n",
        "    success_count = 0\n",
        "    for dataset_name, dataset_path in backup_datasets.items():\n",
        "        if download_kaggle_dataset(dataset_name, dataset_path, dataset_name):\n",
        "            success_count += 1\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "    print(f\"\\n📊 Backup Datasets Summary: {success_count}/{len(backup_datasets)} downloaded successfully\")\n",
        "    return success_count\n",
        "\n",
        "def load_backup_datasets():\n",
        "    \"\"\"Load backup datasets\"\"\"\n",
        "    datasets_loaded = {}\n",
        "\n",
        "    backup_folders = ['superstore_sales', 'website_analytics', 'customer_behavior',\n",
        "                     'ecommerce_simple', 'digital_marketing_simple']\n",
        "\n",
        "    for folder in backup_folders:\n",
        "        try:\n",
        "            csv_files = list(Path(f'/content/datasets/{folder}').glob('*.csv'))\n",
        "            if csv_files:\n",
        "                backup_data = smart_read_csv(csv_files[0])\n",
        "                datasets_loaded[folder] = backup_data\n",
        "                print(f\"✅ Backup {folder} loaded: {backup_data.shape}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error loading backup {folder}: {str(e)}\")\n",
        "\n",
        "    return datasets_loaded if datasets_loaded else None\n",
        "\n",
        "def load_github_datasets():\n",
        "    \"\"\"Load GitHub datasets\"\"\"\n",
        "    datasets_loaded = {}\n",
        "\n",
        "    # Try clothing data\n",
        "    try:\n",
        "        clothing_data = pd.read_csv('/content/datasets/clothing_github/clothing_data.csv')\n",
        "        datasets_loaded['clothing'] = clothing_data\n",
        "        print(f\"✅ GitHub clothing data loaded: {clothing_data.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading GitHub clothing data: {str(e)}\")\n",
        "\n",
        "    # Try consumer data\n",
        "    try:\n",
        "        consumer_data = pd.read_csv('/content/datasets/consumer_github/consumer_data.csv')\n",
        "        datasets_loaded['consumer_behavior'] = consumer_data\n",
        "        print(f\"✅ GitHub consumer data loaded: {consumer_data.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading GitHub consumer data: {str(e)}\")\n",
        "\n",
        "    # Try budget data\n",
        "    try:\n",
        "        budget_data = pd.read_csv('/content/datasets/budget_github/budget_data.csv')\n",
        "        datasets_loaded['budget_analysis'] = budget_data\n",
        "        print(f\"✅ GitHub budget data loaded: {budget_data.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading GitHub budget data: {str(e)}\")\n",
        "\n",
        "    return datasets_loaded if datasets_loaded else None\n",
        "\n",
        "def load_huggingface_datasets():\n",
        "    \"\"\"Load Hugging Face datasets\"\"\"\n",
        "    datasets_loaded = {}\n",
        "\n",
        "    # Try to load any HF datasets that were downloaded\n",
        "    hf_folders = ['amazon_electronics', 'amazon_beauty', 'web_nlp']\n",
        "\n",
        "    for folder in hf_folders:\n",
        "        try:\n",
        "            csv_files = list(Path(f'/content/datasets/{folder}').glob('*.csv'))\n",
        "            if csv_files:\n",
        "                hf_data = smart_read_csv(csv_files[0], nrows=5000)  # Limit rows for memory\n",
        "                datasets_loaded[folder] = hf_data\n",
        "                print(f\"✅ Hugging Face {folder} loaded: {hf_data.shape}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error loading HF {folder}: {str(e)}\")\n",
        "\n",
        "    return datasets_loaded if datasets_loaded else None\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 9: COMPREHENSIVE TESTING\n",
        "# =============================================================================\n",
        "\n",
        "def test_all_real_datasets():\n",
        "    \"\"\"Test all real dataset loaders\"\"\"\n",
        "    print(\"🧪 Testing all REAL dataset loaders...\\n\")\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # Test verified working datasets\n",
        "    print(\"1️⃣ Testing Olist E-commerce data:\")\n",
        "    results['olist'] = load_olist_data()\n",
        "    print()\n",
        "\n",
        "    print(\"2️⃣ Testing Online Retail data:\")\n",
        "    results['online_retail'] = load_online_retail_data()\n",
        "    print()\n",
        "\n",
        "    print(\"3️⃣ Testing A/B testing data:\")\n",
        "    results['ab_testing'] = load_ab_testing_data()\n",
        "    print()\n",
        "\n",
        "    print(\"4️⃣ Testing Cookie Cats data:\")\n",
        "    results['cookie_cats'] = load_cookie_cats_data()\n",
        "    print()\n",
        "\n",
        "    print(\"5️⃣ Testing Marketing Campaign data:\")\n",
        "    results['marketing'] = load_marketing_campaign_data()\n",
        "    print()\n",
        "\n",
        "    print(\"6️⃣ Testing E-commerce Behavior data:\")\n",
        "    try:\n",
        "        results['ecommerce_behavior'] = load_ecommerce_behavior_data()\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error in e-commerce behavior: {str(e)}\")\n",
        "        results['ecommerce_behavior'] = None\n",
        "    print()\n",
        "\n",
        "    print(\"7️⃣ Testing Amazon Products data:\")\n",
        "    results['amazon'] = load_amazon_products_data()\n",
        "    print()\n",
        "\n",
        "    print(\"8️⃣ Testing Retail Analytics data:\")\n",
        "    results['retail'] = load_retail_analytics_data()\n",
        "    print()\n",
        "\n",
        "    # Test replacement datasets that have files\n",
        "    print(\"9️⃣ Testing Digital Ads data:\")\n",
        "    results['digital_ads'] = load_digital_ads_data()\n",
        "    print()\n",
        "\n",
        "    print(\"🔟 Testing E-commerce Events data:\")\n",
        "    results['ecommerce_events'] = load_ecommerce_events_data()\n",
        "    print()\n",
        "\n",
        "    # Test additional replacement datasets\n",
        "    print(\"1️⃣1️⃣ Testing Replacement datasets:\")\n",
        "    results['replacements'] = load_replacement_datasets()\n",
        "    print()\n",
        "\n",
        "    # Test GitHub datasets\n",
        "    print(\"1️⃣2️⃣ Testing GitHub datasets:\")\n",
        "    results['github'] = load_github_datasets()\n",
        "    print()\n",
        "\n",
        "    # Test Hugging Face datasets\n",
        "    print(\"1️⃣3️⃣ Testing Hugging Face datasets:\")\n",
        "    try:\n",
        "        results['huggingface'] = load_huggingface_datasets()\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Hugging Face loading failed: {str(e)}\")\n",
        "        results['huggingface'] = None\n",
        "    print()\n",
        "\n",
        "    # Summary\n",
        "    successful_loads = sum(1 for v in results.values() if v is not None)\n",
        "    total_tests = len(results)\n",
        "\n",
        "    print(f\"✨ Testing complete! {successful_loads}/{total_tests} dataset groups loaded successfully\")\n",
        "\n",
        "    # Detailed summary\n",
        "    working_datasets = []\n",
        "    for key, value in results.items():\n",
        "        if value is not None:\n",
        "            if isinstance(value, dict):\n",
        "                working_datasets.append(f\"{key} ({len(value)} files)\")\n",
        "            else:\n",
        "                working_datasets.append(key)\n",
        "\n",
        "    print(f\"\\n🎯 Successfully loaded datasets:\")\n",
        "    for dataset in working_datasets:\n",
        "        print(f\"   ✅ {dataset}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 10: MAIN EXECUTION\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to setup and download all REAL datasets\"\"\"\n",
        "    print(\"🎯 WEB ANALYTICS & OPTIMIZATION PROJECT\")\n",
        "    print(\"📦 Real Dataset Downloader for Google Colab\")\n",
        "    print(\"🚫 NO SYNTHETIC DATA - REAL DATASETS ONLY\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Step 1: Setup Kaggle API\n",
        "    setup_kaggle_api()\n",
        "    print()\n",
        "\n",
        "    # Step 2: Install packages\n",
        "    install_packages()\n",
        "    print()\n",
        "\n",
        "    # Step 3: Download verified working datasets\n",
        "    working_count = download_all_working_datasets()\n",
        "\n",
        "    # Step 4: Download replacement datasets for better coverage\n",
        "    replacement_count = download_replacement_datasets()\n",
        "\n",
        "    # Step 5: Download GitHub datasets\n",
        "    github_count = download_github_datasets()\n",
        "\n",
        "    # Step 6: Try downloading from Hugging Face\n",
        "    try:\n",
        "        hf_count = download_huggingface_datasets()\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Hugging Face downloads failed: {str(e)}\")\n",
        "        hf_count = 0\n",
        "\n",
        "    # Step 7: Discover all files\n",
        "    file_map = discover_all_datasets()\n",
        "\n",
        "    print(\"🎉 Download phase complete!\")\n",
        "    print(f\"📊 Summary:\")\n",
        "    print(f\"   Working datasets: {working_count}\")\n",
        "    print(f\"   Replacement datasets: {replacement_count}\")\n",
        "    print(f\"   GitHub datasets: {github_count}\")\n",
        "    print(f\"   Hugging Face datasets: {hf_count}\")\n",
        "    print(f\"   Total real datasets available: {working_count + replacement_count + github_count + hf_count}\")\n",
        "\n",
        "    print(\"\\n📍 Next steps:\")\n",
        "    print(\"1. Test dataset loading\")\n",
        "    print(\"2. Choose the best datasets for your analysis\")\n",
        "    print(\"3. Start with data cleaning and integration\")\n",
        "    print(\"4. Build your analytics models\")\n",
        "\n",
        "    return file_map\n",
        "\n",
        "# =============================================================================\n",
        "# EXECUTION\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Run the main setup\n",
        "        file_map = main()\n",
        "\n",
        "        # Test all real datasets\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        results = test_all_real_datasets()\n",
        "\n",
        "        # Count successful datasets\n",
        "        successful_datasets = [k for k, v in results.items() if v is not None]\n",
        "\n",
        "        # If we don't have enough datasets, download backups\n",
        "        if len(successful_datasets) < 8:\n",
        "            print(f\"\\n🔄 Only {len(successful_datasets)} dataset groups loaded. Downloading backup datasets...\")\n",
        "            backup_count = download_additional_backups()\n",
        "\n",
        "            if backup_count > 0:\n",
        "                print(\"\\n🧪 Testing backup datasets...\")\n",
        "                backup_results = load_backup_datasets()\n",
        "                if backup_results:\n",
        "                    results['backups'] = backup_results\n",
        "                    successful_datasets.append('backups')\n",
        "\n",
        "        # Final summary\n",
        "        print(f\"\\n🎯 FINAL SUMMARY - REAL DATASETS ONLY:\")\n",
        "        print(f\"✅ Successfully loaded dataset groups: {len(successful_datasets)}\")\n",
        "\n",
        "        # Count total individual datasets\n",
        "        total_individual_datasets = 0\n",
        "        for k, v in results.items():\n",
        "            if v is not None:\n",
        "                if isinstance(v, dict):\n",
        "                    total_individual_datasets += len(v)\n",
        "                else:\n",
        "                    total_individual_datasets += 1\n",
        "\n",
        "        print(f\"📊 Total individual datasets: {total_individual_datasets}\")\n",
        "        print(f\"📋 Available dataset groups: {', '.join(successful_datasets)}\")\n",
        "\n",
        "        if len(successful_datasets) >= 8:\n",
        "            print(\"\\n🚀 EXCELLENT! You have a comprehensive collection of real datasets for web analytics!\")\n",
        "        elif len(successful_datasets) >= 5:\n",
        "            print(\"\\n✅ GOOD! You have sufficient real datasets to start your analysis!\")\n",
        "        elif len(successful_datasets) >= 3:\n",
        "            print(\"\\n⚠️ LIMITED but workable. You have basic datasets for analysis.\")\n",
        "        else:\n",
        "            print(\"\\n❌ FEW datasets available. Consider checking internet connection or trying individual downloads.\")\n",
        "\n",
        "        print(\"\\n🎉 Ready to build your web analytics platform with REAL data!\")\n",
        "        print(\"\\n💡 Recommended starting datasets:\")\n",
        "        if results.get('olist') is not None: print(\"   🔹 Olist E-commerce (comprehensive)\")\n",
        "        if results.get('online_retail') is not None: print(\"   🔹 Online Retail (transaction analysis)\")\n",
        "        if results.get('ab_testing') is not None: print(\"   🔹 A/B Testing (conversion optimization)\")\n",
        "        if results.get('digital_ads') is not None: print(\"   🔹 Digital Ads (marketing analytics)\")\n",
        "        if results.get('ecommerce_behavior') is not None: print(\"   🔹 E-commerce Behavior (user tracking)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Setup failed with error: {str(e)}\")\n",
        "        print(\"💡 Trying to download backup datasets as fallback...\")\n",
        "        try:\n",
        "            backup_count = download_additional_backups()\n",
        "            if backup_count > 0:\n",
        "                backup_results = load_backup_datasets()\n",
        "                print(f\"\\n✅ Loaded {len(backup_results) if backup_results else 0} backup datasets!\")\n",
        "            else:\n",
        "                print(\"\\n❌ Backup downloads also failed. Please check:\")\n",
        "                print(\"   - Internet connection\")\n",
        "                print(\"   - Kaggle API credentials\")\n",
        "                print(\"   - Try running individual dataset downloads\")\n",
        "        except Exception as backup_error:\n",
        "            print(f\"❌ Backup downloads failed: {str(backup_error)}\")\n",
        "            print(\"🔧 Please try manual dataset downloads or check your setup.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bbd76d4335234228aa6501b2664c2cb4",
            "29b9af5c15754ab68b41f24151a5c372",
            "e34fb111f61f44b894180d12582ff6c4",
            "0f6ae85543de4e309e15ee68f6dcf969",
            "3a296a5dc6a34e87ab6055de2af324cb",
            "38bdb102e8eb413fb22f821e369ef05d",
            "52f1cd0992a447e38c5c5d62dbb28d30",
            "85b9d1ebf8fc494185b918635b446b83",
            "72328cb445f740aa81d34984f1ba9690",
            "a34a220eb1a44d7fbaf99f875c73d2ed",
            "8b84ccc17ebe40efb9f8835aa79a75fa",
            "62df3bd4341a417fa77ddf76656fd690",
            "ea679773020a42808bedca707a57d61a",
            "7a7f22fcb216439787e568c40a8b7f12",
            "03bd040823db42cb886a038a7351362a",
            "b0c244559e264b278455caee09b10adc",
            "b605936e6512453ca6fb644a4362e9b8",
            "095ef2777521425fae4b817645864514",
            "910586bf22df4153aa28367d30220213",
            "52f9814bf63145ed866fb36c192de3b2",
            "7b3848be5bf04fa3999c6ab20d4329dd",
            "f881013f43d141bba183d4d8c228be00",
            "8e2ddf587387451dbed8a5bd181e0a8e",
            "ecabb2a55a4d4715bd3ac391801b30ed",
            "bcaaa43c724e4493bef7a3d61ef59b6b",
            "19804a00b76044cca3268196d10e3fb4",
            "1ae8c7f8fea7499b9533c9773e698a2d",
            "52bb7c02b4894a7a94075fc245d3747d",
            "4fb850eaf44548af8315aa8a6dd9f3c3",
            "8691bf5eb2244d798d479c71083e9e08",
            "e80088514a1e41609e79e5d0ac6cbd24",
            "82ed001ea0ea4302946f6da13a6303de",
            "f696bf41992f45e287d1f290fa413e2f",
            "f7b3f3aa2e0640958e38afa2a442b499",
            "05c885c1db5148b0a2856ef66c7daee3",
            "79d36e476b3a45c5a4d8795be6545e35",
            "b2889cbba23f4599aa65e89ac3da2c20",
            "f78ad141c1ec457eb07a0ae8ee0eb4a5",
            "63a632d0754149618a67c5f1915d6cbc",
            "fafa924eec8842059a4edc72beb092b8",
            "e3201b8387b84959a501c7b97cbe0073",
            "f43faa5be421415b8b3e2cc03166d9dd",
            "bfaeac3d8f76452aa80dfa9646941072",
            "8f6c20720dc24b7d9371e93253f6e7d4",
            "c1e548e5060d485dae21d1ae8ca6bb43",
            "8791771770bc4d72a4353d0516160d52",
            "41780eb4b3164ff2ae34787eb8157bd1",
            "6194e4eaca96453a8ea1f754b14968d4",
            "1531e22563c444978063f416ceb2d800",
            "9f3f12dcc2e34f189c881f776c8537ea",
            "147312915fcf43edbc50757c491ea60f",
            "4466658d88d340ceb1366c5c45ff9d36",
            "180fabc72825457d9dca3c92136b1a99",
            "812036b7ef2548b8a5df9748697fe544",
            "56a43818738e4ea391fd729ff7f59ae7"
          ]
        },
        "id": "chRsvPknpmXu",
        "outputId": "7200fcd1-65d1-458c-a3c1-a814c3ebffb1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 WEB ANALYTICS & OPTIMIZATION PROJECT\n",
            "📦 Real Dataset Downloader for Google Colab\n",
            "🚫 NO SYNTHETIC DATA - REAL DATASETS ONLY\n",
            "============================================================\n",
            "✅ Kaggle API credentials setup complete!\n",
            "\n",
            "✅ All packages installed!\n",
            "\n",
            "🚀 Starting download of WORKING datasets...\n",
            "\n",
            "📥 Downloading olist_ecommerce...\n",
            "✅ olist_ecommerce downloaded successfully!\n",
            "--------------------------------------------------\n",
            "📥 Downloading online_retail...\n",
            "✅ online_retail downloaded successfully!\n",
            "--------------------------------------------------\n",
            "📥 Downloading ab_testing...\n",
            "✅ ab_testing downloaded successfully!\n",
            "--------------------------------------------------\n",
            "📥 Downloading cookie_cats...\n",
            "✅ cookie_cats downloaded successfully!\n",
            "--------------------------------------------------\n",
            "📥 Downloading marketing_campaign...\n",
            "✅ marketing_campaign downloaded successfully!\n",
            "--------------------------------------------------\n",
            "📥 Downloading customer_personality...\n",
            "✅ customer_personality downloaded successfully!\n",
            "--------------------------------------------------\n",
            "📥 Downloading amazon_products...\n",
            "✅ amazon_products downloaded successfully!\n",
            "--------------------------------------------------\n",
            "📥 Downloading ecommerce_behavior...\n",
            "✅ ecommerce_behavior downloaded successfully!\n",
            "--------------------------------------------------\n",
            "📥 Downloading retail_analytics...\n",
            "✅ retail_analytics downloaded successfully!\n",
            "--------------------------------------------------\n",
            "\n",
            "📊 Working Datasets Summary: 9/9 downloaded successfully\n",
            "\n",
            "🔄 Downloading replacement datasets for better web analytics...\n",
            "\n",
            "📥 Downloading digital_ads_real...\n",
            "✅ digital_ads_real downloaded successfully!\n",
            "------------------------------\n",
            "📥 Downloading ecommerce_events...\n",
            "✅ ecommerce_events downloaded successfully!\n",
            "------------------------------\n",
            "📥 Downloading ecommerce_sales...\n",
            "✅ ecommerce_sales downloaded successfully!\n",
            "------------------------------\n",
            "📥 Downloading online_sales...\n",
            "✅ online_sales downloaded successfully!\n",
            "------------------------------\n",
            "📥 Downloading customer_shopping...\n",
            "✅ customer_shopping downloaded successfully!\n",
            "------------------------------\n",
            "📥 Downloading web_classification...\n",
            "✅ web_classification downloaded successfully!\n",
            "------------------------------\n",
            "📥 Downloading facebook_ads...\n",
            "✅ facebook_ads downloaded successfully!\n",
            "------------------------------\n",
            "📥 Downloading advertising_data...\n",
            "✅ advertising_data downloaded successfully!\n",
            "------------------------------\n",
            "📥 Downloading retail_sales...\n",
            "✅ retail_sales downloaded successfully!\n",
            "------------------------------\n",
            "📥 Downloading user_behavior...\n",
            "✅ user_behavior downloaded successfully!\n",
            "------------------------------\n",
            "📥 Downloading shopping_trends...\n",
            "✅ shopping_trends downloaded successfully!\n",
            "------------------------------\n",
            "\n",
            "📊 Replacement Datasets Summary: 11/11 downloaded successfully\n",
            "\n",
            "🐙 Downloading datasets from GitHub...\n",
            "\n",
            "📥 Downloading clothing_github from GitHub...\n",
            "✅ clothing_github downloaded from GitHub!\n",
            "📥 Downloading consumer_github from GitHub...\n",
            "✅ consumer_github downloaded from GitHub!\n",
            "📥 Downloading budget_github from GitHub...\n",
            "✅ budget_github downloaded from GitHub!\n",
            "\n",
            "📊 GitHub Datasets Summary: 3 downloaded successfully\n",
            "\n",
            "🤗 Downloading datasets from Hugging Face...\n",
            "\n",
            "🤗 Downloading amazon_electronics from Hugging Face...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbd76d4335234228aa6501b2664c2cb4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/22.6G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62df3bd4341a417fa77ddf76656fd690",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating full split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Failed to download amazon_electronics from Hugging Face: Loading a dataset cached in a LocalFileSystem is not supported.\n",
            "🤗 Downloading amazon_beauty from Hugging Face...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/327M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e2ddf587387451dbed8a5bd181e0a8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating full split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7b3f3aa2e0640958e38afa2a442b499"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Failed to download amazon_beauty from Hugging Face: Loading a dataset cached in a LocalFileSystem is not supported.\n",
            "🤗 Downloading web_nlp from Hugging Face...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/734 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1e548e5060d485dae21d1ae8ca6bb43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Failed to download web_nlp from Hugging Face: Invalid pattern: '**' can only be an entire path component\n",
            "\n",
            "📊 Hugging Face Datasets Summary: 0 downloaded successfully\n",
            "🔍 Discovering all dataset files...\n",
            "\n",
            "📁 olist_ecommerce:\n",
            "  📄 olist_order_items_dataset.csv\n",
            "  📄 olist_orders_dataset.csv\n",
            "  📄 product_category_name_translation.csv\n",
            "  📄 olist_geolocation_dataset.csv\n",
            "  📄 olist_order_reviews_dataset.csv\n",
            "  📄 olist_customers_dataset.csv\n",
            "  📄 olist_products_dataset.csv\n",
            "  📄 olist_sellers_dataset.csv\n",
            "  📄 olist_order_payments_dataset.csv\n",
            "\n",
            "📁 online_retail:\n",
            "  📊 online_retail_II.xlsx\n",
            "\n",
            "📁 ab_testing:\n",
            "  📄 control_group.csv\n",
            "  📄 test_group.csv\n",
            "\n",
            "📁 cookie_cats:\n",
            "  📄 cookie_cats.csv\n",
            "\n",
            "📁 marketing_campaign:\n",
            "  📄 marketing_campaign.csv\n",
            "\n",
            "📁 customer_personality:\n",
            "  📄 marketing_campaign.csv\n",
            "\n",
            "📁 amazon_products:\n",
            "  📄 amazon_categories.csv\n",
            "  📄 amazon_products.csv\n",
            "\n",
            "📁 ecommerce_behavior:\n",
            "  📄 2019-Nov.csv\n",
            "  📄 2019-Oct.csv\n",
            "\n",
            "📁 retail_analytics:\n",
            "  📄 stores data-set.csv\n",
            "  📄 sales data-set.csv\n",
            "  📄 Features data set.csv\n",
            "\n",
            "📁 digital_ads_real:\n",
            "  📄 KAG_conversion_data.csv\n",
            "\n",
            "📁 ecommerce_events:\n",
            "  📄 2019-Nov.csv\n",
            "  📄 2019-Dec.csv\n",
            "  📄 2020-Jan.csv\n",
            "  📄 2019-Oct.csv\n",
            "  📄 2020-Feb.csv\n",
            "\n",
            "📁 ecommerce_sales:\n",
            "  📄 data.csv\n",
            "\n",
            "📁 online_sales:\n",
            "  📄 retail_sales_dataset.csv\n",
            "\n",
            "📁 customer_shopping:\n",
            "  📄 customer_shopping_data.csv\n",
            "\n",
            "📁 web_classification:\n",
            "  ❌ No data files found\n",
            "\n",
            "📁 facebook_ads:\n",
            "  ❌ No data files found\n",
            "\n",
            "📁 advertising_data:\n",
            "  ❌ No data files found\n",
            "\n",
            "📁 retail_sales:\n",
            "  📄 orders.csv\n",
            "\n",
            "📁 user_behavior:\n",
            "  ❌ No data files found\n",
            "\n",
            "📁 shopping_trends:\n",
            "  📄 shopping_trends_updated.csv\n",
            "  📄 shopping_trends.csv\n",
            "\n",
            "📁 clothing_github (GitHub):\n",
            "  📄 clothing_data.csv\n",
            "\n",
            "📁 consumer_github (GitHub):\n",
            "  📄 consumer_data.csv\n",
            "\n",
            "📁 budget_github (GitHub):\n",
            "  📄 budget_data.csv\n",
            "\n",
            "🎉 Download phase complete!\n",
            "📊 Summary:\n",
            "   Working datasets: 9\n",
            "   Replacement datasets: 11\n",
            "   GitHub datasets: 3\n",
            "   Hugging Face datasets: 0\n",
            "   Total real datasets available: 23\n",
            "\n",
            "📍 Next steps:\n",
            "1. Test dataset loading\n",
            "2. Choose the best datasets for your analysis\n",
            "3. Start with data cleaning and integration\n",
            "4. Build your analytics models\n",
            "\n",
            "============================================================\n",
            "🧪 Testing all REAL dataset loaders...\n",
            "\n",
            "1️⃣ Testing Olist E-commerce data:\n",
            "✅ Olist data loaded successfully!\n",
            "Orders: (99441, 8), Customers: (99441, 5)\n",
            "Order Items: (112650, 7), Products: (32951, 9)\n",
            "\n",
            "2️⃣ Testing Online Retail data:\n",
            "✅ Online retail data loaded: (525461, 8)\n",
            "Columns: ['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate']...\n",
            "\n",
            "3️⃣ Testing A/B testing data:\n",
            "✅ A/B testing data loaded successfully!\n",
            "Control group: (30, 10), Test group: (30, 10)\n",
            "\n",
            "4️⃣ Testing Cookie Cats data:\n",
            "✅ Cookie Cats data loaded: (90189, 5)\n",
            "Columns: ['userid', 'version', 'sum_gamerounds', 'retention_1', 'retention_7']\n",
            "\n",
            "5️⃣ Testing Marketing Campaign data:\n",
            "✅ Marketing campaign data loaded: (2240, 29)\n",
            "Columns: ['ID', 'Year_Birth', 'Education', 'Marital_Status', 'Income']...\n",
            "\n",
            "6️⃣ Testing E-commerce Behavior data:\n",
            "Loading November 2019 data...\n",
            "Loading October 2019 data...\n",
            "✅ E-commerce behavior data loaded!\n",
            "November 2019: (50000, 9), October 2019: (50000, 9)\n",
            "Columns: ['event_time', 'event_type', 'product_id', 'category_id', 'category_code', 'brand', 'price', 'user_id', 'user_session']\n",
            "\n",
            "7️⃣ Testing Amazon Products data:\n",
            "✅ Amazon products data loaded!\n",
            "Products: (1426337, 11), Categories: (248, 2)\n",
            "\n",
            "8️⃣ Testing Retail Analytics data:\n",
            "✅ Retail analytics data loaded!\n",
            "Sales: (1000, 5), Stores: (45, 3), Features: (1000, 12)\n",
            "\n",
            "9️⃣ Testing Digital Ads data:\n",
            "✅ Digital ads data loaded: (1143, 11)\n",
            "Columns: ['ad_id', 'xyz_campaign_id', 'fb_campaign_id', 'age', 'gender', 'interest', 'Impressions', 'Clicks', 'Spent', 'Total_Conversion', 'Approved_Conversion']\n",
            "\n",
            "🔟 Testing E-commerce Events data:\n",
            "✅ Loaded 2019-Nov: (25000, 9)\n",
            "✅ Loaded 2019-Dec: (25000, 9)\n",
            "✅ Loaded 2020-Jan: (25000, 9)\n",
            "✅ E-commerce events data loaded: 3 files\n",
            "\n",
            "1️⃣1️⃣ Testing Replacement datasets:\n",
            "✅ Customer shopping data loaded: (1000, 10)\n",
            "✅ E-commerce sales data loaded: (1000, 8)\n",
            "✅ Online sales data loaded: (1000, 9)\n",
            "\n",
            "1️⃣2️⃣ Testing GitHub datasets:\n",
            "✅ GitHub clothing data loaded: (400, 14)\n",
            "✅ GitHub consumer data loaded: (601, 10)\n",
            "✅ GitHub budget data loaded: (23972, 7)\n",
            "\n",
            "1️⃣3️⃣ Testing Hugging Face datasets:\n",
            "\n",
            "✨ Testing complete! 12/13 dataset groups loaded successfully\n",
            "\n",
            "🎯 Successfully loaded datasets:\n",
            "   ✅ olist (4 files)\n",
            "   ✅ online_retail\n",
            "   ✅ ab_testing (2 files)\n",
            "   ✅ cookie_cats\n",
            "   ✅ marketing\n",
            "   ✅ ecommerce_behavior (2 files)\n",
            "   ✅ amazon (2 files)\n",
            "   ✅ retail (3 files)\n",
            "   ✅ digital_ads\n",
            "   ✅ ecommerce_events (3 files)\n",
            "   ✅ replacements (3 files)\n",
            "   ✅ github (3 files)\n",
            "\n",
            "🎯 FINAL SUMMARY - REAL DATASETS ONLY:\n",
            "✅ Successfully loaded dataset groups: 12\n",
            "📊 Total individual datasets: 26\n",
            "📋 Available dataset groups: olist, online_retail, ab_testing, cookie_cats, marketing, ecommerce_behavior, amazon, retail, digital_ads, ecommerce_events, replacements, github\n",
            "\n",
            "🚀 EXCELLENT! You have a comprehensive collection of real datasets for web analytics!\n",
            "\n",
            "🎉 Ready to build your web analytics platform with REAL data!\n",
            "\n",
            "💡 Recommended starting datasets:\n",
            "   🔹 Olist E-commerce (comprehensive)\n",
            "   🔹 Online Retail (transaction analysis)\n",
            "   🔹 A/B Testing (conversion optimization)\n",
            "   🔹 Digital Ads (marketing analytics)\n",
            "   🔹 E-commerce Behavior (user tracking)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A/B TESTING FRAMEWORK - CORE SETUP\n",
        "# Advanced statistical methods for A/B testing\n"
      ],
      "metadata": {
        "id": "s7eDQKrZSDRO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKsCBuF2pJmH",
        "outputId": "2937cb00-bf3d-44c5-984b-5883de3b3f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧪 ENHANCED A/B TESTING FRAMEWORK - CHUNK 1\n",
            "Ready to initialize with your real datasets!\n",
            "\n",
            "Usage:\n",
            "ab_tester = initialize_ab_framework()\n",
            "ab_tester.inspect_dataset_structure('cookie_cats')\n"
          ]
        }
      ],
      "source": [
        "# A/B TESTING FRAMEWORK - CORE SETUP\n",
        "# Advanced statistical methods for A/B testing\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import norm, beta, gamma, chi2_contingency\n",
        "from statsmodels.stats.power import ttest_power, zt_ind_solve_power\n",
        "from statsmodels.stats.proportion import proportions_ztest, proportion_effectsize\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "import math\n",
        "from datetime import datetime, timedelta\n",
        "from pathlib import Path\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class AdvancedABTesting:\n",
        "    \"\"\"\n",
        "    Enhanced A/B Testing Framework specifically designed for your real datasets:\n",
        "    - A/B Testing Data: control_group.csv + test_group.csv (Facebook ads)\n",
        "    - Cookie Cats: Mobile game A/B test with 90K users\n",
        "    - Digital Ads: Conversion tracking with 1143 records\n",
        "\n",
        "    Features:\n",
        "    - Power analysis and sample size calculation\n",
        "    - Sequential testing (early stopping)\n",
        "    - Bayesian analysis with Beta-Binomial conjugate priors\n",
        "    - Multiple testing corrections\n",
        "    - Effect size calculations\n",
        "    - Real-time monitoring capabilities\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_path='/content/datasets'):\n",
        "        \"\"\"Initialize with your dataset paths\"\"\"\n",
        "        self.data_path = data_path\n",
        "        self.test_results = {}\n",
        "        self.sequential_results = []\n",
        "        self.datasets = {}\n",
        "\n",
        "        print(\"🚀 ENHANCED A/B TESTING FRAMEWORK INITIALIZED\")\n",
        "        print(\"=\" * 55)\n",
        "        print(\"🎯 Designed for Your Real Datasets:\")\n",
        "        print(\"   📊 A/B Testing Data (Facebook Ads)\")\n",
        "        print(\"   🎮 Cookie Cats (Mobile Game Retention)\")\n",
        "        print(\"   💰 Digital Ads (Conversion Tracking)\")\n",
        "        print(\"=\" * 55)\n",
        "\n",
        "    def load_your_datasets(self):\n",
        "        \"\"\"Load your specific A/B testing datasets\"\"\"\n",
        "        try:\n",
        "            # Load A/B Testing Data (Facebook Ads Campaign)\n",
        "            control_path = f'{self.data_path}/ab_testing/control_group.csv'\n",
        "            test_path = f'{self.data_path}/ab_testing/test_group.csv'\n",
        "\n",
        "            if Path(control_path).exists() and Path(test_path).exists():\n",
        "                self.datasets['ab_facebook'] = {\n",
        "                    'control': pd.read_csv(control_path, delimiter=';'),\n",
        "                    'test': pd.read_csv(test_path, delimiter=';')\n",
        "                }\n",
        "                print(\"✅ Facebook Ads A/B Test Data Loaded\")\n",
        "                print(f\"   Control: {self.datasets['ab_facebook']['control'].shape}\")\n",
        "                print(f\"   Test: {self.datasets['ab_facebook']['test'].shape}\")\n",
        "\n",
        "            # Load Cookie Cats Data (Mobile Game A/B Test)\n",
        "            cookie_path = f'{self.data_path}/cookie_cats/cookie_cats.csv'\n",
        "            if Path(cookie_path).exists():\n",
        "                self.datasets['cookie_cats'] = pd.read_csv(cookie_path)\n",
        "                print(\"✅ Cookie Cats Mobile Game A/B Test Loaded\")\n",
        "                print(f\"   Total Users: {self.datasets['cookie_cats'].shape}\")\n",
        "                print(f\"   Versions: {self.datasets['cookie_cats']['version'].unique()}\")\n",
        "\n",
        "            # Load Digital Ads Conversion Data\n",
        "            digital_ads_path = f'{self.data_path}/digital_ads_real/KAG_conversion_data.csv'\n",
        "            if Path(digital_ads_path).exists():\n",
        "                self.datasets['digital_ads'] = pd.read_csv(digital_ads_path)\n",
        "                print(\"✅ Digital Ads Conversion Data Loaded\")\n",
        "                print(f\"   Records: {self.datasets['digital_ads'].shape}\")\n",
        "                print(f\"   Campaigns: {self.datasets['digital_ads']['xyz_campaign_id'].nunique()}\")\n",
        "\n",
        "            # Summary\n",
        "            print(f\"\\n📊 DATASET SUMMARY:\")\n",
        "            print(f\"   Total A/B Test Datasets: {len(self.datasets)}\")\n",
        "            for name, data in self.datasets.items():\n",
        "                if isinstance(data, dict):\n",
        "                    total_records = sum(df.shape[0] for df in data.values())\n",
        "                    print(f\"   {name}: {total_records:,} total records\")\n",
        "                else:\n",
        "                    print(f\"   {name}: {data.shape[0]:,} records\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error loading datasets: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def inspect_dataset_structure(self, dataset_name=None):\n",
        "        \"\"\"Inspect the structure of your loaded datasets\"\"\"\n",
        "        if not self.datasets:\n",
        "            print(\"❌ No datasets loaded. Run load_your_datasets() first.\")\n",
        "            return\n",
        "\n",
        "        datasets_to_inspect = [dataset_name] if dataset_name else list(self.datasets.keys())\n",
        "\n",
        "        for name in datasets_to_inspect:\n",
        "            if name not in self.datasets:\n",
        "                print(f\"❌ Dataset '{name}' not found\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\n🔍 INSPECTING DATASET: {name.upper()}\")\n",
        "            print(\"=\" * 50)\n",
        "\n",
        "            data = self.datasets[name]\n",
        "\n",
        "            if name == 'ab_facebook':\n",
        "                # Facebook Ads A/B Test Analysis\n",
        "                control_df = data['control']\n",
        "                test_df = data['test']\n",
        "\n",
        "                print(\"📊 FACEBOOK ADS A/B TEST STRUCTURE:\")\n",
        "                print(f\"Control Group Columns: {list(control_df.columns)}\")\n",
        "                print(f\"Test Group Columns: {list(test_df.columns)}\")\n",
        "\n",
        "                # Show key metrics\n",
        "                print(f\"\\n📈 KEY METRICS AVAILABLE:\")\n",
        "                if '# of Purchase' in control_df.columns:\n",
        "                    print(f\"   💰 Purchases (Control): {control_df['# of Purchase'].sum()}\")\n",
        "                    print(f\"   💰 Purchases (Test): {test_df['# of Purchase'].sum()}\")\n",
        "\n",
        "                if 'Spent' in control_df.columns:\n",
        "                    print(f\"   💸 Total Spend (Control): ${control_df['Spent'].sum():.2f}\")\n",
        "                    print(f\"   💸 Total Spend (Test): ${test_df['Spent'].sum():.2f}\")\n",
        "\n",
        "                if '# of Website Clicks' in control_df.columns:\n",
        "                    print(f\"   🖱️ Clicks (Control): {control_df['# of Website Clicks'].sum()}\")\n",
        "                    print(f\"   🖱️ Clicks (Test): {test_df['# of Website Clicks'].sum()}\")\n",
        "\n",
        "            elif name == 'cookie_cats':\n",
        "                # Cookie Cats Mobile Game Analysis\n",
        "                print(\"🎮 COOKIE CATS MOBILE GAME STRUCTURE:\")\n",
        "                print(f\"Columns: {list(data.columns)}\")\n",
        "                print(f\"Total Users: {len(data):,}\")\n",
        "\n",
        "                # Version distribution\n",
        "                version_dist = data['version'].value_counts()\n",
        "                print(f\"\\n📱 VERSION DISTRIBUTION:\")\n",
        "                for version, count in version_dist.items():\n",
        "                    print(f\"   {version}: {count:,} users ({count/len(data)*100:.1f}%)\")\n",
        "\n",
        "                # Retention metrics\n",
        "                if 'retention_1' in data.columns and 'retention_7' in data.columns:\n",
        "                    retention_1 = data.groupby('version')['retention_1'].mean()\n",
        "                    retention_7 = data.groupby('version')['retention_7'].mean()\n",
        "\n",
        "                    print(f\"\\n📈 RETENTION RATES BY VERSION:\")\n",
        "                    for version in data['version'].unique():\n",
        "                        print(f\"   {version}:\")\n",
        "                        print(f\"     1-day retention: {retention_1[version]*100:.2f}%\")\n",
        "                        print(f\"     7-day retention: {retention_7[version]*100:.2f}%\")\n",
        "\n",
        "            elif name == 'digital_ads':\n",
        "                # Digital Ads Conversion Analysis\n",
        "                print(\"💰 DIGITAL ADS CONVERSION STRUCTURE:\")\n",
        "                print(f\"Columns: {list(data.columns)}\")\n",
        "                print(f\"Total Records: {len(data):,}\")\n",
        "\n",
        "                # Campaign summary\n",
        "                if 'xyz_campaign_id' in data.columns:\n",
        "                    campaigns = data['xyz_campaign_id'].nunique()\n",
        "                    print(f\"   📊 Unique Campaigns: {campaigns}\")\n",
        "\n",
        "                # Conversion metrics\n",
        "                if 'Total_Conversion' in data.columns and 'Spent' in data.columns:\n",
        "                    total_conversions = data['Total_Conversion'].sum()\n",
        "                    total_spend = data['Spent'].sum()\n",
        "                    avg_cost_per_conversion = total_spend / total_conversions if total_conversions > 0 else 0\n",
        "\n",
        "                    print(f\"\\n💸 OVERALL PERFORMANCE:\")\n",
        "                    print(f\"   Total Conversions: {total_conversions:,}\")\n",
        "                    print(f\"   Total Spend: ${total_spend:,.2f}\")\n",
        "                    print(f\"   Avg Cost per Conversion: ${avg_cost_per_conversion:.2f}\")\n",
        "\n",
        "                # Demographic breakdown\n",
        "                if 'age' in data.columns and 'gender' in data.columns:\n",
        "                    print(f\"\\n👥 DEMOGRAPHIC BREAKDOWN:\")\n",
        "                    demo_performance = data.groupby(['age', 'gender']).agg({\n",
        "                        'Total_Conversion': 'sum',\n",
        "                        'Spent': 'sum'\n",
        "                    }).reset_index()\n",
        "                    demo_performance['cost_per_conversion'] = (\n",
        "                        demo_performance['Spent'] / demo_performance['Total_Conversion']\n",
        "                    ).round(2)\n",
        "\n",
        "                    best_performing = demo_performance.loc[\n",
        "                        demo_performance['cost_per_conversion'].idxmin()\n",
        "                    ]\n",
        "                    print(f\"   Best Performing: {best_performing['age']} {best_performing['gender']}\")\n",
        "                    print(f\"   Cost per Conversion: ${best_performing['cost_per_conversion']:.2f}\")\n",
        "\n",
        "# Initialize the framework with your data\n",
        "def initialize_ab_framework():\n",
        "    \"\"\"Initialize the A/B testing framework with your datasets\"\"\"\n",
        "\n",
        "    # Create framework instance\n",
        "    ab_tester = AdvancedABTesting()\n",
        "\n",
        "    # Load your datasets\n",
        "    if ab_tester.load_your_datasets():\n",
        "        print(\"\\n🎉 SUCCESS! Your A/B testing datasets are ready for analysis!\")\n",
        "\n",
        "        # Quick inspection of all datasets\n",
        "        ab_tester.inspect_dataset_structure()\n",
        "\n",
        "        return ab_tester\n",
        "    else:\n",
        "        print(\"\\n❌ Failed to load datasets. Please check your data paths.\")\n",
        "        return None\n",
        "\n",
        "# Usage example\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"🧪 ENHANCED A/B TESTING FRAMEWORK - CHUNK 1\")\n",
        "    print(\"Ready to initialize with your real datasets!\")\n",
        "    print(\"\\nUsage:\")\n",
        "    print(\"ab_tester = initialize_ab_framework()\")\n",
        "    print(\"ab_tester.inspect_dataset_structure('cookie_cats')\")  # Inspect specific dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ab_tester = initialize_ab_framework()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5iFPZajSEkM",
        "outputId": "1f2c2c25-20a9-4f6b-d80e-21099d67f90a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 ENHANCED A/B TESTING FRAMEWORK INITIALIZED\n",
            "=======================================================\n",
            "🎯 Designed for Your Real Datasets:\n",
            "   📊 A/B Testing Data (Facebook Ads)\n",
            "   🎮 Cookie Cats (Mobile Game Retention)\n",
            "   💰 Digital Ads (Conversion Tracking)\n",
            "=======================================================\n",
            "✅ Facebook Ads A/B Test Data Loaded\n",
            "   Control: (30, 10)\n",
            "   Test: (30, 10)\n",
            "✅ Cookie Cats Mobile Game A/B Test Loaded\n",
            "   Total Users: (90189, 5)\n",
            "   Versions: ['gate_30' 'gate_40']\n",
            "✅ Digital Ads Conversion Data Loaded\n",
            "   Records: (1143, 11)\n",
            "   Campaigns: 3\n",
            "\n",
            "📊 DATASET SUMMARY:\n",
            "   Total A/B Test Datasets: 3\n",
            "   ab_facebook: 60 total records\n",
            "   cookie_cats: 90,189 records\n",
            "   digital_ads: 1,143 records\n",
            "\n",
            "🎉 SUCCESS! Your A/B testing datasets are ready for analysis!\n",
            "\n",
            "🔍 INSPECTING DATASET: AB_FACEBOOK\n",
            "==================================================\n",
            "📊 FACEBOOK ADS A/B TEST STRUCTURE:\n",
            "Control Group Columns: ['Campaign Name', 'Date', 'Spend [USD]', '# of Impressions', 'Reach', '# of Website Clicks', '# of Searches', '# of View Content', '# of Add to Cart', '# of Purchase']\n",
            "Test Group Columns: ['Campaign Name', 'Date', 'Spend [USD]', '# of Impressions', 'Reach', '# of Website Clicks', '# of Searches', '# of View Content', '# of Add to Cart', '# of Purchase']\n",
            "\n",
            "📈 KEY METRICS AVAILABLE:\n",
            "   💰 Purchases (Control): 15161.0\n",
            "   💰 Purchases (Test): 15637\n",
            "   🖱️ Clicks (Control): 154303.0\n",
            "   🖱️ Clicks (Test): 180970\n",
            "\n",
            "🔍 INSPECTING DATASET: COOKIE_CATS\n",
            "==================================================\n",
            "🎮 COOKIE CATS MOBILE GAME STRUCTURE:\n",
            "Columns: ['userid', 'version', 'sum_gamerounds', 'retention_1', 'retention_7']\n",
            "Total Users: 90,189\n",
            "\n",
            "📱 VERSION DISTRIBUTION:\n",
            "   gate_40: 45,489 users (50.4%)\n",
            "   gate_30: 44,700 users (49.6%)\n",
            "\n",
            "📈 RETENTION RATES BY VERSION:\n",
            "   gate_30:\n",
            "     1-day retention: 44.82%\n",
            "     7-day retention: 19.02%\n",
            "   gate_40:\n",
            "     1-day retention: 44.23%\n",
            "     7-day retention: 18.20%\n",
            "\n",
            "🔍 INSPECTING DATASET: DIGITAL_ADS\n",
            "==================================================\n",
            "💰 DIGITAL ADS CONVERSION STRUCTURE:\n",
            "Columns: ['ad_id', 'xyz_campaign_id', 'fb_campaign_id', 'age', 'gender', 'interest', 'Impressions', 'Clicks', 'Spent', 'Total_Conversion', 'Approved_Conversion']\n",
            "Total Records: 1,143\n",
            "   📊 Unique Campaigns: 3\n",
            "\n",
            "💸 OVERALL PERFORMANCE:\n",
            "   Total Conversions: 3,264\n",
            "   Total Spend: $58,705.23\n",
            "   Avg Cost per Conversion: $17.99\n",
            "\n",
            "👥 DEMOGRAPHIC BREAKDOWN:\n",
            "   Best Performing: 30-34 M\n",
            "   Cost per Conversion: $9.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ab_tester.inspect_dataset_structure('cookie_cats')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc5V_gqBSEnC",
        "outputId": "17b91447-d14d-40ee-efa6-346ec1ac5298"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 INSPECTING DATASET: COOKIE_CATS\n",
            "==================================================\n",
            "🎮 COOKIE CATS MOBILE GAME STRUCTURE:\n",
            "Columns: ['userid', 'version', 'sum_gamerounds', 'retention_1', 'retention_7']\n",
            "Total Users: 90,189\n",
            "\n",
            "📱 VERSION DISTRIBUTION:\n",
            "   gate_40: 45,489 users (50.4%)\n",
            "   gate_30: 44,700 users (49.6%)\n",
            "\n",
            "📈 RETENTION RATES BY VERSION:\n",
            "   gate_30:\n",
            "     1-day retention: 44.82%\n",
            "     7-day retention: 19.02%\n",
            "   gate_40:\n",
            "     1-day retention: 44.23%\n",
            "     7-day retention: 18.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Size Calculation & Power Analysis"
      ],
      "metadata": {
        "id": "R0RoM1n4SqFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, initialize your ab_tester (from Chunk 1)\n",
        "ab_tester = initialize_ab_framework()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayv7AgpgSErS",
        "outputId": "90ed180a-010c-4cc0-8768-5d0be82897bc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 ENHANCED A/B TESTING FRAMEWORK INITIALIZED\n",
            "=======================================================\n",
            "🎯 Designed for Your Real Datasets:\n",
            "   📊 A/B Testing Data (Facebook Ads)\n",
            "   🎮 Cookie Cats (Mobile Game Retention)\n",
            "   💰 Digital Ads (Conversion Tracking)\n",
            "=======================================================\n",
            "✅ Facebook Ads A/B Test Data Loaded\n",
            "   Control: (30, 10)\n",
            "   Test: (30, 10)\n",
            "✅ Cookie Cats Mobile Game A/B Test Loaded\n",
            "   Total Users: (90189, 5)\n",
            "   Versions: ['gate_30' 'gate_40']\n",
            "✅ Digital Ads Conversion Data Loaded\n",
            "   Records: (1143, 11)\n",
            "   Campaigns: 3\n",
            "\n",
            "📊 DATASET SUMMARY:\n",
            "   Total A/B Test Datasets: 3\n",
            "   ab_facebook: 60 total records\n",
            "   cookie_cats: 90,189 records\n",
            "   digital_ads: 1,143 records\n",
            "\n",
            "🎉 SUCCESS! Your A/B testing datasets are ready for analysis!\n",
            "\n",
            "🔍 INSPECTING DATASET: AB_FACEBOOK\n",
            "==================================================\n",
            "📊 FACEBOOK ADS A/B TEST STRUCTURE:\n",
            "Control Group Columns: ['Campaign Name', 'Date', 'Spend [USD]', '# of Impressions', 'Reach', '# of Website Clicks', '# of Searches', '# of View Content', '# of Add to Cart', '# of Purchase']\n",
            "Test Group Columns: ['Campaign Name', 'Date', 'Spend [USD]', '# of Impressions', 'Reach', '# of Website Clicks', '# of Searches', '# of View Content', '# of Add to Cart', '# of Purchase']\n",
            "\n",
            "📈 KEY METRICS AVAILABLE:\n",
            "   💰 Purchases (Control): 15161.0\n",
            "   💰 Purchases (Test): 15637\n",
            "   🖱️ Clicks (Control): 154303.0\n",
            "   🖱️ Clicks (Test): 180970\n",
            "\n",
            "🔍 INSPECTING DATASET: COOKIE_CATS\n",
            "==================================================\n",
            "🎮 COOKIE CATS MOBILE GAME STRUCTURE:\n",
            "Columns: ['userid', 'version', 'sum_gamerounds', 'retention_1', 'retention_7']\n",
            "Total Users: 90,189\n",
            "\n",
            "📱 VERSION DISTRIBUTION:\n",
            "   gate_40: 45,489 users (50.4%)\n",
            "   gate_30: 44,700 users (49.6%)\n",
            "\n",
            "📈 RETENTION RATES BY VERSION:\n",
            "   gate_30:\n",
            "     1-day retention: 44.82%\n",
            "     7-day retention: 19.02%\n",
            "   gate_40:\n",
            "     1-day retention: 44.23%\n",
            "     7-day retention: 18.20%\n",
            "\n",
            "🔍 INSPECTING DATASET: DIGITAL_ADS\n",
            "==================================================\n",
            "💰 DIGITAL ADS CONVERSION STRUCTURE:\n",
            "Columns: ['ad_id', 'xyz_campaign_id', 'fb_campaign_id', 'age', 'gender', 'interest', 'Impressions', 'Clicks', 'Spent', 'Total_Conversion', 'Approved_Conversion']\n",
            "Total Records: 1,143\n",
            "   📊 Unique Campaigns: 3\n",
            "\n",
            "💸 OVERALL PERFORMANCE:\n",
            "   Total Conversions: 3,264\n",
            "   Total Spend: $58,705.23\n",
            "   Avg Cost per Conversion: $17.99\n",
            "\n",
            "👥 DEMOGRAPHIC BREAKDOWN:\n",
            "   Best Performing: 30-34 M\n",
            "   Cost per Conversion: $9.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DIRECT IMPLEMENTATION (NO IMPORT NEEDED)\n",
        "# Run this code directly in your notebook after initializing ab_tester\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from statsmodels.stats.power import zt_ind_solve_power\n",
        "from statsmodels.stats.proportion import proportions_ztest, proportion_effectsize\n",
        "\n",
        "def inspect_dataset_columns(ab_tester, dataset_name):\n",
        "    \"\"\"Inspect actual column names in your datasets\"\"\"\n",
        "    print(f\"🔍 INSPECTING ACTUAL COLUMNS IN {dataset_name.upper()}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    if dataset_name not in ab_tester.datasets:\n",
        "        print(f\"❌ Dataset '{dataset_name}' not loaded\")\n",
        "        return None\n",
        "\n",
        "    if dataset_name == 'cookie_cats':\n",
        "        data = ab_tester.datasets['cookie_cats']\n",
        "        print(f\"📊 Cookie Cats columns: {list(data.columns)}\")\n",
        "        print(f\"📊 Data shape: {data.shape}\")\n",
        "        print(f\"📊 Sample data:\\n{data.head()}\")\n",
        "        return list(data.columns)\n",
        "\n",
        "    elif dataset_name == 'ab_facebook':\n",
        "        control_data = ab_tester.datasets['ab_facebook']['control']\n",
        "        test_data = ab_tester.datasets['ab_facebook']['test']\n",
        "        print(f\"📊 Facebook Control columns: {list(control_data.columns)}\")\n",
        "        print(f\"📊 Facebook Test columns: {list(test_data.columns)}\")\n",
        "        print(f\"📊 Control shape: {control_data.shape}\")\n",
        "        print(f\"📊 Test shape: {test_data.shape}\")\n",
        "        print(f\"📊 Control sample:\\n{control_data.head()}\")\n",
        "        return list(control_data.columns)\n",
        "\n",
        "    elif dataset_name == 'digital_ads':\n",
        "        data = ab_tester.datasets['digital_ads']\n",
        "        print(f\"📊 Digital Ads columns: {list(data.columns)}\")\n",
        "        print(f\"📊 Data shape: {data.shape}\")\n",
        "        print(f\"📊 Sample data:\\n{data.head()}\")\n",
        "        return list(data.columns)\n",
        "\n",
        "    return None\n",
        "\n",
        "def get_baseline_rate_fixed(ab_tester, dataset_name, metric):\n",
        "    \"\"\"Extract baseline conversion rate with robust column handling\"\"\"\n",
        "\n",
        "    if dataset_name == 'cookie_cats':\n",
        "        data = ab_tester.datasets['cookie_cats']\n",
        "\n",
        "        if metric == 'retention_1':\n",
        "            if 'retention_1' in data.columns:\n",
        "                return data['retention_1'].mean()\n",
        "            else:\n",
        "                print(f\"❌ Column 'retention_1' not found in cookie_cats\")\n",
        "                return None\n",
        "        elif metric == 'retention_7':\n",
        "            if 'retention_7' in data.columns:\n",
        "                return data['retention_7'].mean()\n",
        "            else:\n",
        "                print(f\"❌ Column 'retention_7' not found in cookie_cats\")\n",
        "                return None\n",
        "\n",
        "    elif dataset_name == 'ab_facebook':\n",
        "        control_data = ab_tester.datasets['ab_facebook']['control']\n",
        "\n",
        "        # Check for different possible column names\n",
        "        purchase_columns = ['# of Purchase', 'purchases', 'Purchase', 'conversions']\n",
        "        click_columns = ['# of Website Clicks', 'clicks', 'Clicks', 'website_clicks']\n",
        "        impression_columns = ['# of Impressions', 'impressions', 'Impressions', 'reach']\n",
        "\n",
        "        # Find actual column names\n",
        "        actual_purchase_col = None\n",
        "        actual_click_col = None\n",
        "        actual_impression_col = None\n",
        "\n",
        "        for col in purchase_columns:\n",
        "            if col in control_data.columns:\n",
        "                actual_purchase_col = col\n",
        "                break\n",
        "\n",
        "        for col in click_columns:\n",
        "            if col in control_data.columns:\n",
        "                actual_click_col = col\n",
        "                break\n",
        "\n",
        "        for col in impression_columns:\n",
        "            if col in control_data.columns:\n",
        "                actual_impression_col = col\n",
        "                break\n",
        "\n",
        "        print(f\"📊 Found columns - Purchase: {actual_purchase_col}, Clicks: {actual_click_col}, Impressions: {actual_impression_col}\")\n",
        "\n",
        "        if metric == 'purchase_rate':\n",
        "            if actual_purchase_col and actual_impression_col:\n",
        "                total_purchases = control_data[actual_purchase_col].sum()\n",
        "                total_impressions = control_data[actual_impression_col].sum()\n",
        "                return total_purchases / total_impressions if total_impressions > 0 else 0\n",
        "            else:\n",
        "                print(f\"❌ Required columns not found for purchase_rate\")\n",
        "                return None\n",
        "\n",
        "        elif metric == 'click_rate':\n",
        "            if actual_click_col and actual_impression_col:\n",
        "                total_clicks = control_data[actual_click_col].sum()\n",
        "                total_impressions = control_data[actual_impression_col].sum()\n",
        "                return total_clicks / total_impressions if total_impressions > 0 else 0\n",
        "            else:\n",
        "                print(f\"❌ Required columns not found for click_rate\")\n",
        "                return None\n",
        "\n",
        "    elif dataset_name == 'digital_ads':\n",
        "        data = ab_tester.datasets['digital_ads']\n",
        "\n",
        "        # Check for different possible column names\n",
        "        conversion_columns = ['Total_Conversion', 'conversions', 'Conversions', 'total_conversions']\n",
        "        click_columns = ['Clicks', 'clicks', 'total_clicks']\n",
        "        impression_columns = ['Impressions', 'impressions', 'total_impressions']\n",
        "\n",
        "        actual_conversion_col = None\n",
        "        actual_click_col = None\n",
        "        actual_impression_col = None\n",
        "\n",
        "        for col in conversion_columns:\n",
        "            if col in data.columns:\n",
        "                actual_conversion_col = col\n",
        "                break\n",
        "\n",
        "        for col in click_columns:\n",
        "            if col in data.columns:\n",
        "                actual_click_col = col\n",
        "                break\n",
        "\n",
        "        for col in impression_columns:\n",
        "            if col in data.columns:\n",
        "                actual_impression_col = col\n",
        "                break\n",
        "\n",
        "        if metric == 'conversion_rate':\n",
        "            if actual_conversion_col and actual_impression_col:\n",
        "                total_conversions = data[actual_conversion_col].sum()\n",
        "                total_impressions = data[actual_impression_col].sum()\n",
        "                return total_conversions / total_impressions if total_impressions > 0 else 0\n",
        "            else:\n",
        "                print(f\"❌ Required columns not found for conversion_rate\")\n",
        "                return None\n",
        "\n",
        "        elif metric == 'click_rate':\n",
        "            if actual_click_col and actual_impression_col:\n",
        "                total_clicks = data[actual_click_col].sum()\n",
        "                total_impressions = data[actual_impression_col].sum()\n",
        "                return total_clicks / total_impressions if total_impressions > 0 else 0\n",
        "            else:\n",
        "                print(f\"❌ Required columns not found for click_rate\")\n",
        "                return None\n",
        "\n",
        "    return None\n",
        "\n",
        "def calculate_potential_impact_fixed(ab_tester, dataset_name, metric, mde):\n",
        "    \"\"\"Calculate potential business impact with robust column handling\"\"\"\n",
        "\n",
        "    impact = {}\n",
        "\n",
        "    try:\n",
        "        if dataset_name == 'cookie_cats':\n",
        "            total_users = len(ab_tester.datasets['cookie_cats'])\n",
        "            baseline_rate = get_baseline_rate_fixed(ab_tester, dataset_name, metric)\n",
        "\n",
        "            if baseline_rate:\n",
        "                current_retaining_users = total_users * baseline_rate\n",
        "                improved_retaining_users = total_users * baseline_rate * (1 + mde)\n",
        "                additional_users = improved_retaining_users - current_retaining_users\n",
        "\n",
        "                impact['Additional Retained Users'] = f\"{additional_users:,.0f} users\"\n",
        "                impact['Revenue Impact (est. $5/user)'] = f\"${additional_users * 5:,.0f}\"\n",
        "\n",
        "        elif dataset_name == 'ab_facebook':\n",
        "            control_data = ab_tester.datasets['ab_facebook']['control']\n",
        "\n",
        "            # Find spend column with multiple possible names\n",
        "            spend_columns = ['Spent', 'spend', 'cost', 'Cost', 'amount_spent']\n",
        "            purchase_columns = ['# of Purchase', 'purchases', 'Purchase', 'conversions']\n",
        "\n",
        "            actual_spend_col = None\n",
        "            actual_purchase_col = None\n",
        "\n",
        "            for col in spend_columns:\n",
        "                if col in control_data.columns:\n",
        "                    actual_spend_col = col\n",
        "                    break\n",
        "\n",
        "            for col in purchase_columns:\n",
        "                if col in control_data.columns:\n",
        "                    actual_purchase_col = col\n",
        "                    break\n",
        "\n",
        "            print(f\"📊 Found Facebook columns - Spend: {actual_spend_col}, Purchase: {actual_purchase_col}\")\n",
        "\n",
        "            if actual_purchase_col:\n",
        "                total_purchases = control_data[actual_purchase_col].sum()\n",
        "                improved_purchases = total_purchases * (1 + mde)\n",
        "                additional_purchases = improved_purchases - total_purchases\n",
        "\n",
        "                impact['Additional Purchases'] = f\"{additional_purchases:.0f} purchases\"\n",
        "\n",
        "                if actual_spend_col:\n",
        "                    total_spend = control_data[actual_spend_col].sum()\n",
        "                    current_cpa = total_spend / total_purchases if total_purchases > 0 else 0\n",
        "                    impact['Reduced CPA'] = f\"${current_cpa/(1+mde):.2f} (vs ${current_cpa:.2f})\"\n",
        "                else:\n",
        "                    impact['Note'] = \"Spend column not found - using purchase count only\"\n",
        "            else:\n",
        "                impact['Estimated Impact'] = f\"Improved performance by {mde*100:.1f}%\"\n",
        "\n",
        "        elif dataset_name == 'digital_ads':\n",
        "            data = ab_tester.datasets['digital_ads']\n",
        "\n",
        "            # Find relevant columns\n",
        "            conversion_columns = ['Total_Conversion', 'conversions', 'Conversions']\n",
        "\n",
        "            actual_conversion_col = None\n",
        "\n",
        "            for col in conversion_columns:\n",
        "                if col in data.columns:\n",
        "                    actual_conversion_col = col\n",
        "                    break\n",
        "\n",
        "            if actual_conversion_col:\n",
        "                total_conversions = data[actual_conversion_col].sum()\n",
        "                improved_conversions = total_conversions * (1 + mde)\n",
        "                additional_conversions = improved_conversions - total_conversions\n",
        "                avg_revenue_per_conversion = 50  # Estimate\n",
        "\n",
        "                impact['Additional Conversions'] = f\"{additional_conversions:.0f} conversions\"\n",
        "                impact['Additional Revenue (est.)'] = f\"${additional_conversions * avg_revenue_per_conversion:,.0f}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Warning: Could not calculate impact for {dataset_name}: {str(e)}\")\n",
        "        impact['Note'] = f\"Impact calculation needs column verification for {dataset_name}\"\n",
        "\n",
        "    return impact\n",
        "\n",
        "def calculate_sample_size_for_your_data_fixed(ab_tester, dataset_name='cookie_cats',\n",
        "                                            metric='retention_1', mde=0.15,\n",
        "                                            power=0.8, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Calculate required sample size based on YOUR actual dataset baselines\n",
        "    FIXED to handle actual column names\n",
        "    \"\"\"\n",
        "    print(\"🧮 CALCULATING SAMPLE SIZE USING YOUR REAL DATA\")\n",
        "    print(\"=\" * 55)\n",
        "\n",
        "    if dataset_name not in ab_tester.datasets:\n",
        "        print(f\"❌ Dataset '{dataset_name}' not loaded\")\n",
        "        return None\n",
        "\n",
        "    # First inspect the dataset to see actual columns\n",
        "    print(\"🔍 Checking dataset structure...\")\n",
        "    inspect_dataset_columns(ab_tester, dataset_name)\n",
        "\n",
        "    # Calculate baseline rate from your actual data\n",
        "    baseline_rate = get_baseline_rate_fixed(ab_tester, dataset_name, metric)\n",
        "\n",
        "    if baseline_rate is None:\n",
        "        print(f\"❌ Could not calculate baseline for {metric} in {dataset_name}\")\n",
        "        print(\"💡 Try inspecting the dataset first to see available columns\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\n📊 USING YOUR REAL DATA:\")\n",
        "    print(f\"   Dataset: {dataset_name}\")\n",
        "    print(f\"   Metric: {metric}\")\n",
        "    print(f\"   Current Baseline Rate: {baseline_rate*100:.2f}%\")\n",
        "\n",
        "    # Calculate effect size\n",
        "    new_rate = baseline_rate * (1 + mde)\n",
        "    effect_size = proportion_effectsize(baseline_rate, new_rate)\n",
        "\n",
        "    # Calculate required sample size per group\n",
        "    try:\n",
        "        sample_size = zt_ind_solve_power(\n",
        "            effect_size=effect_size,\n",
        "            power=power,\n",
        "            alpha=alpha,\n",
        "            alternative='two-sided'\n",
        "        )\n",
        "    except Exception as e:\n",
        "        # Fallback calculation\n",
        "        print(f\"⚠️ Using fallback calculation: {str(e)}\")\n",
        "        z_alpha = norm.ppf(1 - alpha/2)\n",
        "        z_beta = norm.ppf(power)\n",
        "        p_pooled = (baseline_rate + new_rate) / 2\n",
        "\n",
        "        sample_size = (\n",
        "            2 * p_pooled * (1 - p_pooled) * (z_alpha + z_beta)**2\n",
        "        ) / (baseline_rate - new_rate)**2\n",
        "\n",
        "    total_sample_size = sample_size * 2  # Both groups\n",
        "\n",
        "    # Calculate test duration estimates based on your data volume\n",
        "    if dataset_name == 'cookie_cats':\n",
        "        daily_traffic = len(ab_tester.datasets['cookie_cats']) / 30  # Assume 30 days\n",
        "    else:\n",
        "        daily_traffic = 1000  # Default\n",
        "\n",
        "    traffic_scenarios = {\n",
        "        'current_pace': daily_traffic,\n",
        "        'conservative_10pct': daily_traffic * 0.1,\n",
        "        'aggressive_50pct': daily_traffic * 0.5,\n",
        "        'maximum_100pct': daily_traffic\n",
        "    }\n",
        "\n",
        "    duration_estimates = {}\n",
        "    for scenario, daily_visitors in traffic_scenarios.items():\n",
        "        if daily_visitors > 0:\n",
        "            days_needed = total_sample_size / daily_visitors\n",
        "            duration_estimates[scenario] = days_needed\n",
        "\n",
        "    # Calculate expected outcomes\n",
        "    expected_improvement = mde * 100\n",
        "    potential_impact = calculate_potential_impact_fixed(ab_tester, dataset_name, metric, mde)\n",
        "\n",
        "    results = {\n",
        "        'dataset_used': dataset_name,\n",
        "        'metric_analyzed': metric,\n",
        "        'baseline_conversion_rate': baseline_rate * 100,\n",
        "        'target_conversion_rate': new_rate * 100,\n",
        "        'minimum_detectable_effect': mde * 100,\n",
        "        'statistical_power': power * 100,\n",
        "        'significance_level': alpha * 100,\n",
        "        'effect_size_cohens_h': effect_size,\n",
        "        'sample_size_per_group': int(sample_size),\n",
        "        'total_sample_size': int(total_sample_size),\n",
        "        'duration_estimates': duration_estimates,\n",
        "        'expected_improvement': expected_improvement,\n",
        "        'potential_business_impact': potential_impact\n",
        "    }\n",
        "\n",
        "    # Display detailed results\n",
        "    print(f\"\\n📈 SAMPLE SIZE ANALYSIS RESULTS:\")\n",
        "    print(f\"   🎯 Current Rate: {results['baseline_conversion_rate']:.2f}%\")\n",
        "    print(f\"   📊 Target Rate: {results['target_conversion_rate']:.2f}%\")\n",
        "    print(f\"   📈 Expected Improvement: +{results['expected_improvement']:.1f}%\")\n",
        "    print(f\"   ⚡ Statistical Power: {results['statistical_power']:.0f}%\")\n",
        "    print(f\"   🔍 Significance Level: {results['significance_level']:.1f}%\")\n",
        "    print(f\"   📏 Effect Size (Cohen's h): {results['effect_size_cohens_h']:.3f}\")\n",
        "    print(f\"   👥 Sample Size per Group: {results['sample_size_per_group']:,}\")\n",
        "    print(f\"   📊 Total Sample Size Needed: {results['total_sample_size']:,}\")\n",
        "\n",
        "    if duration_estimates:\n",
        "        print(f\"\\n⏱️ ESTIMATED TEST DURATION:\")\n",
        "        for scenario, days in duration_estimates.items():\n",
        "            scenario_name = scenario.replace('_', ' ').title()\n",
        "            if days < 365:  # Less than a year\n",
        "                print(f\"   {scenario_name}: {days:.0f} days\")\n",
        "            else:\n",
        "                print(f\"   {scenario_name}: {days/365:.1f} years\")\n",
        "\n",
        "    if potential_impact:\n",
        "        print(f\"\\n💰 POTENTIAL BUSINESS IMPACT:\")\n",
        "        for key, value in potential_impact.items():\n",
        "            print(f\"   {key}: {value}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# MAIN EXECUTION FUNCTION - RUN THIS\n",
        "def run_power_analysis_fixed(ab_tester):\n",
        "    \"\"\"Run power analysis with fixed column handling - NO IMPORTS NEEDED\"\"\"\n",
        "\n",
        "    print(\"🚀 RUNNING FIXED POWER ANALYSIS ON YOUR REAL DATA\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # First, inspect all your datasets\n",
        "    print(\"\\n🔍 INSPECTING ALL YOUR DATASETS\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    for dataset_name in ab_tester.datasets.keys():\n",
        "        inspect_dataset_columns(ab_tester, dataset_name)\n",
        "        print(\"\\n\" + \"-\" * 50)\n",
        "\n",
        "    # Analyze Cookie Cats retention optimization\n",
        "    print(\"\\n1️⃣ COOKIE CATS RETENTION OPTIMIZATION (FIXED)\")\n",
        "    print(\"=\" * 50)\n",
        "    cookie_results = calculate_sample_size_for_your_data_fixed(\n",
        "        ab_tester,\n",
        "        dataset_name='cookie_cats',\n",
        "        metric='retention_1',\n",
        "        mde=0.15,  # 15% improvement target\n",
        "        power=0.8\n",
        "    )\n",
        "\n",
        "    # Try Facebook Ads analysis with error handling\n",
        "    if 'ab_facebook' in ab_tester.datasets:\n",
        "        print(\"\\n2️⃣ FACEBOOK ADS OPTIMIZATION (FIXED)\")\n",
        "        print(\"=\" * 40)\n",
        "        try:\n",
        "            facebook_results = calculate_sample_size_for_your_data_fixed(\n",
        "                ab_tester,\n",
        "                dataset_name='ab_facebook',\n",
        "                metric='purchase_rate',\n",
        "                mde=0.20,  # 20% improvement target\n",
        "                power=0.8\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Facebook analysis error: {str(e)}\")\n",
        "            facebook_results = None\n",
        "    else:\n",
        "        facebook_results = None\n",
        "\n",
        "    # Try Digital Ads analysis\n",
        "    if 'digital_ads' in ab_tester.datasets:\n",
        "        print(\"\\n3️⃣ DIGITAL ADS OPTIMIZATION (FIXED)\")\n",
        "        print(\"=\" * 35)\n",
        "        try:\n",
        "            digital_results = calculate_sample_size_for_your_data_fixed(\n",
        "                ab_tester,\n",
        "                dataset_name='digital_ads',\n",
        "                metric='conversion_rate',\n",
        "                mde=0.15,\n",
        "                power=0.8\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Digital ads analysis error: {str(e)}\")\n",
        "            digital_results = None\n",
        "    else:\n",
        "        digital_results = None\n",
        "\n",
        "    print(f\"\\n🎉 POWER ANALYSIS COMPLETE!\")\n",
        "    print(f\"✅ Cookie Cats: {'Success' if cookie_results else 'Failed'}\")\n",
        "    print(f\"✅ Facebook Ads: {'Success' if facebook_results else 'Failed'}\")\n",
        "    print(f\"✅ Digital Ads: {'Success' if digital_results else 'Failed'}\")\n",
        "\n",
        "    return {\n",
        "        'cookie_cats_sample_size': cookie_results,\n",
        "        'facebook_ads_sample_size': facebook_results,\n",
        "        'digital_ads_sample_size': digital_results\n",
        "    }\n",
        "\n",
        "# ==========================================\n",
        "# RUN THIS CODE DIRECTLY IN YOUR NOTEBOOK\n",
        "# ==========================================\n",
        "\n",
        "print(\"📊 CHUNK 2 - DIRECT IMPLEMENTATION READY\")\n",
        "print(\"✅ No imports needed - run directly in your environment\")\n",
        "print(\"\\nUsage:\")\n",
        "print(\"# Assuming you have ab_tester initialized from Chunk 1:\")\n",
        "print(\"power_results = run_power_analysis_fixed(ab_tester)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5w-UNQ4aRmq",
        "outputId": "5b3614d8-1629-4033-b894-3b16f2fb3cd6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 CHUNK 2 - DIRECT IMPLEMENTATION READY\n",
            "✅ No imports needed - run directly in your environment\n",
            "\n",
            "Usage:\n",
            "# Assuming you have ab_tester initialized from Chunk 1:\n",
            "power_results = run_power_analysis_fixed(ab_tester)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "power_results = run_power_analysis_fixed(ab_tester)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZY3YRbraTkY",
        "outputId": "7671f7fc-c4af-4a68-d9b6-02adfdf80bab"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 RUNNING FIXED POWER ANALYSIS ON YOUR REAL DATA\n",
            "============================================================\n",
            "\n",
            "🔍 INSPECTING ALL YOUR DATASETS\n",
            "========================================\n",
            "🔍 INSPECTING ACTUAL COLUMNS IN AB_FACEBOOK\n",
            "==================================================\n",
            "📊 Facebook Control columns: ['Campaign Name', 'Date', 'Spend [USD]', '# of Impressions', 'Reach', '# of Website Clicks', '# of Searches', '# of View Content', '# of Add to Cart', '# of Purchase']\n",
            "📊 Facebook Test columns: ['Campaign Name', 'Date', 'Spend [USD]', '# of Impressions', 'Reach', '# of Website Clicks', '# of Searches', '# of View Content', '# of Add to Cart', '# of Purchase']\n",
            "📊 Control shape: (30, 10)\n",
            "📊 Test shape: (30, 10)\n",
            "📊 Control sample:\n",
            "      Campaign Name       Date  Spend [USD]  # of Impressions     Reach  \\\n",
            "0  Control Campaign  1.08.2019         2280           82702.0   56930.0   \n",
            "1  Control Campaign  2.08.2019         1757          121040.0  102513.0   \n",
            "2  Control Campaign  3.08.2019         2343          131711.0  110862.0   \n",
            "3  Control Campaign  4.08.2019         1940           72878.0   61235.0   \n",
            "4  Control Campaign  5.08.2019         1835               NaN       NaN   \n",
            "\n",
            "   # of Website Clicks  # of Searches  # of View Content  # of Add to Cart  \\\n",
            "0               7016.0         2290.0             2159.0            1819.0   \n",
            "1               8110.0         2033.0             1841.0            1219.0   \n",
            "2               6508.0         1737.0             1549.0            1134.0   \n",
            "3               3065.0         1042.0              982.0            1183.0   \n",
            "4                  NaN            NaN                NaN               NaN   \n",
            "\n",
            "   # of Purchase  \n",
            "0          618.0  \n",
            "1          511.0  \n",
            "2          372.0  \n",
            "3          340.0  \n",
            "4            NaN  \n",
            "\n",
            "--------------------------------------------------\n",
            "🔍 INSPECTING ACTUAL COLUMNS IN COOKIE_CATS\n",
            "==================================================\n",
            "📊 Cookie Cats columns: ['userid', 'version', 'sum_gamerounds', 'retention_1', 'retention_7']\n",
            "📊 Data shape: (90189, 5)\n",
            "📊 Sample data:\n",
            "   userid  version  sum_gamerounds  retention_1  retention_7\n",
            "0     116  gate_30               3        False        False\n",
            "1     337  gate_30              38         True        False\n",
            "2     377  gate_40             165         True        False\n",
            "3     483  gate_40               1        False        False\n",
            "4     488  gate_40             179         True         True\n",
            "\n",
            "--------------------------------------------------\n",
            "🔍 INSPECTING ACTUAL COLUMNS IN DIGITAL_ADS\n",
            "==================================================\n",
            "📊 Digital Ads columns: ['ad_id', 'xyz_campaign_id', 'fb_campaign_id', 'age', 'gender', 'interest', 'Impressions', 'Clicks', 'Spent', 'Total_Conversion', 'Approved_Conversion']\n",
            "📊 Data shape: (1143, 11)\n",
            "📊 Sample data:\n",
            "    ad_id  xyz_campaign_id  fb_campaign_id    age gender  interest  \\\n",
            "0  708746              916          103916  30-34      M        15   \n",
            "1  708749              916          103917  30-34      M        16   \n",
            "2  708771              916          103920  30-34      M        20   \n",
            "3  708815              916          103928  30-34      M        28   \n",
            "4  708818              916          103928  30-34      M        28   \n",
            "\n",
            "   Impressions  Clicks  Spent  Total_Conversion  Approved_Conversion  \n",
            "0         7350       1   1.43                 2                    1  \n",
            "1        17861       2   1.82                 2                    0  \n",
            "2          693       0   0.00                 1                    0  \n",
            "3         4259       1   1.25                 1                    0  \n",
            "4         4133       1   1.29                 1                    1  \n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "1️⃣ COOKIE CATS RETENTION OPTIMIZATION (FIXED)\n",
            "==================================================\n",
            "🧮 CALCULATING SAMPLE SIZE USING YOUR REAL DATA\n",
            "=======================================================\n",
            "🔍 Checking dataset structure...\n",
            "🔍 INSPECTING ACTUAL COLUMNS IN COOKIE_CATS\n",
            "==================================================\n",
            "📊 Cookie Cats columns: ['userid', 'version', 'sum_gamerounds', 'retention_1', 'retention_7']\n",
            "📊 Data shape: (90189, 5)\n",
            "📊 Sample data:\n",
            "   userid  version  sum_gamerounds  retention_1  retention_7\n",
            "0     116  gate_30               3        False        False\n",
            "1     337  gate_30              38         True        False\n",
            "2     377  gate_40             165         True        False\n",
            "3     483  gate_40               1        False        False\n",
            "4     488  gate_40             179         True         True\n",
            "\n",
            "📊 USING YOUR REAL DATA:\n",
            "   Dataset: cookie_cats\n",
            "   Metric: retention_1\n",
            "   Current Baseline Rate: 44.52%\n",
            "\n",
            "📈 SAMPLE SIZE ANALYSIS RESULTS:\n",
            "   🎯 Current Rate: 44.52%\n",
            "   📊 Target Rate: 51.20%\n",
            "   📈 Expected Improvement: +15.0%\n",
            "   ⚡ Statistical Power: 80%\n",
            "   🔍 Significance Level: 5.0%\n",
            "   📏 Effect Size (Cohen's h): -0.134\n",
            "   👥 Sample Size per Group: 877\n",
            "   📊 Total Sample Size Needed: 1,754\n",
            "\n",
            "⏱️ ESTIMATED TEST DURATION:\n",
            "   Current Pace: 1 days\n",
            "   Conservative 10Pct: 6 days\n",
            "   Aggressive 50Pct: 1 days\n",
            "   Maximum 100Pct: 1 days\n",
            "\n",
            "💰 POTENTIAL BUSINESS IMPACT:\n",
            "   Additional Retained Users: 6,023 users\n",
            "   Revenue Impact (est. $5/user): $30,115\n",
            "\n",
            "2️⃣ FACEBOOK ADS OPTIMIZATION (FIXED)\n",
            "========================================\n",
            "🧮 CALCULATING SAMPLE SIZE USING YOUR REAL DATA\n",
            "=======================================================\n",
            "🔍 Checking dataset structure...\n",
            "🔍 INSPECTING ACTUAL COLUMNS IN AB_FACEBOOK\n",
            "==================================================\n",
            "📊 Facebook Control columns: ['Campaign Name', 'Date', 'Spend [USD]', '# of Impressions', 'Reach', '# of Website Clicks', '# of Searches', '# of View Content', '# of Add to Cart', '# of Purchase']\n",
            "📊 Facebook Test columns: ['Campaign Name', 'Date', 'Spend [USD]', '# of Impressions', 'Reach', '# of Website Clicks', '# of Searches', '# of View Content', '# of Add to Cart', '# of Purchase']\n",
            "📊 Control shape: (30, 10)\n",
            "📊 Test shape: (30, 10)\n",
            "📊 Control sample:\n",
            "      Campaign Name       Date  Spend [USD]  # of Impressions     Reach  \\\n",
            "0  Control Campaign  1.08.2019         2280           82702.0   56930.0   \n",
            "1  Control Campaign  2.08.2019         1757          121040.0  102513.0   \n",
            "2  Control Campaign  3.08.2019         2343          131711.0  110862.0   \n",
            "3  Control Campaign  4.08.2019         1940           72878.0   61235.0   \n",
            "4  Control Campaign  5.08.2019         1835               NaN       NaN   \n",
            "\n",
            "   # of Website Clicks  # of Searches  # of View Content  # of Add to Cart  \\\n",
            "0               7016.0         2290.0             2159.0            1819.0   \n",
            "1               8110.0         2033.0             1841.0            1219.0   \n",
            "2               6508.0         1737.0             1549.0            1134.0   \n",
            "3               3065.0         1042.0              982.0            1183.0   \n",
            "4                  NaN            NaN                NaN               NaN   \n",
            "\n",
            "   # of Purchase  \n",
            "0          618.0  \n",
            "1          511.0  \n",
            "2          372.0  \n",
            "3          340.0  \n",
            "4            NaN  \n",
            "📊 Found columns - Purchase: # of Purchase, Clicks: # of Website Clicks, Impressions: # of Impressions\n",
            "\n",
            "📊 USING YOUR REAL DATA:\n",
            "   Dataset: ab_facebook\n",
            "   Metric: purchase_rate\n",
            "   Current Baseline Rate: 0.48%\n",
            "📊 Found Facebook columns - Spend: None, Purchase: # of Purchase\n",
            "\n",
            "📈 SAMPLE SIZE ANALYSIS RESULTS:\n",
            "   🎯 Current Rate: 0.48%\n",
            "   📊 Target Rate: 0.57%\n",
            "   📈 Expected Improvement: +20.0%\n",
            "   ⚡ Statistical Power: 80%\n",
            "   🔍 Significance Level: 5.0%\n",
            "   📏 Effect Size (Cohen's h): -0.013\n",
            "   👥 Sample Size per Group: 89,806\n",
            "   📊 Total Sample Size Needed: 179,613\n",
            "\n",
            "⏱️ ESTIMATED TEST DURATION:\n",
            "   Current Pace: 180 days\n",
            "   Conservative 10Pct: 4.9 years\n",
            "   Aggressive 50Pct: 359 days\n",
            "   Maximum 100Pct: 180 days\n",
            "\n",
            "💰 POTENTIAL BUSINESS IMPACT:\n",
            "   Additional Purchases: 3032 purchases\n",
            "   Note: Spend column not found - using purchase count only\n",
            "\n",
            "3️⃣ DIGITAL ADS OPTIMIZATION (FIXED)\n",
            "===================================\n",
            "🧮 CALCULATING SAMPLE SIZE USING YOUR REAL DATA\n",
            "=======================================================\n",
            "🔍 Checking dataset structure...\n",
            "🔍 INSPECTING ACTUAL COLUMNS IN DIGITAL_ADS\n",
            "==================================================\n",
            "📊 Digital Ads columns: ['ad_id', 'xyz_campaign_id', 'fb_campaign_id', 'age', 'gender', 'interest', 'Impressions', 'Clicks', 'Spent', 'Total_Conversion', 'Approved_Conversion']\n",
            "📊 Data shape: (1143, 11)\n",
            "📊 Sample data:\n",
            "    ad_id  xyz_campaign_id  fb_campaign_id    age gender  interest  \\\n",
            "0  708746              916          103916  30-34      M        15   \n",
            "1  708749              916          103917  30-34      M        16   \n",
            "2  708771              916          103920  30-34      M        20   \n",
            "3  708815              916          103928  30-34      M        28   \n",
            "4  708818              916          103928  30-34      M        28   \n",
            "\n",
            "   Impressions  Clicks  Spent  Total_Conversion  Approved_Conversion  \n",
            "0         7350       1   1.43                 2                    1  \n",
            "1        17861       2   1.82                 2                    0  \n",
            "2          693       0   0.00                 1                    0  \n",
            "3         4259       1   1.25                 1                    0  \n",
            "4         4133       1   1.29                 1                    1  \n",
            "\n",
            "📊 USING YOUR REAL DATA:\n",
            "   Dataset: digital_ads\n",
            "   Metric: conversion_rate\n",
            "   Current Baseline Rate: 0.00%\n",
            "\n",
            "📈 SAMPLE SIZE ANALYSIS RESULTS:\n",
            "   🎯 Current Rate: 0.00%\n",
            "   📊 Target Rate: 0.00%\n",
            "   📈 Expected Improvement: +15.0%\n",
            "   ⚡ Statistical Power: 80%\n",
            "   🔍 Significance Level: 5.0%\n",
            "   📏 Effect Size (Cohen's h): -0.001\n",
            "   👥 Sample Size per Group: 48,982,518\n",
            "   📊 Total Sample Size Needed: 97,965,036\n",
            "\n",
            "⏱️ ESTIMATED TEST DURATION:\n",
            "   Current Pace: 268.4 years\n",
            "   Conservative 10Pct: 2684.0 years\n",
            "   Aggressive 50Pct: 536.8 years\n",
            "   Maximum 100Pct: 268.4 years\n",
            "\n",
            "💰 POTENTIAL BUSINESS IMPACT:\n",
            "   Additional Conversions: 490 conversions\n",
            "   Additional Revenue (est.): $24,480\n",
            "\n",
            "🎉 POWER ANALYSIS COMPLETE!\n",
            "✅ Cookie Cats: Success\n",
            "✅ Facebook Ads: Success\n",
            "✅ Digital Ads: Success\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Sequential Testing & Early Stopping"
      ],
      "metadata": {
        "id": "EN1isJd9dj09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHUNK 3 - WORKING REAL DATA ANALYSIS\n",
        "# Fixed to actually produce output with your real datasets\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from statsmodels.stats.proportion import proportions_ztest, proportion_effectsize\n",
        "\n",
        "def analyze_cookie_cats_real_ab_test(ab_tester):\n",
        "    \"\"\"\n",
        "    Analyze the actual Cookie Cats A/B test (gate_30 vs gate_40)\n",
        "    NO simulation - uses your real 90K users data\n",
        "    \"\"\"\n",
        "    print(\"🎮 COOKIE CATS REAL A/B TEST ANALYSIS\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"📊 Using your actual 90,189 users data\")\n",
        "\n",
        "    if 'cookie_cats' not in ab_tester.datasets:\n",
        "        print(\"❌ Cookie Cats dataset not loaded\")\n",
        "        return None\n",
        "\n",
        "    data = ab_tester.datasets['cookie_cats']\n",
        "\n",
        "    # Real A/B test groups\n",
        "    control_group = data[data['version'] == 'gate_30']\n",
        "    treatment_group = data[data['version'] == 'gate_40']\n",
        "\n",
        "    print(f\"\\n📊 REAL DATA SUMMARY:\")\n",
        "    print(f\"   Control (gate_30): {len(control_group):,} users\")\n",
        "    print(f\"   Treatment (gate_40): {len(treatment_group):,} users\")\n",
        "    print(f\"   Total users: {len(data):,}\")\n",
        "\n",
        "    # Analyze both retention metrics using REAL data\n",
        "    results = {}\n",
        "\n",
        "    # 1-day retention analysis\n",
        "    print(f\"\\n📈 1-DAY RETENTION ANALYSIS:\")\n",
        "    control_retention_1 = control_group['retention_1'].sum()\n",
        "    control_total_1 = len(control_group)\n",
        "    treatment_retention_1 = treatment_group['retention_1'].sum()\n",
        "    treatment_total_1 = len(treatment_group)\n",
        "\n",
        "    control_rate_1 = control_retention_1 / control_total_1\n",
        "    treatment_rate_1 = treatment_retention_1 / treatment_total_1\n",
        "    relative_change_1 = ((treatment_rate_1 - control_rate_1) / control_rate_1) * 100\n",
        "\n",
        "    # Statistical test\n",
        "    z_stat_1, p_value_1 = proportions_ztest(\n",
        "        [control_retention_1, treatment_retention_1],\n",
        "        [control_total_1, treatment_total_1]\n",
        "    )\n",
        "\n",
        "    print(f\"   Control Rate: {control_rate_1*100:.2f}% ({control_retention_1:,}/{control_total_1:,})\")\n",
        "    print(f\"   Treatment Rate: {treatment_rate_1*100:.2f}% ({treatment_retention_1:,}/{treatment_total_1:,})\")\n",
        "    print(f\"   Relative Change: {relative_change_1:+.1f}%\")\n",
        "    print(f\"   Z-statistic: {z_stat_1:.3f}\")\n",
        "    print(f\"   P-value: {p_value_1:.4f}\")\n",
        "    print(f\"   Statistically Significant: {'✅ Yes' if p_value_1 < 0.05 else '❌ No'}\")\n",
        "\n",
        "    results['retention_1'] = {\n",
        "        'control_rate': control_rate_1,\n",
        "        'treatment_rate': treatment_rate_1,\n",
        "        'relative_change': relative_change_1,\n",
        "        'z_statistic': z_stat_1,\n",
        "        'p_value': p_value_1,\n",
        "        'significant': p_value_1 < 0.05,\n",
        "        'control_users': control_total_1,\n",
        "        'treatment_users': treatment_total_1\n",
        "    }\n",
        "\n",
        "    # 7-day retention analysis\n",
        "    print(f\"\\n📈 7-DAY RETENTION ANALYSIS:\")\n",
        "    control_retention_7 = control_group['retention_7'].sum()\n",
        "    treatment_retention_7 = treatment_group['retention_7'].sum()\n",
        "\n",
        "    control_rate_7 = control_retention_7 / control_total_1\n",
        "    treatment_rate_7 = treatment_retention_7 / treatment_total_1\n",
        "    relative_change_7 = ((treatment_rate_7 - control_rate_7) / control_rate_7) * 100\n",
        "\n",
        "    # Statistical test\n",
        "    z_stat_7, p_value_7 = proportions_ztest(\n",
        "        [control_retention_7, treatment_retention_7],\n",
        "        [control_total_1, treatment_total_1]\n",
        "    )\n",
        "\n",
        "    print(f\"   Control Rate: {control_rate_7*100:.2f}% ({control_retention_7:,}/{control_total_1:,})\")\n",
        "    print(f\"   Treatment Rate: {treatment_rate_7*100:.2f}% ({treatment_retention_7:,}/{treatment_total_1:,})\")\n",
        "    print(f\"   Relative Change: {relative_change_7:+.1f}%\")\n",
        "    print(f\"   Z-statistic: {z_stat_7:.3f}\")\n",
        "    print(f\"   P-value: {p_value_7:.4f}\")\n",
        "    print(f\"   Statistically Significant: {'✅ Yes' if p_value_7 < 0.05 else '❌ No'}\")\n",
        "\n",
        "    results['retention_7'] = {\n",
        "        'control_rate': control_rate_7,\n",
        "        'treatment_rate': treatment_rate_7,\n",
        "        'relative_change': relative_change_7,\n",
        "        'z_statistic': z_stat_7,\n",
        "        'p_value': p_value_7,\n",
        "        'significant': p_value_7 < 0.05,\n",
        "        'control_users': control_total_1,\n",
        "        'treatment_users': treatment_total_1\n",
        "    }\n",
        "\n",
        "    # Business impact calculation\n",
        "    print(f\"\\n💰 BUSINESS IMPACT CALCULATION:\")\n",
        "    if relative_change_1 > 0:\n",
        "        total_users = len(data)\n",
        "        additional_retained_1 = total_users * control_rate_1 * (relative_change_1 / 100)\n",
        "        revenue_impact_1 = additional_retained_1 * 5  # $5 per retained user\n",
        "\n",
        "        print(f\"   1-day retention improvement: +{relative_change_1:.1f}%\")\n",
        "        print(f\"   Additional retained users: {additional_retained_1:,.0f}\")\n",
        "        print(f\"   Estimated revenue impact: ${revenue_impact_1:,.0f}\")\n",
        "\n",
        "        results['business_impact'] = {\n",
        "            'additional_users': additional_retained_1,\n",
        "            'revenue_impact': revenue_impact_1,\n",
        "            'retention_improvement': relative_change_1\n",
        "        }\n",
        "\n",
        "    print(f\"\\n🎯 DATA SOURCE: 100% Real Cookie Cats A/B Test Data\")\n",
        "    print(f\"   ✅ No synthetic data used\")\n",
        "    print(f\"   ✅ No simulation applied\")\n",
        "    print(f\"   ✅ Actual user behavior analysis\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def analyze_facebook_ads_real_ab_test(ab_tester):\n",
        "    \"\"\"\n",
        "    Analyze the actual Facebook Ads A/B test\n",
        "    Uses your real control vs test campaign data\n",
        "    \"\"\"\n",
        "    print(\"\\n💰 FACEBOOK ADS REAL A/B TEST ANALYSIS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    if 'ab_facebook' not in ab_tester.datasets:\n",
        "        print(\"❌ Facebook Ads dataset not loaded\")\n",
        "        return None\n",
        "\n",
        "    control_data = ab_tester.datasets['ab_facebook']['control']\n",
        "    test_data = ab_tester.datasets['ab_facebook']['test']\n",
        "\n",
        "    print(f\"📊 REAL FACEBOOK ADS DATA:\")\n",
        "    print(f\"   Control campaigns: {len(control_data)}\")\n",
        "    print(f\"   Test campaigns: {len(test_data)}\")\n",
        "    print(f\"   Columns: {list(control_data.columns)}\")\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # Find the correct column names\n",
        "    purchase_col = None\n",
        "    click_col = None\n",
        "    impression_col = None\n",
        "\n",
        "    # Check for purchase columns\n",
        "    for col in ['# of Purchase', 'purchases', 'Purchase']:\n",
        "        if col in control_data.columns:\n",
        "            purchase_col = col\n",
        "            break\n",
        "\n",
        "    # Check for click columns\n",
        "    for col in ['# of Website Clicks', 'clicks', 'Clicks']:\n",
        "        if col in control_data.columns:\n",
        "            click_col = col\n",
        "            break\n",
        "\n",
        "    # Check for impression columns\n",
        "    for col in ['# of Impressions', 'impressions', 'Impressions']:\n",
        "        if col in control_data.columns:\n",
        "            impression_col = col\n",
        "            break\n",
        "\n",
        "    print(f\"\\n📊 FOUND COLUMNS:\")\n",
        "    print(f\"   Purchase: {purchase_col}\")\n",
        "    print(f\"   Clicks: {click_col}\")\n",
        "    print(f\"   Impressions: {impression_col}\")\n",
        "\n",
        "    # Analyze purchase rates if data available\n",
        "    if purchase_col and impression_col:\n",
        "        print(f\"\\n📈 PURCHASE RATE ANALYSIS:\")\n",
        "\n",
        "        control_purchases = control_data[purchase_col].sum()\n",
        "        control_impressions = control_data[impression_col].sum()\n",
        "        test_purchases = test_data[purchase_col].sum()\n",
        "        test_impressions = test_data[impression_col].sum()\n",
        "\n",
        "        control_purchase_rate = control_purchases / control_impressions if control_impressions > 0 else 0\n",
        "        test_purchase_rate = test_purchases / test_impressions if test_impressions > 0 else 0\n",
        "        relative_change = ((test_purchase_rate - control_purchase_rate) / control_purchase_rate * 100) if control_purchase_rate > 0 else 0\n",
        "\n",
        "        print(f\"   Control: {control_purchases:,} purchases / {control_impressions:,} impressions = {control_purchase_rate*100:.4f}%\")\n",
        "        print(f\"   Test: {test_purchases:,} purchases / {test_impressions:,} impressions = {test_purchase_rate*100:.4f}%\")\n",
        "        print(f\"   Relative Change: {relative_change:+.1f}%\")\n",
        "\n",
        "        # Statistical test\n",
        "        if control_impressions > 0 and test_impressions > 0:\n",
        "            z_stat, p_value = proportions_ztest(\n",
        "                [control_purchases, test_purchases],\n",
        "                [control_impressions, test_impressions]\n",
        "            )\n",
        "            print(f\"   Z-statistic: {z_stat:.3f}\")\n",
        "            print(f\"   P-value: {p_value:.4f}\")\n",
        "            print(f\"   Statistically Significant: {'✅ Yes' if p_value < 0.05 else '❌ No'}\")\n",
        "\n",
        "            results['purchase_rate'] = {\n",
        "                'control_rate': control_purchase_rate,\n",
        "                'test_rate': test_purchase_rate,\n",
        "                'relative_change': relative_change,\n",
        "                'z_statistic': z_stat,\n",
        "                'p_value': p_value,\n",
        "                'significant': p_value < 0.05\n",
        "            }\n",
        "\n",
        "    # Analyze click rates if data available\n",
        "    if click_col and impression_col:\n",
        "        print(f\"\\n🖱️ CLICK RATE ANALYSIS:\")\n",
        "\n",
        "        control_clicks = control_data[click_col].sum()\n",
        "        test_clicks = test_data[click_col].sum()\n",
        "\n",
        "        control_click_rate = control_clicks / control_impressions if control_impressions > 0 else 0\n",
        "        test_click_rate = test_clicks / test_impressions if test_impressions > 0 else 0\n",
        "        relative_change_clicks = ((test_click_rate - control_click_rate) / control_click_rate * 100) if control_click_rate > 0 else 0\n",
        "\n",
        "        print(f\"   Control: {control_clicks:,} clicks / {control_impressions:,} impressions = {control_click_rate*100:.4f}%\")\n",
        "        print(f\"   Test: {test_clicks:,} clicks / {test_impressions:,} impressions = {test_click_rate*100:.4f}%\")\n",
        "        print(f\"   Relative Change: {relative_change_clicks:+.1f}%\")\n",
        "\n",
        "        # Statistical test\n",
        "        if control_impressions > 0 and test_impressions > 0:\n",
        "            z_stat_clicks, p_value_clicks = proportions_ztest(\n",
        "                [control_clicks, test_clicks],\n",
        "                [control_impressions, test_impressions]\n",
        "            )\n",
        "            print(f\"   Z-statistic: {z_stat_clicks:.3f}\")\n",
        "            print(f\"   P-value: {p_value_clicks:.4f}\")\n",
        "            print(f\"   Statistically Significant: {'✅ Yes' if p_value_clicks < 0.05 else '❌ No'}\")\n",
        "\n",
        "            results['click_rate'] = {\n",
        "                'control_rate': control_click_rate,\n",
        "                'test_rate': test_click_rate,\n",
        "                'relative_change': relative_change_clicks,\n",
        "                'z_statistic': z_stat_clicks,\n",
        "                'p_value': p_value_clicks,\n",
        "                'significant': p_value_clicks < 0.05\n",
        "            }\n",
        "\n",
        "    print(f\"\\n🎯 DATA SOURCE: 100% Real Facebook Ads A/B Test Data\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def multiple_testing_correction_real_data(ab_tester):\n",
        "    \"\"\"\n",
        "    Apply multiple testing corrections to your REAL A/B test results\n",
        "    No synthetic data - uses actual p-values from your tests\n",
        "    \"\"\"\n",
        "    print(\"\\n🔬 MULTIPLE TESTING CORRECTION - REAL DATA\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Collect real p-values from your actual A/B tests\n",
        "    real_p_values = {}\n",
        "\n",
        "    # Get Cookie Cats results\n",
        "    cookie_results = analyze_cookie_cats_real_ab_test(ab_tester)\n",
        "    if cookie_results:\n",
        "        real_p_values['cookie_cats_retention_1'] = cookie_results['retention_1']['p_value']\n",
        "        real_p_values['cookie_cats_retention_7'] = cookie_results['retention_7']['p_value']\n",
        "\n",
        "    # Get Facebook Ads results\n",
        "    facebook_results = analyze_facebook_ads_real_ab_test(ab_tester)\n",
        "    if facebook_results:\n",
        "        if 'purchase_rate' in facebook_results:\n",
        "            real_p_values['facebook_purchase_rate'] = facebook_results['purchase_rate']['p_value']\n",
        "        if 'click_rate' in facebook_results:\n",
        "            real_p_values['facebook_click_rate'] = facebook_results['click_rate']['p_value']\n",
        "\n",
        "    if not real_p_values:\n",
        "        print(\"❌ No real A/B test results available for correction\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\n📊 REAL P-VALUES FROM YOUR TESTS:\")\n",
        "    for test_name, p_val in real_p_values.items():\n",
        "        significant = \"✅\" if p_val < 0.05 else \"❌\"\n",
        "        print(f\"   {test_name}: p = {p_val:.4f} {significant}\")\n",
        "\n",
        "    # Apply Bonferroni correction\n",
        "    n_tests = len(real_p_values)\n",
        "    bonferroni_alpha = 0.05 / n_tests\n",
        "\n",
        "    print(f\"\\n🔬 BONFERRONI CORRECTION:\")\n",
        "    print(f\"   Number of tests: {n_tests}\")\n",
        "    print(f\"   Original α: 0.05\")\n",
        "    print(f\"   Corrected α: {bonferroni_alpha:.4f}\")\n",
        "\n",
        "    bonferroni_significant = []\n",
        "    for test_name, p_val in real_p_values.items():\n",
        "        significant = p_val < bonferroni_alpha\n",
        "        bonferroni_significant.append(significant)\n",
        "        status = \"✅ Significant\" if significant else \"❌ Not Significant\"\n",
        "        print(f\"   {test_name}: {status}\")\n",
        "\n",
        "    # Apply Benjamini-Hochberg correction\n",
        "    from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "    p_values_list = list(real_p_values.values())\n",
        "    test_names_list = list(real_p_values.keys())\n",
        "\n",
        "    bh_significant, bh_p_corrected, _, _ = multipletests(\n",
        "        p_values_list,\n",
        "        alpha=0.05,\n",
        "        method='fdr_bh'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n🔬 BENJAMINI-HOCHBERG CORRECTION (FDR):\")\n",
        "    for i, test_name in enumerate(test_names_list):\n",
        "        status = \"✅ Significant\" if bh_significant[i] else \"❌ Not Significant\"\n",
        "        print(f\"   {test_name}: {status} (corrected p = {bh_p_corrected[i]:.4f})\")\n",
        "\n",
        "    # Summary\n",
        "    original_significant = sum(1 for p in p_values_list if p < 0.05)\n",
        "    bonferroni_count = sum(bonferroni_significant)\n",
        "    bh_count = sum(bh_significant)\n",
        "\n",
        "    print(f\"\\n📊 CORRECTION SUMMARY:\")\n",
        "    print(f\"   Original significant tests: {original_significant}/{n_tests}\")\n",
        "    print(f\"   Bonferroni significant: {bonferroni_count}/{n_tests}\")\n",
        "    print(f\"   Benjamini-Hochberg significant: {bh_count}/{n_tests}\")\n",
        "\n",
        "    print(f\"\\n🎯 DATA SOURCE: 100% Real A/B Test P-values\")\n",
        "    print(f\"   ✅ No synthetic p-values\")\n",
        "    print(f\"   ✅ Actual statistical test results\")\n",
        "\n",
        "    return {\n",
        "        'original_p_values': real_p_values,\n",
        "        'bonferroni_alpha': bonferroni_alpha,\n",
        "        'bonferroni_significant': bonferroni_significant,\n",
        "        'bh_significant': bh_significant.tolist(),\n",
        "        'bh_p_corrected': bh_p_corrected.tolist(),\n",
        "        'summary': {\n",
        "            'original_significant': original_significant,\n",
        "            'bonferroni_significant': bonferroni_count,\n",
        "            'bh_significant': bh_count,\n",
        "            'total_tests': n_tests\n",
        "        }\n",
        "    }\n",
        "\n",
        "def run_complete_real_data_analysis(ab_tester):\n",
        "    \"\"\"\n",
        "    Run complete A/B testing analysis using ONLY your real datasets\n",
        "    NO synthetic data, NO simulation - 100% real analysis\n",
        "    \"\"\"\n",
        "    print(\"🚀 COMPLETE REAL DATA A/B TESTING ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"🎯 Using ONLY your actual datasets\")\n",
        "    print(\"❌ No synthetic data\")\n",
        "    print(\"❌ No simulation\")\n",
        "    print(\"✅ 100% real user behavior analysis\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # 1. Cookie Cats Real Analysis\n",
        "    print(\"\\n1️⃣ COOKIE CATS ANALYSIS\")\n",
        "    print(\"=\" * 30)\n",
        "    cookie_results = analyze_cookie_cats_real_ab_test(ab_tester)\n",
        "    if cookie_results:\n",
        "        results['cookie_cats'] = cookie_results\n",
        "\n",
        "    # 2. Facebook Ads Real Analysis\n",
        "    print(\"\\n2️⃣ FACEBOOK ADS ANALYSIS\")\n",
        "    print(\"=\" * 30)\n",
        "    facebook_results = analyze_facebook_ads_real_ab_test(ab_tester)\n",
        "    if facebook_results:\n",
        "        results['facebook_ads'] = facebook_results\n",
        "\n",
        "    # 3. Multiple Testing Correction\n",
        "    print(\"\\n3️⃣ MULTIPLE TESTING CORRECTION\")\n",
        "    print(\"=\" * 35)\n",
        "    correction_results = multiple_testing_correction_real_data(ab_tester)\n",
        "    if correction_results:\n",
        "        results['multiple_testing'] = correction_results\n",
        "\n",
        "    # 4. Summary\n",
        "    print(\"\\n🎉 COMPLETE ANALYSIS SUMMARY\")\n",
        "    print(\"=\" * 35)\n",
        "\n",
        "    total_tests = 0\n",
        "    significant_tests = 0\n",
        "\n",
        "    if 'cookie_cats' in results:\n",
        "        if results['cookie_cats']['retention_1']['significant']:\n",
        "            print(\"✅ Cookie Cats 1-day retention: SIGNIFICANT improvement\")\n",
        "            significant_tests += 1\n",
        "        else:\n",
        "            print(\"❌ Cookie Cats 1-day retention: Not significant\")\n",
        "        total_tests += 1\n",
        "\n",
        "        if results['cookie_cats']['retention_7']['significant']:\n",
        "            print(\"✅ Cookie Cats 7-day retention: SIGNIFICANT improvement\")\n",
        "            significant_tests += 1\n",
        "        else:\n",
        "            print(\"❌ Cookie Cats 7-day retention: Not significant\")\n",
        "        total_tests += 1\n",
        "\n",
        "    if 'facebook_ads' in results:\n",
        "        for metric, result in results['facebook_ads'].items():\n",
        "            if result['significant']:\n",
        "                print(f\"✅ Facebook Ads {metric}: SIGNIFICANT improvement\")\n",
        "                significant_tests += 1\n",
        "            else:\n",
        "                print(f\"❌ Facebook Ads {metric}: Not significant\")\n",
        "            total_tests += 1\n",
        "\n",
        "    print(f\"\\n📊 FINAL RESULTS:\")\n",
        "    print(f\"   Total A/B tests analyzed: {total_tests}\")\n",
        "    print(f\"   Statistically significant: {significant_tests}\")\n",
        "    print(f\"   Success rate: {(significant_tests/total_tests)*100:.1f}%\" if total_tests > 0 else \"   No tests completed\")\n",
        "\n",
        "    print(f\"\\n🎯 DATA AUTHENTICITY:\")\n",
        "    print(f\"   ✅ Real datasets used: {len(ab_tester.datasets)}\")\n",
        "    print(f\"   ✅ Real users analyzed: 90,000+ (Cookie Cats)\")\n",
        "    print(f\"   ✅ Real campaign data: Facebook Ads A/B test\")\n",
        "    print(f\"   ❌ Synthetic data: 0%\")\n",
        "    print(f\"   ❌ Simulated data: 0%\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# ==========================================\n",
        "# MAIN EXECUTION - RUN THIS\n",
        "# ==========================================\n",
        "\n",
        "print(\"🎮 CHUNK 3 - REAL DATA A/B TESTING ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "print(\"✅ Fixed to produce actual output\")\n",
        "print(\"✅ Uses only your real datasets\")\n",
        "print(\"✅ No synthetic or simulated data\")\n",
        "print(\"\\nUsage:\")\n",
        "print(\"# Run this to analyze your real A/B tests:\")\n",
        "print(\"real_results = run_complete_real_data_analysis(ab_tester)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWmh4psFTD6d",
        "outputId": "df15fde9-924d-4675-9cf8-37e864926ba7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎮 CHUNK 3 - REAL DATA A/B TESTING ANALYSIS\n",
            "==================================================\n",
            "✅ Fixed to produce actual output\n",
            "✅ Uses only your real datasets\n",
            "✅ No synthetic or simulated data\n",
            "\n",
            "Usage:\n",
            "# Run this to analyze your real A/B tests:\n",
            "real_results = run_complete_real_data_analysis(ab_tester)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_results = run_complete_real_data_analysis(ab_tester)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szz0Cz7Eds6u",
        "outputId": "a578fdfb-c622-414d-d00a-24b099dc4122"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 COMPLETE REAL DATA A/B TESTING ANALYSIS\n",
            "============================================================\n",
            "🎯 Using ONLY your actual datasets\n",
            "❌ No synthetic data\n",
            "❌ No simulation\n",
            "✅ 100% real user behavior analysis\n",
            "============================================================\n",
            "\n",
            "1️⃣ COOKIE CATS ANALYSIS\n",
            "==============================\n",
            "🎮 COOKIE CATS REAL A/B TEST ANALYSIS\n",
            "==================================================\n",
            "📊 Using your actual 90,189 users data\n",
            "\n",
            "📊 REAL DATA SUMMARY:\n",
            "   Control (gate_30): 44,700 users\n",
            "   Treatment (gate_40): 45,489 users\n",
            "   Total users: 90,189\n",
            "\n",
            "📈 1-DAY RETENTION ANALYSIS:\n",
            "   Control Rate: 44.82% (20,034/44,700)\n",
            "   Treatment Rate: 44.23% (20,119/45,489)\n",
            "   Relative Change: -1.3%\n",
            "   Z-statistic: 1.784\n",
            "   P-value: 0.0744\n",
            "   Statistically Significant: ❌ No\n",
            "\n",
            "📈 7-DAY RETENTION ANALYSIS:\n",
            "   Control Rate: 19.02% (8,502/44,700)\n",
            "   Treatment Rate: 18.20% (8,279/45,489)\n",
            "   Relative Change: -4.3%\n",
            "   Z-statistic: 3.164\n",
            "   P-value: 0.0016\n",
            "   Statistically Significant: ✅ Yes\n",
            "\n",
            "💰 BUSINESS IMPACT CALCULATION:\n",
            "\n",
            "🎯 DATA SOURCE: 100% Real Cookie Cats A/B Test Data\n",
            "   ✅ No synthetic data used\n",
            "   ✅ No simulation applied\n",
            "   ✅ Actual user behavior analysis\n",
            "\n",
            "2️⃣ FACEBOOK ADS ANALYSIS\n",
            "==============================\n",
            "\n",
            "💰 FACEBOOK ADS REAL A/B TEST ANALYSIS\n",
            "==================================================\n",
            "📊 REAL FACEBOOK ADS DATA:\n",
            "   Control campaigns: 30\n",
            "   Test campaigns: 30\n",
            "   Columns: ['Campaign Name', 'Date', 'Spend [USD]', '# of Impressions', 'Reach', '# of Website Clicks', '# of Searches', '# of View Content', '# of Add to Cart', '# of Purchase']\n",
            "\n",
            "📊 FOUND COLUMNS:\n",
            "   Purchase: # of Purchase\n",
            "   Clicks: # of Website Clicks\n",
            "   Impressions: # of Impressions\n",
            "\n",
            "📈 PURCHASE RATE ANALYSIS:\n",
            "   Control: 15,161.0 purchases / 3,177,233.0 impressions = 0.4772%\n",
            "   Test: 15,637 purchases / 2,237,544 impressions = 0.6988%\n",
            "   Relative Change: +46.5%\n",
            "   Z-statistic: -33.775\n",
            "   P-value: 0.0000\n",
            "   Statistically Significant: ✅ Yes\n",
            "\n",
            "🖱️ CLICK RATE ANALYSIS:\n",
            "   Control: 154,303.0 clicks / 3,177,233.0 impressions = 4.8565%\n",
            "   Test: 180,970 clicks / 2,237,544 impressions = 8.0879%\n",
            "   Relative Change: +66.5%\n",
            "   Z-statistic: -153.630\n",
            "   P-value: 0.0000\n",
            "   Statistically Significant: ✅ Yes\n",
            "\n",
            "🎯 DATA SOURCE: 100% Real Facebook Ads A/B Test Data\n",
            "\n",
            "3️⃣ MULTIPLE TESTING CORRECTION\n",
            "===================================\n",
            "\n",
            "🔬 MULTIPLE TESTING CORRECTION - REAL DATA\n",
            "==================================================\n",
            "🎮 COOKIE CATS REAL A/B TEST ANALYSIS\n",
            "==================================================\n",
            "📊 Using your actual 90,189 users data\n",
            "\n",
            "📊 REAL DATA SUMMARY:\n",
            "   Control (gate_30): 44,700 users\n",
            "   Treatment (gate_40): 45,489 users\n",
            "   Total users: 90,189\n",
            "\n",
            "📈 1-DAY RETENTION ANALYSIS:\n",
            "   Control Rate: 44.82% (20,034/44,700)\n",
            "   Treatment Rate: 44.23% (20,119/45,489)\n",
            "   Relative Change: -1.3%\n",
            "   Z-statistic: 1.784\n",
            "   P-value: 0.0744\n",
            "   Statistically Significant: ❌ No\n",
            "\n",
            "📈 7-DAY RETENTION ANALYSIS:\n",
            "   Control Rate: 19.02% (8,502/44,700)\n",
            "   Treatment Rate: 18.20% (8,279/45,489)\n",
            "   Relative Change: -4.3%\n",
            "   Z-statistic: 3.164\n",
            "   P-value: 0.0016\n",
            "   Statistically Significant: ✅ Yes\n",
            "\n",
            "💰 BUSINESS IMPACT CALCULATION:\n",
            "\n",
            "🎯 DATA SOURCE: 100% Real Cookie Cats A/B Test Data\n",
            "   ✅ No synthetic data used\n",
            "   ✅ No simulation applied\n",
            "   ✅ Actual user behavior analysis\n",
            "\n",
            "💰 FACEBOOK ADS REAL A/B TEST ANALYSIS\n",
            "==================================================\n",
            "📊 REAL FACEBOOK ADS DATA:\n",
            "   Control campaigns: 30\n",
            "   Test campaigns: 30\n",
            "   Columns: ['Campaign Name', 'Date', 'Spend [USD]', '# of Impressions', 'Reach', '# of Website Clicks', '# of Searches', '# of View Content', '# of Add to Cart', '# of Purchase']\n",
            "\n",
            "📊 FOUND COLUMNS:\n",
            "   Purchase: # of Purchase\n",
            "   Clicks: # of Website Clicks\n",
            "   Impressions: # of Impressions\n",
            "\n",
            "📈 PURCHASE RATE ANALYSIS:\n",
            "   Control: 15,161.0 purchases / 3,177,233.0 impressions = 0.4772%\n",
            "   Test: 15,637 purchases / 2,237,544 impressions = 0.6988%\n",
            "   Relative Change: +46.5%\n",
            "   Z-statistic: -33.775\n",
            "   P-value: 0.0000\n",
            "   Statistically Significant: ✅ Yes\n",
            "\n",
            "🖱️ CLICK RATE ANALYSIS:\n",
            "   Control: 154,303.0 clicks / 3,177,233.0 impressions = 4.8565%\n",
            "   Test: 180,970 clicks / 2,237,544 impressions = 8.0879%\n",
            "   Relative Change: +66.5%\n",
            "   Z-statistic: -153.630\n",
            "   P-value: 0.0000\n",
            "   Statistically Significant: ✅ Yes\n",
            "\n",
            "🎯 DATA SOURCE: 100% Real Facebook Ads A/B Test Data\n",
            "\n",
            "📊 REAL P-VALUES FROM YOUR TESTS:\n",
            "   cookie_cats_retention_1: p = 0.0744 ❌\n",
            "   cookie_cats_retention_7: p = 0.0016 ✅\n",
            "   facebook_purchase_rate: p = 0.0000 ✅\n",
            "   facebook_click_rate: p = 0.0000 ✅\n",
            "\n",
            "🔬 BONFERRONI CORRECTION:\n",
            "   Number of tests: 4\n",
            "   Original α: 0.05\n",
            "   Corrected α: 0.0125\n",
            "   cookie_cats_retention_1: ❌ Not Significant\n",
            "   cookie_cats_retention_7: ✅ Significant\n",
            "   facebook_purchase_rate: ✅ Significant\n",
            "   facebook_click_rate: ✅ Significant\n",
            "\n",
            "🔬 BENJAMINI-HOCHBERG CORRECTION (FDR):\n",
            "   cookie_cats_retention_1: ❌ Not Significant (corrected p = 0.0744)\n",
            "   cookie_cats_retention_7: ✅ Significant (corrected p = 0.0021)\n",
            "   facebook_purchase_rate: ✅ Significant (corrected p = 0.0000)\n",
            "   facebook_click_rate: ✅ Significant (corrected p = 0.0000)\n",
            "\n",
            "📊 CORRECTION SUMMARY:\n",
            "   Original significant tests: 3/4\n",
            "   Bonferroni significant: 3/4\n",
            "   Benjamini-Hochberg significant: 3/4\n",
            "\n",
            "🎯 DATA SOURCE: 100% Real A/B Test P-values\n",
            "   ✅ No synthetic p-values\n",
            "   ✅ Actual statistical test results\n",
            "\n",
            "🎉 COMPLETE ANALYSIS SUMMARY\n",
            "===================================\n",
            "❌ Cookie Cats 1-day retention: Not significant\n",
            "✅ Cookie Cats 7-day retention: SIGNIFICANT improvement\n",
            "✅ Facebook Ads purchase_rate: SIGNIFICANT improvement\n",
            "✅ Facebook Ads click_rate: SIGNIFICANT improvement\n",
            "\n",
            "📊 FINAL RESULTS:\n",
            "   Total A/B tests analyzed: 4\n",
            "   Statistically significant: 3\n",
            "   Success rate: 75.0%\n",
            "\n",
            "🎯 DATA AUTHENTICITY:\n",
            "   ✅ Real datasets used: 3\n",
            "   ✅ Real users analyzed: 90,000+ (Cookie Cats)\n",
            "   ✅ Real campaign data: Facebook Ads A/B test\n",
            "   ❌ Synthetic data: 0%\n",
            "   ❌ Simulated data: 0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CcjkBT-rds9k"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "susuXP3xds_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian A/B Testing Analysis"
      ],
      "metadata": {
        "id": "sAQJVKYnUKaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHUNK 4: BAYESIAN A/B TESTING ANALYSIS\n",
        "# Probabilistic approach to A/B testing with your real datasets\n",
        "\n",
        "def add_bayesian_methods(ab_tester_class):\n",
        "    \"\"\"Add Bayesian analysis methods to the AdvancedABTesting class\"\"\"\n",
        "\n",
        "    def bayesian_ab_analysis(self, dataset_name, metric,\n",
        "                           prior_alpha=1, prior_beta=1,\n",
        "                           n_simulations=100000, credible_interval=0.95):\n",
        "        \"\"\"\n",
        "        Comprehensive Bayesian A/B testing analysis using Beta-Binomial conjugate priors\n",
        "\n",
        "        Parameters:\n",
        "        - dataset_name: Your dataset ('cookie_cats', 'ab_facebook', 'digital_ads')\n",
        "        - metric: The metric to analyze\n",
        "        - prior_alpha, prior_beta: Beta prior parameters (uninformative by default)\n",
        "        - n_simulations: Monte Carlo simulations for probability calculations\n",
        "        - credible_interval: Credible interval width (e.g., 0.95 for 95% CI)\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"🔮 BAYESIAN A/B TEST ANALYSIS\")\n",
        "        print(\"=\" * 45)\n",
        "        print(f\"Dataset: {dataset_name} | Metric: {metric}\")\n",
        "\n",
        "        # Extract control and treatment data\n",
        "        control_data, treatment_data = self._extract_ab_data(dataset_name, metric)\n",
        "\n",
        "        if control_data is None or treatment_data is None:\n",
        "            print(\"❌ Could not extract A/B test data\")\n",
        "            return None\n",
        "\n",
        "        control_conversions = control_data['conversions']\n",
        "        control_total = control_data['total']\n",
        "        treatment_conversions = treatment_data['conversions']\n",
        "        treatment_total = treatment_data['total']\n",
        "\n",
        "        print(f\"📊 DATA SUMMARY:\")\n",
        "        print(f\"   Control: {control_conversions}/{control_total} conversions ({control_conversions/control_total*100:.2f}%)\")\n",
        "        print(f\"   Treatment: {treatment_conversions}/{treatment_total} conversions ({treatment_conversions/treatment_total*100:.2f}%)\")\n",
        "\n",
        "        # Calculate posterior parameters using Beta-Binomial conjugacy\n",
        "        control_alpha_post = prior_alpha + control_conversions\n",
        "        control_beta_post = prior_beta + control_total - control_conversions\n",
        "\n",
        "        treatment_alpha_post = prior_alpha + treatment_conversions\n",
        "        treatment_beta_post = prior_beta + treatment_total - treatment_conversions\n",
        "\n",
        "        # Posterior means (expected conversion rates)\n",
        "        control_mean = control_alpha_post / (control_alpha_post + control_beta_post)\n",
        "        treatment_mean = treatment_alpha_post / (treatment_alpha_post + treatment_beta_post)\n",
        "\n",
        "        print(f\"\\n🎯 POSTERIOR ESTIMATES:\")\n",
        "        print(f\"   Control Rate: {control_mean*100:.2f}%\")\n",
        "        print(f\"   Treatment Rate: {treatment_mean*100:.2f}%\")\n",
        "        print(f\"   Relative Improvement: {((treatment_mean - control_mean)/control_mean)*100:+.1f}%\")\n",
        "\n",
        "        # Monte Carlo simulation for probability calculations\n",
        "        np.random.seed(42)  # For reproducibility\n",
        "\n",
        "        # Sample from posterior distributions\n",
        "        control_samples = np.random.beta(control_alpha_post, control_beta_post, n_simulations)\n",
        "        treatment_samples = np.random.beta(treatment_alpha_post, treatment_beta_post, n_simulations)\n",
        "\n",
        "        # Calculate key probabilities\n",
        "        prob_treatment_better = np.mean(treatment_samples > control_samples)\n",
        "        prob_control_better = 1 - prob_treatment_better\n",
        "\n",
        "        # Expected loss calculations (decision theory)\n",
        "        loss_if_choose_treatment = np.mean(np.maximum(control_samples - treatment_samples, 0))\n",
        "        loss_if_choose_control = np.mean(np.maximum(treatment_samples - control_samples, 0))\n",
        "\n",
        "        # Relative improvement distribution\n",
        "        relative_improvement = (treatment_samples - control_samples) / control_samples\n",
        "\n",
        "        # Credible intervals\n",
        "        ci_lower = np.percentile(relative_improvement, (1-credible_interval)/2 * 100)\n",
        "        ci_upper = np.percentile(relative_improvement, (1-(1-credible_interval)/2) * 100)\n",
        "\n",
        "        # Risk assessments\n",
        "        prob_negative_effect = np.mean(relative_improvement < 0) * 100\n",
        "        prob_small_effect = np.mean(np.abs(relative_improvement) < 0.01) * 100  # <1% change\n",
        "        prob_medium_effect = np.mean((relative_improvement >= 0.01) & (relative_improvement < 0.1)) * 100  # 1-10%\n",
        "        prob_large_effect = np.mean(relative_improvement >= 0.1) * 100  # >10% improvement\n",
        "\n",
        "        # Value at Risk (VaR) - worst case scenarios\n",
        "        var_5pct = np.percentile(relative_improvement, 5) * 100  # 5% VaR\n",
        "        var_1pct = np.percentile(relative_improvement, 1) * 100  # 1% VaR\n",
        "\n",
        "        # Probability of practical significance (minimum worthwhile effect)\n",
        "        min_worthwhile_effect = 0.02  # 2% minimum improvement\n",
        "        prob_practically_significant = np.mean(relative_improvement > min_worthwhile_effect) * 100\n",
        "\n",
        "        # Decision recommendation based on thresholds\n",
        "        recommendation = self._get_bayesian_recommendation(\n",
        "            prob_treatment_better, loss_if_choose_treatment, loss_if_choose_control,\n",
        "            prob_practically_significant, prob_negative_effect\n",
        "        )\n",
        "\n",
        "        # Business impact estimation\n",
        "        business_impact = self._calculate_bayesian_business_impact(\n",
        "            dataset_name, metric, treatment_mean - control_mean, relative_improvement\n",
        "        )\n",
        "\n",
        "        results = {\n",
        "            'dataset': dataset_name,\n",
        "            'metric': metric,\n",
        "            'data_summary': {\n",
        "                'control_conversions': control_conversions,\n",
        "                'control_total': control_total,\n",
        "                'treatment_conversions': treatment_conversions,\n",
        "                'treatment_total': treatment_total\n",
        "            },\n",
        "            'posterior_estimates': {\n",
        "                'control_mean': control_mean * 100,\n",
        "                'treatment_mean': treatment_mean * 100,\n",
        "                'absolute_difference': (treatment_mean - control_mean) * 100,\n",
        "                'relative_improvement': ((treatment_mean - control_mean)/control_mean) * 100\n",
        "            },\n",
        "            'probabilities': {\n",
        "                'treatment_better': prob_treatment_better * 100,\n",
        "                'control_better': prob_control_better * 100,\n",
        "                'practically_significant': prob_practically_significant\n",
        "            },\n",
        "            'expected_loss': {\n",
        "                'if_choose_treatment': loss_if_choose_treatment * 100,\n",
        "                'if_choose_control': loss_if_choose_control * 100\n",
        "            },\n",
        "            'credible_interval': {\n",
        "                'lower': ci_lower * 100,\n",
        "                'upper': ci_upper * 100,\n",
        "                'width': credible_interval * 100\n",
        "            },\n",
        "            'risk_assessment': {\n",
        "                'prob_negative_effect': prob_negative_effect,\n",
        "                'prob_small_effect': prob_small_effect,\n",
        "                'prob_medium_effect': prob_medium_effect,\n",
        "                'prob_large_effect': prob_large_effect,\n",
        "                'var_5pct': var_5pct,\n",
        "                'var_1pct': var_1pct\n",
        "            },\n",
        "            'recommendation': recommendation,\n",
        "            'business_impact': business_impact,\n",
        "            'samples': {\n",
        "                'control': control_samples,\n",
        "                'treatment': treatment_samples,\n",
        "                'relative_improvement': relative_improvement\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Display comprehensive results\n",
        "        print(f\"\\n📈 PROBABILITY ANALYSIS:\")\n",
        "        print(f\"   Probability Treatment is Better: {results['probabilities']['treatment_better']:.1f}%\")\n",
        "        print(f\"   Probability Control is Better: {results['probabilities']['control_better']:.1f}%\")\n",
        "        print(f\"   Probability of Practical Significance: {results['probabilities']['practically_significant']:.1f}%\")\n",
        "\n",
        "        print(f\"\\n💰 EXPECTED LOSS (Decision Theory):\")\n",
        "        print(f\"   Loss if Choose Treatment: {results['expected_loss']['if_choose_treatment']:.3f}%\")\n",
        "        print(f\"   Loss if Choose Control: {results['expected_loss']['if_choose_control']:.3f}%\")\n",
        "\n",
        "        print(f\"\\n📊 {credible_interval*100:.0f}% CREDIBLE INTERVAL (Relative Improvement):\")\n",
        "        print(f\"   Lower Bound: {results['credible_interval']['lower']:+.1f}%\")\n",
        "        print(f\"   Upper Bound: {results['credible_interval']['upper']:+.1f}%\")\n",
        "\n",
        "        print(f\"\\n⚠️ RISK ASSESSMENT:\")\n",
        "        print(f\"   Risk of Negative Effect: {results['risk_assessment']['prob_negative_effect']:.1f}%\")\n",
        "        print(f\"   Probability of Small Effect (<1%): {results['risk_assessment']['prob_small_effect']:.1f}%\")\n",
        "        print(f\"   Probability of Medium Effect (1-10%): {results['risk_assessment']['prob_medium_effect']:.1f}%\")\n",
        "        print(f\"   Probability of Large Effect (>10%): {results['risk_assessment']['prob_large_effect']:.1f}%\")\n",
        "        print(f\"   Value at Risk (5%): {results['risk_assessment']['var_5pct']:+.1f}%\")\n",
        "        print(f\"   Value at Risk (1%): {results['risk_assessment']['var_1pct']:+.1f}%\")\n",
        "\n",
        "        print(f\"\\n🎯 BAYESIAN RECOMMENDATION: {results['recommendation']}\")\n",
        "\n",
        "        if business_impact:\n",
        "            print(f\"\\n💼 BUSINESS IMPACT ESTIMATION:\")\n",
        "            for key, value in business_impact.items():\n",
        "                print(f\"   {key}: {value}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _extract_ab_data(self, dataset_name, metric):\n",
        "        \"\"\"Extract control and treatment data for Bayesian analysis\"\"\"\n",
        "\n",
        "        if dataset_name == 'cookie_cats':\n",
        "            data = self.datasets['cookie_cats']\n",
        "\n",
        "            control_data = data[data['version'] == 'gate_30']\n",
        "            treatment_data = data[data['version'] == 'gate_40']\n",
        "\n",
        "            if metric == 'retention_1':\n",
        "                control_conversions = control_data['retention_1'].sum()\n",
        "                treatment_conversions = treatment_data['retention_1'].sum()\n",
        "            elif metric == 'retention_7':\n",
        "                control_conversions = control_data['retention_7'].sum()\n",
        "                treatment_conversions = treatment_data['retention_7'].sum()\n",
        "            else:\n",
        "                return None, None\n",
        "\n",
        "            return {\n",
        "                'conversions': control_conversions,\n",
        "                'total': len(control_data)\n",
        "            }, {\n",
        "                'conversions': treatment_conversions,\n",
        "                'total': len(treatment_data)\n",
        "            }\n",
        "\n",
        "        elif dataset_name == 'ab_facebook':\n",
        "            control_df = self.datasets['ab_facebook']['control']\n",
        "            treatment_df = self.datasets['ab_facebook']['test']\n",
        "\n",
        "            if metric == 'purchase_rate':\n",
        "                control_conversions = control_df['# of Purchase'].sum()\n",
        "                control_total = control_df['# of Impressions'].sum()\n",
        "                treatment_conversions = treatment_df['# of Purchase'].sum()\n",
        "                treatment_total = treatment_df['# of Impressions'].sum()\n",
        "            elif metric == 'click_rate':\n",
        "                control_conversions = control_df['# of Website Clicks'].sum()\n",
        "                control_total = control_df['# of Impressions'].sum()\n",
        "                treatment_conversions = treatment_df['# of Website Clicks'].sum()\n",
        "                treatment_total = treatment_df['# of Impressions'].sum()\n",
        "            else:\n",
        "                return None, None\n",
        "\n",
        "            return {\n",
        "                'conversions': control_conversions,\n",
        "                'total': control_total\n",
        "            }, {\n",
        "                'conversions': treatment_conversions,\n",
        "                'total': treatment_total\n",
        "            }\n",
        "\n",
        "        return None, None\n",
        "\n",
        "    def _get_bayesian_recommendation(self, prob_treatment_better, loss_treatment,\n",
        "                                   loss_control, prob_practical, prob_negative):\n",
        "        \"\"\"Generate Bayesian recommendation based on probabilities and losses\"\"\"\n",
        "\n",
        "        # Decision thresholds\n",
        "        high_confidence_threshold = 95  # 95% probability\n",
        "        medium_confidence_threshold = 80  # 80% probability\n",
        "        practical_significance_threshold = 70  # 70% probability\n",
        "        max_acceptable_risk = 20  # 20% risk of negative effect\n",
        "\n",
        "        if prob_treatment_better > high_confidence_threshold and prob_negative < max_acceptable_risk:\n",
        "            if prob_practical > practical_significance_threshold:\n",
        "                return \"🟢 STRONG RECOMMENDATION: Implement Treatment\"\n",
        "            else:\n",
        "                return \"🟡 WEAK POSITIVE: Implement Treatment (Low Practical Impact)\"\n",
        "        elif prob_treatment_better > medium_confidence_threshold and prob_negative < max_acceptable_risk:\n",
        "            return \"🟠 MODERATE RECOMMENDATION: Consider Implementing Treatment\"\n",
        "        elif prob_treatment_better < (100 - high_confidence_threshold):\n",
        "            return \"🔴 RECOMMENDATION: Keep Control (Treatment Likely Harmful)\"\n",
        "        else:\n",
        "            return \"⚪ INCONCLUSIVE: Collect More Data or Run Longer\"\n",
        "\n",
        "    def _calculate_bayesian_business_impact(self, dataset_name, metric, absolute_diff, rel_improvement_samples):\n",
        "        \"\"\"Calculate business impact using Bayesian posterior samples\"\"\"\n",
        "\n",
        "        impact = {}\n",
        "\n",
        "        if dataset_name == 'cookie_cats':\n",
        "            total_users = len(self.datasets['cookie_cats'])\n",
        "\n",
        "            # Calculate distribution of additional users\n",
        "            additional_users_samples = total_users * absolute_diff\n",
        "\n",
        "            # Revenue per user estimates\n",
        "            revenue_per_user = 5  # $5 lifetime value\n",
        "\n",
        "            # Calculate revenue impact distribution\n",
        "            revenue_impact_samples = additional_users_samples * revenue_per_user\n",
        "\n",
        "            impact['Expected Additional Users'] = f\"{np.mean(additional_users_samples):,.0f}\"\n",
        "            impact['95% CI Additional Users'] = f\"[{np.percentile(additional_users_samples, 2.5):,.0f}, {np.percentile(additional_users_samples, 97.5):,.0f}]\"\n",
        "            impact['Expected Revenue Impact'] = f\"${np.mean(revenue_impact_samples):,.0f}\"\n",
        "            impact['95% CI Revenue Impact'] = f\"[${np.percentile(revenue_impact_samples, 2.5):,.0f}, ${np.percentile(revenue_impact_samples, 97.5):,.0f}]\"\n",
        "            impact['Probability of Positive ROI'] = f\"{np.mean(revenue_impact_samples > 0)*100:.1f}%\"\n",
        "\n",
        "        elif dataset_name == 'ab_facebook':\n",
        "            control_data = self.datasets['ab_facebook']['control']\n",
        "            baseline_purchases = control_data['# of Purchase'].sum()\n",
        "\n",
        "            # Additional purchases distribution\n",
        "            additional_purchases_samples = baseline_purchases * rel_improvement_samples\n",
        "\n",
        "            # Revenue per purchase\n",
        "            revenue_per_purchase = 50  # $50 average order value\n",
        "\n",
        "            revenue_impact_samples = additional_purchases_samples * revenue_per_purchase\n",
        "\n",
        "            impact['Expected Additional Purchases'] = f\"{np.mean(additional_purchases_samples):.1f}\"\n",
        "            impact['95% CI Additional Purchases'] = f\"[{np.percentile(additional_purchases_samples, 2.5):.1f}, {np.percentile(additional_purchases_samples, 97.5):.1f}]\"\n",
        "            impact['Expected Revenue Impact'] = f\"${np.mean(revenue_impact_samples):,.0f}\"\n",
        "            impact['Probability of Revenue Increase'] = f\"{np.mean(revenue_impact_samples > 0)*100:.1f}%\"\n",
        "\n",
        "        return impact\n",
        "\n",
        "    def bayesian_multivariate_analysis(self, dataset_name, metrics_list):\n",
        "        \"\"\"Analyze multiple metrics simultaneously using Bayesian approach\"\"\"\n",
        "\n",
        "        print(\"🔮 BAYESIAN MULTIVARIATE ANALYSIS\")\n",
        "        print(\"=\" * 45)\n",
        "        print(f\"Dataset: {dataset_name}\")\n",
        "        print(f\"Metrics: {', '.join(metrics_list)}\")\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        for metric in metrics_list:\n",
        "            print(f\"\\n--- Analyzing {metric} ---\")\n",
        "            result = self.bayesian_ab_analysis(dataset_name, metric, n_simulations=50000)\n",
        "            if result:\n",
        "                results[metric] = result\n",
        "\n",
        "        # Cross-metric analysis\n",
        "        if len(results) > 1:\n",
        "            print(f\"\\n🔄 CROSS-METRIC ANALYSIS:\")\n",
        "\n",
        "            metric_names = list(results.keys())\n",
        "            for i, metric1 in enumerate(metric_names):\n",
        "                for metric2 in metric_names[i+1:]:\n",
        "\n",
        "                    # Calculate correlation between metrics\n",
        "                    samples1 = results[metric1]['samples']['relative_improvement']\n",
        "                    samples2 = results[metric2]['samples']['relative_improvement']\n",
        "\n",
        "                    correlation = np.corrcoef(samples1, samples2)[0,1]\n",
        "\n",
        "                    # Joint probability of both metrics improving\n",
        "                    joint_improvement = np.mean((samples1 > 0) & (samples2 > 0)) * 100\n",
        "\n",
        "                    print(f\"   {metric1} vs {metric2}:\")\n",
        "                    print(f\"     Correlation: {correlation:.3f}\")\n",
        "                    print(f\"     Joint Improvement Probability: {joint_improvement:.1f}%\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def bayesian_value_of_information(self, dataset_name, metric, additional_samples_range):\n",
        "        \"\"\"Calculate the value of collecting additional data\"\"\"\n",
        "\n",
        "        print(\"💰 BAYESIAN VALUE OF INFORMATION ANALYSIS\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        # Current analysis\n",
        "        current_results = self.bayesian_ab_analysis(dataset_name, metric, n_simulations=10000)\n",
        "        if not current_results:\n",
        "            return None\n",
        "\n",
        "        current_uncertainty = current_results['credible_interval']['upper'] - current_results['credible_interval']['lower']\n",
        "        current_prob_better = current_results['probabilities']['treatment_better']\n",
        "\n",
        "        print(f\"\\n📊 CURRENT STATE:\")\n",
        "        print(f\"   Probability Treatment Better: {current_prob_better:.1f}%\")\n",
        "        print(f\"   Credible Interval Width: {current_uncertainty:.1f}%\")\n",
        "\n",
        "        voi_results = []\n",
        "\n",
        "        for additional_samples in additional_samples_range:\n",
        "            # Simulate additional data collection\n",
        "            # This is a simplified VOI calculation\n",
        "\n",
        "            # Estimate how much uncertainty would be reduced\n",
        "            current_total = (current_results['data_summary']['control_total'] +\n",
        "                           current_results['data_summary']['treatment_total'])\n",
        "            new_total = current_total + additional_samples\n",
        "\n",
        "            # Approximate uncertainty reduction\n",
        "            uncertainty_reduction_factor = np.sqrt(current_total / new_total)\n",
        "            new_uncertainty = current_uncertainty * uncertainty_reduction_factor\n",
        "\n",
        "            # Estimate probability of changing decision\n",
        "            prob_decision_change = self._estimate_decision_change_probability(\n",
        "                current_prob_better, current_uncertainty, new_uncertainty\n",
        "            )\n",
        "\n",
        "            # Value calculation (simplified)\n",
        "            cost_per_sample = 1  # $1 per additional sample\n",
        "            total_cost = additional_samples * cost_per_sample\n",
        "\n",
        "            # Expected value of perfect information\n",
        "            evpi = prob_decision_change * 1000  # $1000 value if decision changes\n",
        "\n",
        "            net_value = evpi - total_cost\n",
        "\n",
        "            voi_results.append({\n",
        "                'additional_samples': additional_samples,\n",
        "                'new_total_samples': new_total,\n",
        "                'uncertainty_reduction': current_uncertainty - new_uncertainty,\n",
        "                'new_uncertainty': new_uncertainty,\n",
        "                'prob_decision_change': prob_decision_change * 100,\n",
        "                'expected_value': evpi,\n",
        "                'cost': total_cost,\n",
        "                'net_value': net_value\n",
        "            })\n",
        "\n",
        "        # Find optimal additional sample size\n",
        "        optimal_idx = np.argmax([r['net_value'] for r in voi_results])\n",
        "        optimal_result = voi_results[optimal_idx]\n",
        "\n",
        "        print(f\"\\n📈 VALUE OF INFORMATION RESULTS:\")\n",
        "        print(f\"   Optimal Additional Samples: {optimal_result['additional_samples']:,}\")\n",
        "        print(f\"   Expected Net Value: ${optimal_result['net_value']:.0f}\")\n",
        "        print(f\"   Uncertainty Reduction: {optimal_result['uncertainty_reduction']:.1f}%\")\n",
        "        print(f\"   Probability of Decision Change: {optimal_result['prob_decision_change']:.1f}%\")\n",
        "\n",
        "        return voi_results\n",
        "\n",
        "    def _estimate_decision_change_probability(self, current_prob, current_uncertainty, new_uncertainty):\n",
        "        \"\"\"Estimate probability that additional data would change the decision\"\"\"\n",
        "\n",
        "        # Simplified estimation based on how close we are to decision boundaries\n",
        "        # and how much uncertainty would be reduced\n",
        "\n",
        "        distance_from_boundary = abs(current_prob - 50)  # Distance from 50% (indecision)\n",
        "        uncertainty_improvement = (current_uncertainty - new_uncertainty) / current_uncertainty\n",
        "\n",
        "        # Higher chance of decision change if we're close to boundary and uncertainty reduces significantly\n",
        "        prob_change = (1 - distance_from_boundary/50) * uncertainty_improvement * 0.5\n",
        "\n",
        "        return np.clip(prob_change, 0, 0.5)  # Cap at 50% max probability\n",
        "\n",
        "    # Add methods to the class\n",
        "    ab_tester_class.bayesian_ab_analysis = bayesian_ab_analysis\n",
        "    ab_tester_class._extract_ab_data = _extract_ab_data\n",
        "    ab_tester_class._get_bayesian_recommendation = _get_bayesian_recommendation\n",
        "    ab_tester_class._calculate_bayesian_business_impact = _calculate_bayesian_business_impact\n",
        "    ab_tester_class.bayesian_multivariate_analysis = bayesian_multivariate_analysis\n",
        "    ab_tester_class.bayesian_value_of_information = bayesian_value_of_information\n",
        "    ab_tester_class._estimate_decision_change_probability = _estimate_decision_change_probability\n",
        "\n",
        "# Example usage functions\n",
        "def run_bayesian_analysis_suite(ab_tester):\n",
        "    \"\"\"Run comprehensive Bayesian analysis on your datasets\"\"\"\n",
        "\n",
        "    print(\"🚀 COMPREHENSIVE BAYESIAN ANALYSIS SUITE\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Add Bayesian methods\n",
        "    add_bayesian_methods(ab_tester.__class__)\n",
        "\n",
        "    # Analysis 1: Cookie Cats retention analysis\n",
        "    print(\"\\n1️⃣ COOKIE CATS BAYESIAN ANALYSIS\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    cookie_retention_1 = ab_tester.bayesian_ab_analysis(\n",
        "        dataset_name='cookie_cats',\n",
        "        metric='retention_1',\n",
        "        credible_interval=0.95\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # Analysis 2: Cookie Cats 7-day retention\n",
        "    print(\"\\n2️⃣ COOKIE CATS 7-DAY RETENTION\")\n",
        "    print(\"=\" * 35)\n",
        "\n",
        "    cookie_retention_7 = ab_tester.bayesian_ab_analysis(\n",
        "        dataset_name='cookie_cats',\n",
        "        metric='retention_7',\n",
        "        credible_interval=0.95\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # Analysis 3: Multivariate analysis\n",
        "    print(\"\\n3️⃣ MULTIVARIATE BAYESIAN ANALYSIS\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    multivariate_results = ab_tester.bayesian_multivariate_analysis(\n",
        "        dataset_name='cookie_cats',\n",
        "        metrics_list=['retention_1', 'retention_7']\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # Analysis 4: Value of Information\n",
        "    print(\"\\n4️⃣ VALUE OF INFORMATION ANALYSIS\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    voi_results = ab_tester.bayesian_value_of_information(\n",
        "        dataset_name='cookie_cats',\n",
        "        metric='retention_1',\n",
        "        additional_samples_range=[1000, 5000, 10000, 25000, 50000]\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'cookie_retention_1': cookie_retention_1,\n",
        "        'cookie_retention_7': cookie_retention_7,\n",
        "        'multivariate_analysis': multivariate_results,\n",
        "        'value_of_information': voi_results\n",
        "    }\n",
        "\n",
        "def create_bayesian_visualization(bayesian_results):\n",
        "    \"\"\"Create visualizations for Bayesian analysis results\"\"\"\n",
        "\n",
        "    if not bayesian_results or 'samples' not in bayesian_results:\n",
        "        print(\"❌ No Bayesian results with samples available\")\n",
        "        return None\n",
        "\n",
        "    print(\"📊 CREATING BAYESIAN VISUALIZATION DASHBOARD\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Extract samples\n",
        "    control_samples = bayesian_results['samples']['control']\n",
        "    treatment_samples = bayesian_results['samples']['treatment']\n",
        "    rel_improvement_samples = bayesian_results['samples']['relative_improvement']\n",
        "\n",
        "    # Create subplots\n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=2,\n",
        "        subplot_titles=(\n",
        "            'Posterior Distributions',\n",
        "            'Relative Improvement Distribution',\n",
        "            'Probability of Being Better',\n",
        "            'Risk Assessment'\n",
        "        ),\n",
        "        specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
        "               [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
        "    )\n",
        "\n",
        "    # Posterior distributions\n",
        "    fig.add_trace(\n",
        "        go.Histogram(\n",
        "            x=control_samples * 100,\n",
        "            name='Control',\n",
        "            opacity=0.7,\n",
        "            nbinsx=50,\n",
        "            histnorm='probability density'\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Histogram(\n",
        "            x=treatment_samples * 100,\n",
        "            name='Treatment',\n",
        "            opacity=0.7,\n",
        "            nbinsx=50,\n",
        "            histnorm='probability density'\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # Relative improvement distribution\n",
        "    fig.add_trace(\n",
        "        go.Histogram(\n",
        "            x=rel_improvement_samples * 100,\n",
        "            name='Relative Improvement',\n",
        "            opacity=0.8,\n",
        "            nbinsx=50,\n",
        "            histnorm='probability density'\n",
        "        ),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "    # Add vertical line at zero\n",
        "    fig.add_vline(x=0, line_dash=\"dash\", line_color=\"red\",\n",
        "                 annotation_text=\"No Effect\", row=1, col=2)\n",
        "\n",
        "    # Probability visualization\n",
        "    prob_better = np.mean(treatment_samples > control_samples) * 100\n",
        "    prob_worse = 100 - prob_better\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Bar(\n",
        "            x=['Treatment Better', 'Control Better'],\n",
        "            y=[prob_better, prob_worse],\n",
        "            name='Probabilities',\n",
        "            marker_color=['green', 'red']\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "    # Risk assessment\n",
        "    risk_categories = ['Negative Effect', 'Small Effect', 'Medium Effect', 'Large Effect']\n",
        "    risk_probs = [\n",
        "        bayesian_results['risk_assessment']['prob_negative_effect'],\n",
        "        bayesian_results['risk_assessment']['prob_small_effect'],\n",
        "        bayesian_results['risk_assessment']['prob_medium_effect'],\n",
        "        bayesian_results['risk_assessment']['prob_large_effect']\n",
        "    ]\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Bar(\n",
        "            x=risk_categories,\n",
        "            y=risk_probs,\n",
        "            name='Risk Assessment',\n",
        "            marker_color=['red', 'orange', 'yellow', 'green']\n",
        "        ),\n",
        "        row=2, col=2\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f\"Bayesian A/B Testing Analysis - {bayesian_results['dataset']} ({bayesian_results['metric']})\",\n",
        "        showlegend=True,\n",
        "        height=800\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"🔮 ENHANCED A/B TESTING FRAMEWORK - CHUNK 4\")\n",
        "    print(\"Bayesian A/B Testing Analysis\")\n",
        "    print(\"\\nUsage:\")\n",
        "    print(\"# After running Chunks 1-3:\")\n",
        "    print(\"bayesian_results = run_bayesian_analysis_suite(ab_tester)\")\n",
        "    print(\"bayesian_viz = create_bayesian_visualization(bayesian_results['cookie_retention_1'])\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul_UHLwcT4Sm",
        "outputId": "18306539-4b68-4bd6-a820-c30425caad78"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔮 ENHANCED A/B TESTING FRAMEWORK - CHUNK 4\n",
            "Bayesian A/B Testing Analysis\n",
            "\n",
            "Usage:\n",
            "# After running Chunks 1-3:\n",
            "bayesian_results = run_bayesian_analysis_suite(ab_tester)\n",
            "bayesian_viz = create_bayesian_visualization(bayesian_results['cookie_retention_1'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bayesian_results = run_bayesian_analysis_suite(ab_tester)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFDBN8oeT4Wm",
        "outputId": "f4e4784f-6f38-4973-d1e7-e2018e1d6eba"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 COMPREHENSIVE BAYESIAN ANALYSIS SUITE\n",
            "============================================================\n",
            "\n",
            "1️⃣ COOKIE CATS BAYESIAN ANALYSIS\n",
            "========================================\n",
            "🔮 BAYESIAN A/B TEST ANALYSIS\n",
            "=============================================\n",
            "Dataset: cookie_cats | Metric: retention_1\n",
            "📊 DATA SUMMARY:\n",
            "   Control: 20034/44700 conversions (44.82%)\n",
            "   Treatment: 20119/45489 conversions (44.23%)\n",
            "\n",
            "🎯 POSTERIOR ESTIMATES:\n",
            "   Control Rate: 44.82%\n",
            "   Treatment Rate: 44.23%\n",
            "   Relative Improvement: -1.3%\n",
            "\n",
            "📈 PROBABILITY ANALYSIS:\n",
            "   Probability Treatment is Better: 3.7%\n",
            "   Probability Control is Better: 96.3%\n",
            "   Probability of Practical Significance: 0.0%\n",
            "\n",
            "💰 EXPECTED LOSS (Decision Theory):\n",
            "   Loss if Choose Treatment: 0.597%\n",
            "   Loss if Choose Control: 0.005%\n",
            "\n",
            "📊 95% CREDIBLE INTERVAL (Relative Improvement):\n",
            "   Lower Bound: -2.7%\n",
            "   Upper Bound: +0.1%\n",
            "\n",
            "⚠️ RISK ASSESSMENT:\n",
            "   Risk of Negative Effect: 96.3%\n",
            "   Probability of Small Effect (<1%): 33.1%\n",
            "   Probability of Medium Effect (1-10%): 0.1%\n",
            "   Probability of Large Effect (>10%): 0.0%\n",
            "   Value at Risk (5%): -2.5%\n",
            "   Value at Risk (1%): -3.0%\n",
            "\n",
            "🎯 BAYESIAN RECOMMENDATION: 🔴 RECOMMENDATION: Keep Control (Treatment Likely Harmful)\n",
            "\n",
            "💼 BUSINESS IMPACT ESTIMATION:\n",
            "   Expected Additional Users: -533\n",
            "   95% CI Additional Users: [-533, -533]\n",
            "   Expected Revenue Impact: $-2,663\n",
            "   95% CI Revenue Impact: [$-2,663, $-2,663]\n",
            "   Probability of Positive ROI: 0.0%\n",
            "\n",
            "============================================================\n",
            "\n",
            "2️⃣ COOKIE CATS 7-DAY RETENTION\n",
            "===================================\n",
            "🔮 BAYESIAN A/B TEST ANALYSIS\n",
            "=============================================\n",
            "Dataset: cookie_cats | Metric: retention_7\n",
            "📊 DATA SUMMARY:\n",
            "   Control: 8502/44700 conversions (19.02%)\n",
            "   Treatment: 8279/45489 conversions (18.20%)\n",
            "\n",
            "🎯 POSTERIOR ESTIMATES:\n",
            "   Control Rate: 19.02%\n",
            "   Treatment Rate: 18.20%\n",
            "   Relative Improvement: -4.3%\n",
            "\n",
            "📈 PROBABILITY ANALYSIS:\n",
            "   Probability Treatment is Better: 0.1%\n",
            "   Probability Control is Better: 99.9%\n",
            "   Probability of Practical Significance: 0.0%\n",
            "\n",
            "💰 EXPECTED LOSS (Decision Theory):\n",
            "   Loss if Choose Treatment: 0.821%\n",
            "   Loss if Choose Control: 0.000%\n",
            "\n",
            "📊 95% CREDIBLE INTERVAL (Relative Improvement):\n",
            "   Lower Bound: -6.9%\n",
            "   Upper Bound: -1.7%\n",
            "\n",
            "⚠️ RISK ASSESSMENT:\n",
            "   Risk of Negative Effect: 99.9%\n",
            "   Probability of Small Effect (<1%): 0.8%\n",
            "   Probability of Medium Effect (1-10%): 0.0%\n",
            "   Probability of Large Effect (>10%): 0.0%\n",
            "   Value at Risk (5%): -6.5%\n",
            "   Value at Risk (1%): -7.4%\n",
            "\n",
            "🎯 BAYESIAN RECOMMENDATION: 🔴 RECOMMENDATION: Keep Control (Treatment Likely Harmful)\n",
            "\n",
            "💼 BUSINESS IMPACT ESTIMATION:\n",
            "   Expected Additional Users: -740\n",
            "   95% CI Additional Users: [-740, -740]\n",
            "   Expected Revenue Impact: $-3,698\n",
            "   95% CI Revenue Impact: [$-3,698, $-3,698]\n",
            "   Probability of Positive ROI: 0.0%\n",
            "\n",
            "============================================================\n",
            "\n",
            "3️⃣ MULTIVARIATE BAYESIAN ANALYSIS\n",
            "========================================\n",
            "🔮 BAYESIAN MULTIVARIATE ANALYSIS\n",
            "=============================================\n",
            "Dataset: cookie_cats\n",
            "Metrics: retention_1, retention_7\n",
            "\n",
            "--- Analyzing retention_1 ---\n",
            "🔮 BAYESIAN A/B TEST ANALYSIS\n",
            "=============================================\n",
            "Dataset: cookie_cats | Metric: retention_1\n",
            "📊 DATA SUMMARY:\n",
            "   Control: 20034/44700 conversions (44.82%)\n",
            "   Treatment: 20119/45489 conversions (44.23%)\n",
            "\n",
            "🎯 POSTERIOR ESTIMATES:\n",
            "   Control Rate: 44.82%\n",
            "   Treatment Rate: 44.23%\n",
            "   Relative Improvement: -1.3%\n",
            "\n",
            "📈 PROBABILITY ANALYSIS:\n",
            "   Probability Treatment is Better: 3.7%\n",
            "   Probability Control is Better: 96.3%\n",
            "   Probability of Practical Significance: 0.0%\n",
            "\n",
            "💰 EXPECTED LOSS (Decision Theory):\n",
            "   Loss if Choose Treatment: 0.596%\n",
            "   Loss if Choose Control: 0.005%\n",
            "\n",
            "📊 95% CREDIBLE INTERVAL (Relative Improvement):\n",
            "   Lower Bound: -2.8%\n",
            "   Upper Bound: +0.1%\n",
            "\n",
            "⚠️ RISK ASSESSMENT:\n",
            "   Risk of Negative Effect: 96.3%\n",
            "   Probability of Small Effect (<1%): 33.1%\n",
            "   Probability of Medium Effect (1-10%): 0.1%\n",
            "   Probability of Large Effect (>10%): 0.0%\n",
            "   Value at Risk (5%): -2.5%\n",
            "   Value at Risk (1%): -3.0%\n",
            "\n",
            "🎯 BAYESIAN RECOMMENDATION: 🔴 RECOMMENDATION: Keep Control (Treatment Likely Harmful)\n",
            "\n",
            "💼 BUSINESS IMPACT ESTIMATION:\n",
            "   Expected Additional Users: -533\n",
            "   95% CI Additional Users: [-533, -533]\n",
            "   Expected Revenue Impact: $-2,663\n",
            "   95% CI Revenue Impact: [$-2,663, $-2,663]\n",
            "   Probability of Positive ROI: 0.0%\n",
            "\n",
            "--- Analyzing retention_7 ---\n",
            "🔮 BAYESIAN A/B TEST ANALYSIS\n",
            "=============================================\n",
            "Dataset: cookie_cats | Metric: retention_7\n",
            "📊 DATA SUMMARY:\n",
            "   Control: 8502/44700 conversions (19.02%)\n",
            "   Treatment: 8279/45489 conversions (18.20%)\n",
            "\n",
            "🎯 POSTERIOR ESTIMATES:\n",
            "   Control Rate: 19.02%\n",
            "   Treatment Rate: 18.20%\n",
            "   Relative Improvement: -4.3%\n",
            "\n",
            "📈 PROBABILITY ANALYSIS:\n",
            "   Probability Treatment is Better: 0.1%\n",
            "   Probability Control is Better: 99.9%\n",
            "   Probability of Practical Significance: 0.0%\n",
            "\n",
            "💰 EXPECTED LOSS (Decision Theory):\n",
            "   Loss if Choose Treatment: 0.821%\n",
            "   Loss if Choose Control: 0.000%\n",
            "\n",
            "📊 95% CREDIBLE INTERVAL (Relative Improvement):\n",
            "   Lower Bound: -6.9%\n",
            "   Upper Bound: -1.6%\n",
            "\n",
            "⚠️ RISK ASSESSMENT:\n",
            "   Risk of Negative Effect: 99.9%\n",
            "   Probability of Small Effect (<1%): 0.8%\n",
            "   Probability of Medium Effect (1-10%): 0.0%\n",
            "   Probability of Large Effect (>10%): 0.0%\n",
            "   Value at Risk (5%): -6.5%\n",
            "   Value at Risk (1%): -7.4%\n",
            "\n",
            "🎯 BAYESIAN RECOMMENDATION: 🔴 RECOMMENDATION: Keep Control (Treatment Likely Harmful)\n",
            "\n",
            "💼 BUSINESS IMPACT ESTIMATION:\n",
            "   Expected Additional Users: -740\n",
            "   95% CI Additional Users: [-740, -740]\n",
            "   Expected Revenue Impact: $-3,698\n",
            "   95% CI Revenue Impact: [$-3,698, $-3,698]\n",
            "   Probability of Positive ROI: 0.0%\n",
            "\n",
            "🔄 CROSS-METRIC ANALYSIS:\n",
            "   retention_1 vs retention_7:\n",
            "     Correlation: 0.960\n",
            "     Joint Improvement Probability: 0.1%\n",
            "\n",
            "============================================================\n",
            "\n",
            "4️⃣ VALUE OF INFORMATION ANALYSIS\n",
            "========================================\n",
            "💰 BAYESIAN VALUE OF INFORMATION ANALYSIS\n",
            "==================================================\n",
            "🔮 BAYESIAN A/B TEST ANALYSIS\n",
            "=============================================\n",
            "Dataset: cookie_cats | Metric: retention_1\n",
            "📊 DATA SUMMARY:\n",
            "   Control: 20034/44700 conversions (44.82%)\n",
            "   Treatment: 20119/45489 conversions (44.23%)\n",
            "\n",
            "🎯 POSTERIOR ESTIMATES:\n",
            "   Control Rate: 44.82%\n",
            "   Treatment Rate: 44.23%\n",
            "   Relative Improvement: -1.3%\n",
            "\n",
            "📈 PROBABILITY ANALYSIS:\n",
            "   Probability Treatment is Better: 3.8%\n",
            "   Probability Control is Better: 96.2%\n",
            "   Probability of Practical Significance: 0.0%\n",
            "\n",
            "💰 EXPECTED LOSS (Decision Theory):\n",
            "   Loss if Choose Treatment: 0.592%\n",
            "   Loss if Choose Control: 0.006%\n",
            "\n",
            "📊 95% CREDIBLE INTERVAL (Relative Improvement):\n",
            "   Lower Bound: -2.7%\n",
            "   Upper Bound: +0.2%\n",
            "\n",
            "⚠️ RISK ASSESSMENT:\n",
            "   Risk of Negative Effect: 96.2%\n",
            "   Probability of Small Effect (<1%): 33.7%\n",
            "   Probability of Medium Effect (1-10%): 0.1%\n",
            "   Probability of Large Effect (>10%): 0.0%\n",
            "   Value at Risk (5%): -2.5%\n",
            "   Value at Risk (1%): -3.0%\n",
            "\n",
            "🎯 BAYESIAN RECOMMENDATION: 🔴 RECOMMENDATION: Keep Control (Treatment Likely Harmful)\n",
            "\n",
            "💼 BUSINESS IMPACT ESTIMATION:\n",
            "   Expected Additional Users: -533\n",
            "   95% CI Additional Users: [-533, -533]\n",
            "   Expected Revenue Impact: $-2,663\n",
            "   95% CI Revenue Impact: [$-2,663, $-2,663]\n",
            "   Probability of Positive ROI: 0.0%\n",
            "\n",
            "📊 CURRENT STATE:\n",
            "   Probability Treatment Better: 3.8%\n",
            "   Credible Interval Width: 2.9%\n",
            "\n",
            "📈 VALUE OF INFORMATION RESULTS:\n",
            "   Optimal Additional Samples: 1,000\n",
            "   Expected Net Value: $-1000\n",
            "   Uncertainty Reduction: 0.0%\n",
            "   Probability of Decision Change: 0.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bayesian_viz = create_bayesian_visualization(bayesian_results['cookie_retention_1'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMqTj6lSUWqv",
        "outputId": "b837fc6a-054b-4025-d107-71eb301e19b5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 CREATING BAYESIAN VISUALIZATION DASHBOARD\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Testing Corrections & Meta-Analysis"
      ],
      "metadata": {
        "id": "6E_D-3iCi_TS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHUNK 5 FIXED: MULTIPLE TESTING CORRECTIONS - REAL DATA ONLY\n",
        "# Uses ONLY your real datasets, no simulation\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import norm, chi2\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def analyze_multiple_real_ab_tests(ab_tester):\n",
        "    \"\"\"\n",
        "    Analyze multiple real A/B tests from your datasets\n",
        "    NO simulation - uses actual results from your data\n",
        "    \"\"\"\n",
        "    print(\"🔬 MULTIPLE REAL A/B TESTS ANALYSIS\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"📊 Using ONLY your real datasets\")\n",
        "    print(\"❌ No synthetic data\")\n",
        "    print(\"❌ No simulation\")\n",
        "\n",
        "    real_test_results = {}\n",
        "\n",
        "    # 1. Cookie Cats - Multiple metrics (REAL DATA)\n",
        "    if 'cookie_cats' in ab_tester.datasets:\n",
        "        print(\"\\n📱 ANALYZING COOKIE CATS REAL A/B TESTS:\")\n",
        "\n",
        "        data = ab_tester.datasets['cookie_cats']\n",
        "        control_group = data[data['version'] == 'gate_30']\n",
        "        treatment_group = data[data['version'] == 'gate_40']\n",
        "\n",
        "        # Test 1: 1-day retention\n",
        "        control_ret1 = control_group['retention_1'].sum()\n",
        "        control_total1 = len(control_group)\n",
        "        treatment_ret1 = treatment_group['retention_1'].sum()\n",
        "        treatment_total1 = len(treatment_group)\n",
        "\n",
        "        z_stat1, p_value1 = proportions_ztest(\n",
        "            [control_ret1, treatment_ret1],\n",
        "            [control_total1, treatment_total1]\n",
        "        )\n",
        "\n",
        "        real_test_results['cookie_cats_retention_1'] = {\n",
        "            'p_value': p_value1,\n",
        "            'z_statistic': z_stat1,\n",
        "            'control_rate': (control_ret1 / control_total1) * 100,\n",
        "            'treatment_rate': (treatment_ret1 / treatment_total1) * 100,\n",
        "            'significant': p_value1 < 0.05,\n",
        "            'test_name': 'Cookie Cats 1-Day Retention',\n",
        "            'data_source': 'Real Cookie Cats A/B Test'\n",
        "        }\n",
        "\n",
        "        print(f\"   1-Day Retention: p = {p_value1:.4f} {'✅' if p_value1 < 0.05 else '❌'}\")\n",
        "\n",
        "        # Test 2: 7-day retention\n",
        "        control_ret7 = control_group['retention_7'].sum()\n",
        "        treatment_ret7 = treatment_group['retention_7'].sum()\n",
        "\n",
        "        z_stat7, p_value7 = proportions_ztest(\n",
        "            [control_ret7, treatment_ret7],\n",
        "            [control_total1, treatment_total1]\n",
        "        )\n",
        "\n",
        "        real_test_results['cookie_cats_retention_7'] = {\n",
        "            'p_value': p_value7,\n",
        "            'z_statistic': z_stat7,\n",
        "            'control_rate': (control_ret7 / control_total1) * 100,\n",
        "            'treatment_rate': (treatment_ret7 / treatment_total1) * 100,\n",
        "            'significant': p_value7 < 0.05,\n",
        "            'test_name': 'Cookie Cats 7-Day Retention',\n",
        "            'data_source': 'Real Cookie Cats A/B Test'\n",
        "        }\n",
        "\n",
        "        print(f\"   7-Day Retention: p = {p_value7:.4f} {'✅' if p_value7 < 0.05 else '❌'}\")\n",
        "\n",
        "    # 2. Facebook Ads - Multiple metrics (REAL DATA)\n",
        "    if 'ab_facebook' in ab_tester.datasets:\n",
        "        print(\"\\n💰 ANALYZING FACEBOOK ADS REAL A/B TESTS:\")\n",
        "\n",
        "        control_data = ab_tester.datasets['ab_facebook']['control']\n",
        "        test_data = ab_tester.datasets['ab_facebook']['test']\n",
        "\n",
        "        # Find actual column names\n",
        "        purchase_col = None\n",
        "        click_col = None\n",
        "        impression_col = None\n",
        "\n",
        "        for col in ['# of Purchase', 'purchases', 'Purchase']:\n",
        "            if col in control_data.columns:\n",
        "                purchase_col = col\n",
        "                break\n",
        "\n",
        "        for col in ['# of Website Clicks', 'clicks', 'Clicks']:\n",
        "            if col in control_data.columns:\n",
        "                click_col = col\n",
        "                break\n",
        "\n",
        "        for col in ['# of Impressions', 'impressions', 'Impressions']:\n",
        "            if col in control_data.columns:\n",
        "                impression_col = col\n",
        "                break\n",
        "\n",
        "        # Test 3: Purchase rate (if available)\n",
        "        if purchase_col and impression_col:\n",
        "            control_purchases = control_data[purchase_col].sum()\n",
        "            control_impressions = control_data[impression_col].sum()\n",
        "            test_purchases = test_data[purchase_col].sum()\n",
        "            test_impressions = test_data[impression_col].sum()\n",
        "\n",
        "            z_stat_purch, p_value_purch = proportions_ztest(\n",
        "                [control_purchases, test_purchases],\n",
        "                [control_impressions, test_impressions]\n",
        "            )\n",
        "\n",
        "            real_test_results['facebook_purchase_rate'] = {\n",
        "                'p_value': p_value_purch,\n",
        "                'z_statistic': z_stat_purch,\n",
        "                'control_rate': (control_purchases / control_impressions) * 100,\n",
        "                'treatment_rate': (test_purchases / test_impressions) * 100,\n",
        "                'significant': p_value_purch < 0.05,\n",
        "                'test_name': 'Facebook Ads Purchase Rate',\n",
        "                'data_source': 'Real Facebook Ads Campaign'\n",
        "            }\n",
        "\n",
        "            print(f\"   Purchase Rate: p = {p_value_purch:.4f} {'✅' if p_value_purch < 0.05 else '❌'}\")\n",
        "\n",
        "        # Test 4: Click rate (if available)\n",
        "        if click_col and impression_col:\n",
        "            control_clicks = control_data[click_col].sum()\n",
        "            test_clicks = test_data[click_col].sum()\n",
        "\n",
        "            z_stat_click, p_value_click = proportions_ztest(\n",
        "                [control_clicks, test_clicks],\n",
        "                [control_impressions, test_impressions]\n",
        "            )\n",
        "\n",
        "            real_test_results['facebook_click_rate'] = {\n",
        "                'p_value': p_value_click,\n",
        "                'z_statistic': z_stat_click,\n",
        "                'control_rate': (control_clicks / control_impressions) * 100,\n",
        "                'treatment_rate': (test_clicks / test_impressions) * 100,\n",
        "                'significant': p_value_click < 0.05,\n",
        "                'test_name': 'Facebook Ads Click Rate',\n",
        "                'data_source': 'Real Facebook Ads Campaign'\n",
        "            }\n",
        "\n",
        "            print(f\"   Click Rate: p = {p_value_click:.4f} {'✅' if p_value_click < 0.05 else '❌'}\")\n",
        "\n",
        "    # 3. Digital Ads - Conversion rate (REAL DATA)\n",
        "    if 'digital_ads' in ab_tester.datasets:\n",
        "        print(\"\\n📊 ANALYZING DIGITAL ADS CONVERSION PERFORMANCE:\")\n",
        "\n",
        "        data = ab_tester.datasets['digital_ads']\n",
        "\n",
        "        # Create A/B test by splitting data (e.g., by campaign or demographic)\n",
        "        if 'age' in data.columns:\n",
        "            # Compare different age groups as A/B test\n",
        "            young_group = data[data['age'] == '30-34']\n",
        "            older_group = data[data['age'] == '35-39']\n",
        "\n",
        "            if len(young_group) > 0 and len(older_group) > 0:\n",
        "                young_conversions = young_group['Total_Conversion'].sum()\n",
        "                young_impressions = young_group['Impressions'].sum()\n",
        "                older_conversions = older_group['Total_Conversion'].sum()\n",
        "                older_impressions = older_group['Impressions'].sum()\n",
        "\n",
        "                if young_impressions > 0 and older_impressions > 0:\n",
        "                    z_stat_age, p_value_age = proportions_ztest(\n",
        "                        [young_conversions, older_conversions],\n",
        "                        [young_impressions, older_impressions]\n",
        "                    )\n",
        "\n",
        "                    real_test_results['digital_ads_age_comparison'] = {\n",
        "                        'p_value': p_value_age,\n",
        "                        'z_statistic': z_stat_age,\n",
        "                        'control_rate': (young_conversions / young_impressions) * 100,\n",
        "                        'treatment_rate': (older_conversions / older_impressions) * 100,\n",
        "                        'significant': p_value_age < 0.05,\n",
        "                        'test_name': 'Digital Ads Age Group Comparison',\n",
        "                        'data_source': 'Real Digital Ads Data'\n",
        "                    }\n",
        "\n",
        "                    print(f\"   Age Group Comparison: p = {p_value_age:.4f} {'✅' if p_value_age < 0.05 else '❌'}\")\n",
        "\n",
        "    print(f\"\\n📊 TOTAL REAL A/B TESTS ANALYZED: {len(real_test_results)}\")\n",
        "    print(f\"✅ Data Source: 100% Real datasets\")\n",
        "\n",
        "    return real_test_results\n",
        "\n",
        "def apply_multiple_testing_corrections_real(real_test_results):\n",
        "    \"\"\"\n",
        "    Apply multiple testing corrections to your REAL A/B test p-values\n",
        "    \"\"\"\n",
        "    print(\"\\n🔬 MULTIPLE TESTING CORRECTIONS - REAL DATA\")\n",
        "    print(\"=\" * 55)\n",
        "\n",
        "    if not real_test_results:\n",
        "        print(\"❌ No real test results to analyze\")\n",
        "        return None\n",
        "\n",
        "    # Extract real p-values\n",
        "    test_names = list(real_test_results.keys())\n",
        "    p_values = [real_test_results[test]['p_value'] for test in test_names]\n",
        "    n_tests = len(p_values)\n",
        "\n",
        "    print(f\"📊 REAL P-VALUES FROM YOUR TESTS:\")\n",
        "    for i, test_name in enumerate(test_names):\n",
        "        significant = \"✅\" if p_values[i] < 0.05 else \"❌\"\n",
        "        print(f\"   {test_name}: p = {p_values[i]:.4f} {significant}\")\n",
        "\n",
        "    # Apply corrections\n",
        "    corrections_results = {}\n",
        "\n",
        "    # 1. Bonferroni Correction\n",
        "    bonferroni_alpha = 0.05 / n_tests\n",
        "    bonferroni_significant = [p < bonferroni_alpha for p in p_values]\n",
        "\n",
        "    print(f\"\\n🔬 BONFERRONI CORRECTION:\")\n",
        "    print(f\"   Original α: 0.05\")\n",
        "    print(f\"   Corrected α: {bonferroni_alpha:.4f}\")\n",
        "    print(f\"   Significant tests: {sum(bonferroni_significant)}/{n_tests}\")\n",
        "\n",
        "    for i, test_name in enumerate(test_names):\n",
        "        status = \"✅ Significant\" if bonferroni_significant[i] else \"❌ Not Significant\"\n",
        "        print(f\"   {test_name}: {status}\")\n",
        "\n",
        "    # 2. Benjamini-Hochberg (FDR)\n",
        "    bh_significant, bh_pvalues_corrected, _, _ = multipletests(\n",
        "        p_values, alpha=0.05, method='fdr_bh'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n🔬 BENJAMINI-HOCHBERG CORRECTION (FDR):\")\n",
        "    print(f\"   FDR Level: 0.05\")\n",
        "    print(f\"   Significant tests: {sum(bh_significant)}/{n_tests}\")\n",
        "\n",
        "    for i, test_name in enumerate(test_names):\n",
        "        status = \"✅ Significant\" if bh_significant[i] else \"❌ Not Significant\"\n",
        "        print(f\"   {test_name}: {status} (corrected p = {bh_pvalues_corrected[i]:.4f})\")\n",
        "\n",
        "    # 3. Holm Correction\n",
        "    holm_significant, holm_pvalues_corrected, _, _ = multipletests(\n",
        "        p_values, alpha=0.05, method='holm'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n🔬 HOLM CORRECTION:\")\n",
        "    print(f\"   Significant tests: {sum(holm_significant)}/{n_tests}\")\n",
        "\n",
        "    for i, test_name in enumerate(test_names):\n",
        "        status = \"✅ Significant\" if holm_significant[i] else \"❌ Not Significant\"\n",
        "        print(f\"   {test_name}: {status}\")\n",
        "\n",
        "    # Summary\n",
        "    original_significant = sum(1 for p in p_values if p < 0.05)\n",
        "\n",
        "    corrections_results = {\n",
        "        'original_p_values': p_values,\n",
        "        'test_names': test_names,\n",
        "        'original_significant': original_significant,\n",
        "        'bonferroni': {\n",
        "            'corrected_alpha': bonferroni_alpha,\n",
        "            'significant': bonferroni_significant,\n",
        "            'num_significant': sum(bonferroni_significant)\n",
        "        },\n",
        "        'benjamini_hochberg': {\n",
        "            'significant': bh_significant.tolist(),\n",
        "            'corrected_pvalues': bh_pvalues_corrected.tolist(),\n",
        "            'num_significant': sum(bh_significant)\n",
        "        },\n",
        "        'holm': {\n",
        "            'significant': holm_significant.tolist(),\n",
        "            'corrected_pvalues': holm_pvalues_corrected.tolist(),\n",
        "            'num_significant': sum(holm_significant)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(f\"\\n📊 CORRECTION SUMMARY:\")\n",
        "    print(f\"   Original significant: {original_significant}/{n_tests}\")\n",
        "    print(f\"   Bonferroni significant: {corrections_results['bonferroni']['num_significant']}/{n_tests}\")\n",
        "    print(f\"   Benjamini-Hochberg significant: {corrections_results['benjamini_hochberg']['num_significant']}/{n_tests}\")\n",
        "    print(f\"   Holm significant: {corrections_results['holm']['num_significant']}/{n_tests}\")\n",
        "\n",
        "    print(f\"\\n🎯 DATA SOURCE: 100% Real A/B Test Results\")\n",
        "\n",
        "    return corrections_results\n",
        "\n",
        "def meta_analysis_real_data(ab_tester):\n",
        "    \"\"\"\n",
        "    Perform meta-analysis using subsamples of your real Cookie Cats data\n",
        "    \"\"\"\n",
        "    print(\"\\n📊 META-ANALYSIS USING REAL COOKIE CATS DATA\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    if 'cookie_cats' not in ab_tester.datasets:\n",
        "        print(\"❌ Cookie Cats data not available\")\n",
        "        return None\n",
        "\n",
        "    data = ab_tester.datasets['cookie_cats']\n",
        "\n",
        "    # Create multiple \"studies\" by subsampling your real data\n",
        "    studies = []\n",
        "    study_names = []\n",
        "\n",
        "    # Split data into 4 subsamples to simulate different studies\n",
        "    sample_size = len(data) // 4\n",
        "\n",
        "    for i in range(4):\n",
        "        start_idx = i * sample_size\n",
        "        end_idx = (i + 1) * sample_size if i < 3 else len(data)\n",
        "\n",
        "        subsample = data.iloc[start_idx:end_idx]\n",
        "\n",
        "        control_data = subsample[subsample['version'] == 'gate_30']\n",
        "        treatment_data = subsample[subsample['version'] == 'gate_40']\n",
        "\n",
        "        control_rate = control_data['retention_1'].mean()\n",
        "        treatment_rate = treatment_data['retention_1'].mean()\n",
        "\n",
        "        studies.append({\n",
        "            'study_name': f'Cookie_Cats_Subsample_{i+1}',\n",
        "            'control_rate': control_rate,\n",
        "            'treatment_rate': treatment_rate,\n",
        "            'control_n': len(control_data),\n",
        "            'treatment_n': len(treatment_data)\n",
        "        })\n",
        "        study_names.append(f'Subsample_{i+1}')\n",
        "\n",
        "        print(f\"   Study {i+1}: Control={control_rate*100:.2f}%, Treatment={treatment_rate*100:.2f}%\")\n",
        "\n",
        "    # Simple meta-analysis (mean of effect sizes)\n",
        "    effect_sizes = []\n",
        "    for study in studies:\n",
        "        if study['control_rate'] > 0:\n",
        "            relative_effect = (study['treatment_rate'] - study['control_rate']) / study['control_rate']\n",
        "            effect_sizes.append(relative_effect)\n",
        "\n",
        "    if effect_sizes:\n",
        "        pooled_effect = np.mean(effect_sizes)\n",
        "        effect_std = np.std(effect_sizes)\n",
        "\n",
        "        print(f\"\\n📈 META-ANALYSIS RESULTS:\")\n",
        "        print(f\"   Number of studies: {len(studies)}\")\n",
        "        print(f\"   Pooled effect size: {pooled_effect*100:+.2f}%\")\n",
        "        print(f\"   Effect size std: {effect_std*100:.2f}%\")\n",
        "        print(f\"   Consistent direction: {'Yes' if all(e < 0 for e in effect_sizes) else 'No'}\")\n",
        "\n",
        "        return {\n",
        "            'studies': studies,\n",
        "            'effect_sizes': effect_sizes,\n",
        "            'pooled_effect': pooled_effect,\n",
        "            'effect_std': effect_std,\n",
        "            'num_studies': len(studies)\n",
        "        }\n",
        "\n",
        "    return None\n",
        "\n",
        "def run_real_multiple_testing_analysis(ab_tester):\n",
        "    \"\"\"\n",
        "    Run complete multiple testing analysis using ONLY real data\n",
        "    \"\"\"\n",
        "    print(\"🚀 REAL DATA MULTIPLE TESTING ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"🎯 Using ONLY your real datasets\")\n",
        "    print(\"❌ No synthetic data\")\n",
        "    print(\"❌ No simulation\")\n",
        "    print(\"✅ 100% authentic A/B test results\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # 1. Analyze multiple real A/B tests\n",
        "    real_test_results = analyze_multiple_real_ab_tests(ab_tester)\n",
        "\n",
        "    if not real_test_results:\n",
        "        print(\"❌ No real A/B test results found\")\n",
        "        return None\n",
        "\n",
        "    # 2. Apply multiple testing corrections\n",
        "    correction_results = apply_multiple_testing_corrections_real(real_test_results)\n",
        "\n",
        "    # 3. Meta-analysis using real data\n",
        "    meta_results = meta_analysis_real_data(ab_tester)\n",
        "\n",
        "    # 4. Summary\n",
        "    print(f\"\\n🎉 MULTIPLE TESTING ANALYSIS COMPLETE\")\n",
        "    print(\"=\" * 45)\n",
        "\n",
        "    num_tests = len(real_test_results)\n",
        "    original_significant = sum(1 for test in real_test_results.values() if test['significant'])\n",
        "\n",
        "    if correction_results:\n",
        "        bonf_significant = correction_results['bonferroni']['num_significant']\n",
        "        bh_significant = correction_results['benjamini_hochberg']['num_significant']\n",
        "\n",
        "        print(f\"📊 RESULTS SUMMARY:\")\n",
        "        print(f\"   Total real A/B tests: {num_tests}\")\n",
        "        print(f\"   Originally significant: {original_significant}\")\n",
        "        print(f\"   After Bonferroni: {bonf_significant}\")\n",
        "        print(f\"   After Benjamini-Hochberg: {bh_significant}\")\n",
        "\n",
        "        if meta_results:\n",
        "            print(f\"   Meta-analysis pooled effect: {meta_results['pooled_effect']*100:+.1f}%\")\n",
        "\n",
        "    print(f\"\\n🎯 DATA AUTHENTICITY:\")\n",
        "    print(f\"   ✅ Real datasets: {len(ab_tester.datasets)}\")\n",
        "    print(f\"   ✅ Real A/B tests: {num_tests}\")\n",
        "    print(f\"   ✅ Real statistical results: 100%\")\n",
        "    print(f\"   ❌ Synthetic data: 0%\")\n",
        "\n",
        "    return {\n",
        "        'real_test_results': real_test_results,\n",
        "        'correction_results': correction_results,\n",
        "        'meta_analysis': meta_results\n",
        "    }\n",
        "\n",
        "def create_real_multiple_testing_visualization(results):\n",
        "    \"\"\"Create visualizations for real multiple testing analysis\"\"\"\n",
        "\n",
        "    if not results or 'real_test_results' not in results:\n",
        "        print(\"❌ No results to visualize\")\n",
        "        return None\n",
        "\n",
        "    print(\"📊 CREATING REAL DATA VISUALIZATION\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    real_tests = results['real_test_results']\n",
        "    correction_results = results.get('correction_results')\n",
        "\n",
        "    # Create subplots\n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=2,\n",
        "        subplot_titles=(\n",
        "            'P-values from Real A/B Tests',\n",
        "            'Correction Method Comparison',\n",
        "            'Effect Sizes by Test',\n",
        "            'Significance Before/After Correction'\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # P-values from real tests\n",
        "    test_names = [test['test_name'] for test in real_tests.values()]\n",
        "    p_values = [test['p_value'] for test in real_tests.values()]\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Bar(\n",
        "            x=test_names,\n",
        "            y=p_values,\n",
        "            name='P-values',\n",
        "            marker_color=['green' if p < 0.05 else 'red' for p in p_values]\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # Add significance line\n",
        "    fig.add_hline(y=0.05, line_dash=\"dash\", line_color=\"red\",\n",
        "                 annotation_text=\"α = 0.05\", row=1, col=1)\n",
        "\n",
        "    # Correction comparison\n",
        "    if correction_results:\n",
        "        methods = ['Original', 'Bonferroni', 'Benjamini-Hochberg', 'Holm']\n",
        "        significant_counts = [\n",
        "            correction_results['original_significant'],\n",
        "            correction_results['bonferroni']['num_significant'],\n",
        "            correction_results['benjamini_hochberg']['num_significant'],\n",
        "            correction_results['holm']['num_significant']\n",
        "        ]\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=methods,\n",
        "                y=significant_counts,\n",
        "                name='Significant Tests',\n",
        "                marker_color=['blue', 'red', 'green', 'orange']\n",
        "            ),\n",
        "            row=1, col=2\n",
        "        )\n",
        "\n",
        "    # Effect sizes\n",
        "    effect_sizes = []\n",
        "    for test in real_tests.values():\n",
        "        control_rate = test['control_rate']\n",
        "        treatment_rate = test['treatment_rate']\n",
        "        if control_rate > 0:\n",
        "            effect = ((treatment_rate - control_rate) / control_rate) * 100\n",
        "            effect_sizes.append(effect)\n",
        "        else:\n",
        "            effect_sizes.append(0)\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Bar(\n",
        "            x=test_names,\n",
        "            y=effect_sizes,\n",
        "            name='Effect Size (%)',\n",
        "            marker_color=['green' if e > 0 else 'red' for e in effect_sizes]\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=\"Real Data Multiple Testing Analysis\",\n",
        "        showlegend=True,\n",
        "        height=800\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "# ==========================================\n",
        "# MAIN EXECUTION - RUN THIS\n",
        "# ==========================================\n",
        "\n",
        "print(\"🔬 CHUNK 5 - REAL DATA MULTIPLE TESTING ANALYSIS\")\n",
        "print(\"=\" * 55)\n",
        "print(\"✅ Fixed method errors\")\n",
        "print(\"✅ Uses only real datasets\")\n",
        "print(\"✅ No synthetic or simulated data\")\n",
        "print(\"\\nUsage:\")\n",
        "print(\"# Run this to analyze multiple real A/B tests:\")\n",
        "print(\"real_multiple_results = run_real_multiple_testing_analysis(ab_tester)\")\n",
        "print(\"# Create visualization:\")\n",
        "print(\"mt_viz = create_real_multiple_testing_visualization(real_multiple_results)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkhY2rl0UWvO",
        "outputId": "414a5bb3-b0c0-4075-db74-fe6eb396bba8"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔬 CHUNK 5 - REAL DATA MULTIPLE TESTING ANALYSIS\n",
            "=======================================================\n",
            "✅ Fixed method errors\n",
            "✅ Uses only real datasets\n",
            "✅ No synthetic or simulated data\n",
            "\n",
            "Usage:\n",
            "# Run this to analyze multiple real A/B tests:\n",
            "real_multiple_results = run_real_multiple_testing_analysis(ab_tester)\n",
            "# Create visualization:\n",
            "mt_viz = create_real_multiple_testing_visualization(real_multiple_results)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_multiple_results = run_real_multiple_testing_analysis(ab_tester)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7C2He1iUWym",
        "outputId": "fe946c35-6ffa-48d0-8387-dc736bf24af4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 REAL DATA MULTIPLE TESTING ANALYSIS\n",
            "============================================================\n",
            "🎯 Using ONLY your real datasets\n",
            "❌ No synthetic data\n",
            "❌ No simulation\n",
            "✅ 100% authentic A/B test results\n",
            "============================================================\n",
            "🔬 MULTIPLE REAL A/B TESTS ANALYSIS\n",
            "==================================================\n",
            "📊 Using ONLY your real datasets\n",
            "❌ No synthetic data\n",
            "❌ No simulation\n",
            "\n",
            "📱 ANALYZING COOKIE CATS REAL A/B TESTS:\n",
            "   1-Day Retention: p = 0.0744 ❌\n",
            "   7-Day Retention: p = 0.0016 ✅\n",
            "\n",
            "💰 ANALYZING FACEBOOK ADS REAL A/B TESTS:\n",
            "   Purchase Rate: p = 0.0000 ✅\n",
            "   Click Rate: p = 0.0000 ✅\n",
            "\n",
            "📊 ANALYZING DIGITAL ADS CONVERSION PERFORMANCE:\n",
            "   Age Group Comparison: p = 0.0000 ✅\n",
            "\n",
            "📊 TOTAL REAL A/B TESTS ANALYZED: 5\n",
            "✅ Data Source: 100% Real datasets\n",
            "\n",
            "🔬 MULTIPLE TESTING CORRECTIONS - REAL DATA\n",
            "=======================================================\n",
            "📊 REAL P-VALUES FROM YOUR TESTS:\n",
            "   cookie_cats_retention_1: p = 0.0744 ❌\n",
            "   cookie_cats_retention_7: p = 0.0016 ✅\n",
            "   facebook_purchase_rate: p = 0.0000 ✅\n",
            "   facebook_click_rate: p = 0.0000 ✅\n",
            "   digital_ads_age_comparison: p = 0.0000 ✅\n",
            "\n",
            "🔬 BONFERRONI CORRECTION:\n",
            "   Original α: 0.05\n",
            "   Corrected α: 0.0100\n",
            "   Significant tests: 4/5\n",
            "   cookie_cats_retention_1: ❌ Not Significant\n",
            "   cookie_cats_retention_7: ✅ Significant\n",
            "   facebook_purchase_rate: ✅ Significant\n",
            "   facebook_click_rate: ✅ Significant\n",
            "   digital_ads_age_comparison: ✅ Significant\n",
            "\n",
            "🔬 BENJAMINI-HOCHBERG CORRECTION (FDR):\n",
            "   FDR Level: 0.05\n",
            "   Significant tests: 4/5\n",
            "   cookie_cats_retention_1: ❌ Not Significant (corrected p = 0.0744)\n",
            "   cookie_cats_retention_7: ✅ Significant (corrected p = 0.0019)\n",
            "   facebook_purchase_rate: ✅ Significant (corrected p = 0.0000)\n",
            "   facebook_click_rate: ✅ Significant (corrected p = 0.0000)\n",
            "   digital_ads_age_comparison: ✅ Significant (corrected p = 0.0000)\n",
            "\n",
            "🔬 HOLM CORRECTION:\n",
            "   Significant tests: 4/5\n",
            "   cookie_cats_retention_1: ❌ Not Significant\n",
            "   cookie_cats_retention_7: ✅ Significant\n",
            "   facebook_purchase_rate: ✅ Significant\n",
            "   facebook_click_rate: ✅ Significant\n",
            "   digital_ads_age_comparison: ✅ Significant\n",
            "\n",
            "📊 CORRECTION SUMMARY:\n",
            "   Original significant: 4/5\n",
            "   Bonferroni significant: 4/5\n",
            "   Benjamini-Hochberg significant: 4/5\n",
            "   Holm significant: 4/5\n",
            "\n",
            "🎯 DATA SOURCE: 100% Real A/B Test Results\n",
            "\n",
            "📊 META-ANALYSIS USING REAL COOKIE CATS DATA\n",
            "==================================================\n",
            "   Study 1: Control=44.39%, Treatment=44.73%\n",
            "   Study 2: Control=45.25%, Treatment=44.19%\n",
            "   Study 3: Control=45.05%, Treatment=44.05%\n",
            "   Study 4: Control=44.58%, Treatment=43.95%\n",
            "\n",
            "📈 META-ANALYSIS RESULTS:\n",
            "   Number of studies: 4\n",
            "   Pooled effect size: -1.31%\n",
            "   Effect size std: 1.24%\n",
            "   Consistent direction: No\n",
            "\n",
            "🎉 MULTIPLE TESTING ANALYSIS COMPLETE\n",
            "=============================================\n",
            "📊 RESULTS SUMMARY:\n",
            "   Total real A/B tests: 5\n",
            "   Originally significant: 4\n",
            "   After Bonferroni: 4\n",
            "   After Benjamini-Hochberg: 4\n",
            "   Meta-analysis pooled effect: -1.3%\n",
            "\n",
            "🎯 DATA AUTHENTICITY:\n",
            "   ✅ Real datasets: 3\n",
            "   ✅ Real A/B tests: 5\n",
            "   ✅ Real statistical results: 100%\n",
            "   ❌ Synthetic data: 0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mt_viz = create_real_multiple_testing_visualization(real_multiple_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGW2J_92jKmh",
        "outputId": "07998683-5888-4fc1-b133-1f5a51810c21"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 CREATING REAL DATA VISUALIZATION\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CHUNK 6: REAL DATA INTEGRATION & COMPREHENSIVE ANALYSIS\n",
        "# Complete analysis pipeline using your actual datasets\n",
        "\n",
        "def add_comprehensive_analysis_methods(ab_tester_class):\n",
        "    \"\"\"Add comprehensive analysis methods that integrate all previous chunks\"\"\"\n",
        "\n",
        "    def comprehensive_ab_analysis(self, dataset_name='cookie_cats', metrics_list=None,\n",
        "                                analysis_type='full', confidence_level=0.95):\n",
        "        \"\"\"\n",
        "        Run complete A/B testing analysis using all advanced methods on your real data\n",
        "\n",
        "        Parameters:\n",
        "        - dataset_name: 'cookie_cats', 'ab_facebook', or 'digital_ads'\n",
        "        - metrics_list: List of metrics to analyze (None = auto-detect)\n",
        "        - analysis_type: 'full', 'quick', 'bayesian_only', 'frequentist_only'\n",
        "        - confidence_level: Confidence/credible interval level\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"🚀 COMPREHENSIVE A/B TESTING ANALYSIS\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"🎯 Dataset: {dataset_name.upper()}\")\n",
        "        print(f\"📊 Analysis Type: {analysis_type.upper()}\")\n",
        "        print(f\"🔍 Confidence Level: {confidence_level*100:.0f}%\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        if dataset_name not in self.datasets:\n",
        "            print(f\"❌ Dataset '{dataset_name}' not loaded\")\n",
        "            return None\n",
        "\n",
        "        # Auto-detect metrics if not provided\n",
        "        if metrics_list is None:\n",
        "            metrics_list = self._auto_detect_metrics(dataset_name)\n",
        "\n",
        "        print(f\"📈 Metrics to Analyze: {', '.join(metrics_list)}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        # Initialize results container\n",
        "        comprehensive_results = {\n",
        "            'dataset': dataset_name,\n",
        "            'metrics': metrics_list,\n",
        "            'analysis_timestamp': datetime.now().isoformat(),\n",
        "            'analysis_type': analysis_type,\n",
        "            'confidence_level': confidence_level,\n",
        "            'summary': {},\n",
        "            'detailed_results': {}\n",
        "        }\n",
        "\n",
        "        # Run analysis for each metric\n",
        "        for i, metric in enumerate(metrics_list):\n",
        "            print(f\"\\n📊 ANALYZING METRIC {i+1}/{len(metrics_list)}: {metric.upper()}\")\n",
        "            print(\"=\" * 50)\n",
        "\n",
        "            metric_results = self._analyze_single_metric(\n",
        "                dataset_name, metric, analysis_type, confidence_level\n",
        "            )\n",
        "\n",
        "            if metric_results:\n",
        "                comprehensive_results['detailed_results'][metric] = metric_results\n",
        "                comprehensive_results['summary'][metric] = self._extract_metric_summary(metric_results)\n",
        "\n",
        "        # Multi-metric analysis\n",
        "        if len(metrics_list) > 1:\n",
        "            print(f\"\\n🔄 MULTI-METRIC ANALYSIS\")\n",
        "            print(\"=\" * 30)\n",
        "\n",
        "            multi_metric_results = self._multi_metric_analysis(\n",
        "                dataset_name, metrics_list, comprehensive_results['detailed_results']\n",
        "            )\n",
        "            comprehensive_results['multi_metric_analysis'] = multi_metric_results\n",
        "\n",
        "        # Generate executive summary\n",
        "        executive_summary = self._generate_executive_summary(comprehensive_results)\n",
        "        comprehensive_results['executive_summary'] = executive_summary\n",
        "\n",
        "        # Display executive summary\n",
        "        print(f\"\\n📋 EXECUTIVE SUMMARY\")\n",
        "        print(\"=\" * 25)\n",
        "        self._display_executive_summary(executive_summary)\n",
        "\n",
        "        return comprehensive_results\n",
        "\n",
        "    def _auto_detect_metrics(self, dataset_name):\n",
        "        \"\"\"Auto-detect available metrics for each dataset\"\"\"\n",
        "\n",
        "        if dataset_name == 'cookie_cats':\n",
        "            return ['retention_1', 'retention_7']\n",
        "        elif dataset_name == 'ab_facebook':\n",
        "            return ['purchase_rate', 'click_rate']\n",
        "        elif dataset_name == 'digital_ads':\n",
        "            return ['conversion_rate', 'click_rate']\n",
        "        else:\n",
        "            return ['conversion_rate']  # Default\n",
        "\n",
        "    def _analyze_single_metric(self, dataset_name, metric, analysis_type, confidence_level):\n",
        "        \"\"\"Analyze a single metric using all available methods\"\"\"\n",
        "\n",
        "        results = {\n",
        "            'metric': metric,\n",
        "            'dataset': dataset_name\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # 1. Basic descriptive statistics\n",
        "            desc_stats = self._calculate_descriptive_stats(dataset_name, metric)\n",
        "            results['descriptive_stats'] = desc_stats\n",
        "\n",
        "            # 2. Frequentist analysis (always included)\n",
        "            if analysis_type in ['full', 'quick', 'frequentist_only']:\n",
        "                freq_results = self._run_frequentist_analysis(dataset_name, metric, confidence_level)\n",
        "                results['frequentist'] = freq_results\n",
        "\n",
        "            # 3. Bayesian analysis\n",
        "            if analysis_type in ['full', 'bayesian_only']:\n",
        "                bayesian_results = self.bayesian_ab_analysis(\n",
        "                    dataset_name, metric,\n",
        "                    credible_interval=confidence_level,\n",
        "                    n_simulations=50000\n",
        "                )\n",
        "                results['bayesian'] = bayesian_results\n",
        "\n",
        "            # 4. Power analysis (for full analysis)\n",
        "            if analysis_type == 'full':\n",
        "                power_results = self._run_power_analysis(dataset_name, metric)\n",
        "                results['power_analysis'] = power_results\n",
        "\n",
        "            # 5. Sequential testing simulation (for full analysis)\n",
        "            if analysis_type == 'full':\n",
        "                sequential_results = self._run_sequential_simulation(dataset_name, metric)\n",
        "                results['sequential_testing'] = sequential_results\n",
        "\n",
        "            print(f\"✅ Analysis complete for {metric}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error analyzing {metric}: {str(e)}\")\n",
        "            results['error'] = str(e)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _calculate_descriptive_stats(self, dataset_name, metric):\n",
        "        \"\"\"Calculate descriptive statistics for the metric\"\"\"\n",
        "\n",
        "        control_data, treatment_data = self._extract_ab_data(dataset_name, metric)\n",
        "\n",
        "        if control_data is None or treatment_data is None:\n",
        "            return None\n",
        "\n",
        "        control_rate = control_data['conversions'] / control_data['total']\n",
        "        treatment_rate = treatment_data['conversions'] / treatment_data['total']\n",
        "\n",
        "        return {\n",
        "            'control': {\n",
        "                'conversions': control_data['conversions'],\n",
        "                'total': control_data['total'],\n",
        "                'rate': control_rate,\n",
        "                'rate_pct': control_rate * 100\n",
        "            },\n",
        "            'treatment': {\n",
        "                'conversions': treatment_data['conversions'],\n",
        "                'total': treatment_data['total'],\n",
        "                'rate': treatment_rate,\n",
        "                'rate_pct': treatment_rate * 100\n",
        "            },\n",
        "            'difference': {\n",
        "                'absolute': treatment_rate - control_rate,\n",
        "                'relative': ((treatment_rate - control_rate) / control_rate * 100) if control_rate > 0 else 0,\n",
        "                'relative_pct': ((treatment_rate - control_rate) / control_rate * 100) if control_rate > 0 else 0\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _run_frequentist_analysis(self, dataset_name, metric, confidence_level):\n",
        "        \"\"\"Run frequentist statistical analysis\"\"\"\n",
        "\n",
        "        control_data, treatment_data = self._extract_ab_data(dataset_name, metric)\n",
        "\n",
        "        if control_data is None or treatment_data is None:\n",
        "            return None\n",
        "\n",
        "        # Two-proportion z-test\n",
        "        z_stat, p_value = proportions_ztest(\n",
        "            [control_data['conversions'], treatment_data['conversions']],\n",
        "            [control_data['total'], treatment_data['total']]\n",
        "        )\n",
        "\n",
        "        # Effect size (Cohen's h)\n",
        "        control_rate = control_data['conversions'] / control_data['total']\n",
        "        treatment_rate = treatment_data['conversions'] / treatment_data['total']\n",
        "\n",
        "        effect_size = proportion_effectsize(control_rate, treatment_rate)\n",
        "\n",
        "        # Confidence interval for difference in proportions\n",
        "        alpha = 1 - confidence_level\n",
        "        z_critical = norm.ppf(1 - alpha/2)\n",
        "\n",
        "        p1, p2 = control_rate, treatment_rate\n",
        "        n1, n2 = control_data['total'], treatment_data['total']\n",
        "\n",
        "        se_diff = np.sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2)\n",
        "        diff = p2 - p1\n",
        "\n",
        "        ci_lower = diff - z_critical * se_diff\n",
        "        ci_upper = diff + z_critical * se_diff\n",
        "\n",
        "        return {\n",
        "            'z_statistic': z_stat,\n",
        "            'p_value': p_value,\n",
        "            'effect_size_cohens_h': effect_size,\n",
        "            'significant': p_value < (1 - confidence_level),\n",
        "            'confidence_interval': {\n",
        "                'lower': ci_lower * 100,\n",
        "                'upper': ci_upper * 100,\n",
        "                'level': confidence_level * 100\n",
        "            },\n",
        "            'statistical_power': None  # Would need effect size assumption\n",
        "        }\n",
        "\n",
        "    def _run_power_analysis(self, dataset_name, metric):\n",
        "        \"\"\"Run power analysis for the metric\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Use existing method\n",
        "            power_results = self.calculate_sample_size_for_your_data(\n",
        "                dataset_name=dataset_name,\n",
        "                metric=metric,\n",
        "                mde=0.15,\n",
        "                power=0.8,\n",
        "                alpha=0.05\n",
        "            )\n",
        "            return power_results\n",
        "        except Exception as e:\n",
        "            return {'error': str(e)}\n",
        "\n",
        "    def _run_sequential_simulation(self, dataset_name, metric):\n",
        "        \"\"\"Run sequential testing simulation\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Run a quick simulation\n",
        "            seq_history = self.simulate_sequential_test(\n",
        "                dataset_name=dataset_name,\n",
        "                metric=metric,\n",
        "                max_days=10,\n",
        "                spending_function='obrien_fleming'\n",
        "            )\n",
        "\n",
        "            if seq_history:\n",
        "                final_result = seq_history[-1]\n",
        "                return {\n",
        "                    'days_to_decision': len(seq_history),\n",
        "                    'final_recommendation': final_result['recommendation'],\n",
        "                    'stopped_early': final_result['stop_for_efficacy'] or final_result['stop_for_futility'],\n",
        "                    'final_p_value': final_result['p_value']\n",
        "                }\n",
        "        except Exception as e:\n",
        "            return {'error': str(e)}\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _extract_metric_summary(self, metric_results):\n",
        "        \"\"\"Extract key summary statistics from detailed results\"\"\"\n",
        "\n",
        "        summary = {\n",
        "            'metric': metric_results['metric']\n",
        "        }\n",
        "\n",
        "        # Descriptive stats\n",
        "        if 'descriptive_stats' in metric_results:\n",
        "            desc = metric_results['descriptive_stats']\n",
        "            summary['control_rate'] = desc['control']['rate_pct']\n",
        "            summary['treatment_rate'] = desc['treatment']['rate_pct']\n",
        "            summary['relative_change'] = desc['difference']['relative_pct']\n",
        "\n",
        "        # Frequentist results\n",
        "        if 'frequentist' in metric_results:\n",
        "            freq = metric_results['frequentist']\n",
        "            summary['p_value'] = freq['p_value']\n",
        "            summary['significant_frequentist'] = freq['significant']\n",
        "\n",
        "        # Bayesian results\n",
        "        if 'bayesian' in metric_results:\n",
        "            bayes = metric_results['bayesian']\n",
        "            summary['prob_treatment_better'] = bayes['probabilities']['treatment_better']\n",
        "            summary['bayesian_recommendation'] = bayes['recommendation']\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def _multi_metric_analysis(self, dataset_name, metrics_list, detailed_results):\n",
        "        \"\"\"Analyze relationships between multiple metrics\"\"\"\n",
        "\n",
        "        print(\"🔄 Running multi-metric correlation analysis...\")\n",
        "\n",
        "        # Extract p-values for multiple testing correction\n",
        "        p_values_dict = {}\n",
        "        for metric in metrics_list:\n",
        "            if metric in detailed_results and 'frequentist' in detailed_results[metric]:\n",
        "                p_values_dict[metric] = detailed_results[metric]['frequentist']\n",
        "\n",
        "        # Apply multiple testing corrections\n",
        "        corrections = {}\n",
        "        if len(p_values_dict) > 1:\n",
        "            for method in ['bonferroni', 'benjamini_hochberg']:\n",
        "                correction_result = self.multiple_testing_correction(\n",
        "                    p_values_dict,\n",
        "                    correction_method=method,\n",
        "                    alpha=0.05\n",
        "                )\n",
        "                corrections[method] = correction_result\n",
        "\n",
        "        # Metric correlations (if Bayesian samples available)\n",
        "        correlations = {}\n",
        "        if len(metrics_list) > 1:\n",
        "            for i, metric1 in enumerate(metrics_list):\n",
        "                for metric2 in metrics_list[i+1:]:\n",
        "                    if (metric1 in detailed_results and 'bayesian' in detailed_results[metric1] and\n",
        "                        metric2 in detailed_results and 'bayesian' in detailed_results[metric2]):\n",
        "\n",
        "                        samples1 = detailed_results[metric1]['bayesian']['samples']['relative_improvement']\n",
        "                        samples2 = detailed_results[metric2]['bayesian']['samples']['relative_improvement']\n",
        "\n",
        "                        correlation = np.corrcoef(samples1, samples2)[0,1]\n",
        "                        correlations[f'{metric1}_vs_{metric2}'] = correlation\n",
        "\n",
        "        return {\n",
        "            'multiple_testing_corrections': corrections,\n",
        "            'metric_correlations': correlations,\n",
        "            'num_metrics_analyzed': len(metrics_list)\n",
        "        }\n",
        "\n",
        "    def _generate_executive_summary(self, comprehensive_results):\n",
        "        \"\"\"Generate executive summary of all analyses\"\"\"\n",
        "\n",
        "        summary = {\n",
        "            'dataset': comprehensive_results['dataset'],\n",
        "            'total_metrics': len(comprehensive_results['metrics']),\n",
        "            'analysis_timestamp': comprehensive_results['analysis_timestamp'],\n",
        "            'key_findings': [],\n",
        "            'recommendations': [],\n",
        "            'business_impact': {},\n",
        "            'statistical_confidence': 'High',\n",
        "            'next_steps': []\n",
        "        }\n",
        "\n",
        "        # Analyze each metric's results\n",
        "        significant_improvements = 0\n",
        "        significant_degradations = 0\n",
        "        inconclusive_results = 0\n",
        "\n",
        "        for metric, results in comprehensive_results['summary'].items():\n",
        "\n",
        "            # Determine significance and direction\n",
        "            if 'significant_frequentist' in results and results['significant_frequentist']:\n",
        "                if results['relative_change'] > 0:\n",
        "                    significant_improvements += 1\n",
        "                    summary['key_findings'].append(\n",
        "                        f\"✅ {metric}: Significant +{results['relative_change']:.1f}% improvement (p={results['p_value']:.4f})\"\n",
        "                    )\n",
        "                else:\n",
        "                    significant_degradations += 1\n",
        "                    summary['key_findings'].append(\n",
        "                        f\"❌ {metric}: Significant {results['relative_change']:.1f}% degradation (p={results['p_value']:.4f})\"\n",
        "                    )\n",
        "            else:\n",
        "                inconclusive_results += 1\n",
        "                summary['key_findings'].append(\n",
        "                    f\"⚪ {metric}: No significant effect detected ({results['relative_change']:+.1f}%)\"\n",
        "                )\n",
        "\n",
        "            # Add Bayesian insights if available\n",
        "            if 'prob_treatment_better' in results:\n",
        "                prob = results['prob_treatment_better']\n",
        "                if prob > 95:\n",
        "                    summary['key_findings'].append(\n",
        "                        f\"🔮 {metric}: {prob:.1f}% probability treatment is better (Bayesian)\"\n",
        "                    )\n",
        "\n",
        "        # Generate recommendations\n",
        "        if significant_improvements > 0:\n",
        "            summary['recommendations'].append(\n",
        "                f\"🚀 IMPLEMENT: {significant_improvements} metric(s) show significant improvement\"\n",
        "            )\n",
        "\n",
        "        if significant_degradations > 0:\n",
        "            summary['recommendations'].append(\n",
        "                f\"🛑 AVOID: {significant_degradations} metric(s) show significant degradation\"\n",
        "            )\n",
        "\n",
        "        if inconclusive_results > 0:\n",
        "            summary['recommendations'].append(\n",
        "                f\"🔍 INVESTIGATE: {inconclusive_results} metric(s) need more data or longer testing\"\n",
        "            )\n",
        "\n",
        "        # Multiple testing considerations\n",
        "        if 'multi_metric_analysis' in comprehensive_results:\n",
        "            multi_results = comprehensive_results['multi_metric_analysis']\n",
        "            if 'multiple_testing_corrections' in multi_results:\n",
        "                summary['next_steps'].append(\n",
        "                    \"📊 Consider multiple testing corrections when evaluating significance\"\n",
        "                )\n",
        "\n",
        "        # Business impact estimation\n",
        "        summary['business_impact'] = self._estimate_overall_business_impact(\n",
        "            comprehensive_results['dataset'], comprehensive_results['summary']\n",
        "        )\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def _estimate_overall_business_impact(self, dataset_name, metric_summaries):\n",
        "        \"\"\"Estimate overall business impact across all metrics\"\"\"\n",
        "\n",
        "        impact = {\n",
        "            'primary_metric_impact': 'TBD',\n",
        "            'confidence_level': 'Medium',\n",
        "            'risk_assessment': 'Low',\n",
        "            'implementation_priority': 'Medium'\n",
        "        }\n",
        "\n",
        "        # Find primary metric (first one with significant positive effect)\n",
        "        primary_metric = None\n",
        "        for metric, summary in metric_summaries.items():\n",
        "            if (summary.get('significant_frequentist', False) and\n",
        "                summary.get('relative_change', 0) > 0):\n",
        "                primary_metric = metric\n",
        "                break\n",
        "\n",
        "        if primary_metric:\n",
        "            relative_change = metric_summaries[primary_metric]['relative_change']\n",
        "\n",
        "            if dataset_name == 'cookie_cats':\n",
        "                total_users = len(self.datasets['cookie_cats'])\n",
        "                baseline_rate = self._get_baseline_rate(dataset_name, primary_metric)\n",
        "                if baseline_rate:\n",
        "                    additional_users = total_users * baseline_rate * (relative_change / 100)\n",
        "                    impact['primary_metric_impact'] = f\"{additional_users:,.0f} additional retained users\"\n",
        "                    impact['estimated_revenue'] = f\"${additional_users * 5:,.0f} (at $5/user)\"\n",
        "\n",
        "            # Set implementation priority\n",
        "            if relative_change > 10:\n",
        "                impact['implementation_priority'] = 'High'\n",
        "            elif relative_change > 5:\n",
        "                impact['implementation_priority'] = 'Medium'\n",
        "            else:\n",
        "                impact['implementation_priority'] = 'Low'\n",
        "\n",
        "        return impact\n",
        "\n",
        "    def _display_executive_summary(self, summary):\n",
        "        \"\"\"Display the executive summary in a formatted way\"\"\"\n",
        "\n",
        "        print(f\"📊 Dataset: {summary['dataset']}\")\n",
        "        print(f\"📈 Metrics Analyzed: {summary['total_metrics']}\")\n",
        "        print(f\"🔍 Statistical Confidence: {summary['statistical_confidence']}\")\n",
        "\n",
        "        print(f\"\\n🎯 KEY FINDINGS:\")\n",
        "        for finding in summary['key_findings']:\n",
        "            print(f\"   {finding}\")\n",
        "\n",
        "        print(f\"\\n📋 RECOMMENDATIONS:\")\n",
        "        for rec in summary['recommendations']:\n",
        "            print(f\"   {rec}\")\n",
        "\n",
        "        if summary['business_impact']:\n",
        "            print(f\"\\n💼 BUSINESS IMPACT:\")\n",
        "            for key, value in summary['business_impact'].items():\n",
        "                print(f\"   {key.replace('_', ' ').title()}: {value}\")\n",
        "\n",
        "        if summary['next_steps']:\n",
        "            print(f\"\\n📌 NEXT STEPS:\")\n",
        "            for step in summary['next_steps']:\n",
        "                print(f\"   {step}\")\n",
        "\n",
        "    def generate_ab_test_report(self, comprehensive_results, include_technical_details=False):\n",
        "        \"\"\"Generate a complete A/B test report\"\"\"\n",
        "\n",
        "        print(\"📋 GENERATING A/B TEST REPORT\")\n",
        "        print(\"=\" * 40)\n",
        "\n",
        "        report = {\n",
        "            'title': f\"A/B Test Analysis Report - {comprehensive_results['dataset']}\",\n",
        "            'executive_summary': comprehensive_results['executive_summary'],\n",
        "            'methodology': self._generate_methodology_section(),\n",
        "            'results_by_metric': {},\n",
        "            'conclusions': self._generate_conclusions(comprehensive_results),\n",
        "            'technical_appendix': {} if include_technical_details else None\n",
        "        }\n",
        "\n",
        "        # Generate results section for each metric\n",
        "        for metric, results in comprehensive_results['detailed_results'].items():\n",
        "            report['results_by_metric'][metric] = self._format_metric_results(metric, results)\n",
        "\n",
        "        # Technical appendix\n",
        "        if include_technical_details:\n",
        "            report['technical_appendix'] = {\n",
        "                'statistical_methods': self._generate_methods_description(),\n",
        "                'assumptions_and_limitations': self._generate_limitations(),\n",
        "                'raw_data_summary': comprehensive_results['summary']\n",
        "            }\n",
        "\n",
        "        return report\n",
        "\n",
        "    def _generate_methodology_section(self):\n",
        "        \"\"\"Generate methodology section for the report\"\"\"\n",
        "\n",
        "        return {\n",
        "            'test_type': 'A/B Test (Randomized Controlled Experiment)',\n",
        "            'statistical_methods': [\n",
        "                'Two-proportion z-test (Frequentist)',\n",
        "                'Bayesian Beta-Binomial analysis',\n",
        "                'Sequential testing with O\\'Brien-Fleming boundaries',\n",
        "                'Multiple testing corrections (Benjamini-Hochberg)'\n",
        "            ],\n",
        "            'significance_level': '5% (α = 0.05)',\n",
        "            'power': '80% (β = 0.20)',\n",
        "            'effect_size': 'Cohen\\'s h for proportion differences'\n",
        "        }\n",
        "\n",
        "    def _format_metric_results(self, metric, results):\n",
        "        \"\"\"Format results for a single metric\"\"\"\n",
        "\n",
        "        formatted = {\n",
        "            'metric_name': metric,\n",
        "            'summary': f\"Analysis of {metric} conversion rates between control and treatment groups\"\n",
        "        }\n",
        "\n",
        "        if 'descriptive_stats' in results:\n",
        "            desc = results['descriptive_stats']\n",
        "            formatted['descriptive_statistics'] = {\n",
        "                'control_conversion_rate': f\"{desc['control']['rate_pct']:.2f}%\",\n",
        "                'treatment_conversion_rate': f\"{desc['treatment']['rate_pct']:.2f}%\",\n",
        "                'absolute_difference': f\"{desc['difference']['absolute']*100:+.2f}%\",\n",
        "                'relative_improvement': f\"{desc['difference']['relative_pct']:+.1f}%\"\n",
        "            }\n",
        "\n",
        "        if 'frequentist' in results:\n",
        "            freq = results['frequentist']\n",
        "            formatted['statistical_test'] = {\n",
        "                'test_type': 'Two-proportion z-test',\n",
        "                'z_statistic': f\"{freq['z_statistic']:.3f}\",\n",
        "                'p_value': f\"{freq['p_value']:.4f}\",\n",
        "                'significant': 'Yes' if freq['significant'] else 'No',\n",
        "                'confidence_interval': f\"[{freq['confidence_interval']['lower']:+.2f}%, {freq['confidence_interval']['upper']:+.2f}%]\"\n",
        "            }\n",
        "\n",
        "        if 'bayesian' in results:\n",
        "            bayes = results['bayesian']\n",
        "            formatted['bayesian_analysis'] = {\n",
        "                'probability_treatment_better': f\"{bayes['probabilities']['treatment_better']:.1f}%\",\n",
        "                'recommendation': bayes['recommendation'],\n",
        "                'expected_loss_if_wrong': f\"{min(bayes['expected_loss']['if_choose_treatment'], bayes['expected_loss']['if_choose_control']):.3f}%\"\n",
        "            }\n",
        "\n",
        "        return formatted\n",
        "\n",
        "    def _generate_conclusions(self, comprehensive_results):\n",
        "        \"\"\"Generate conclusions section\"\"\"\n",
        "\n",
        "        conclusions = {\n",
        "            'primary_conclusion': '',\n",
        "            'secondary_findings': [],\n",
        "            'business_recommendation': '',\n",
        "            'confidence_level': 'Medium'\n",
        "        }\n",
        "\n",
        "        # Determine primary conclusion based on most important metric\n",
        "        summary = comprehensive_results['executive_summary']\n",
        "\n",
        "        if summary['key_findings']:\n",
        "            first_finding = summary['key_findings'][0]\n",
        "            if '✅' in first_finding:\n",
        "                conclusions['primary_conclusion'] = \"Treatment variant shows statistically significant improvement\"\n",
        "                conclusions['business_recommendation'] = \"Implement the treatment variant\"\n",
        "                conclusions['confidence_level'] = 'High'\n",
        "            elif '❌' in first_finding:\n",
        "                conclusions['primary_conclusion'] = \"Treatment variant shows statistically significant degradation\"\n",
        "                conclusions['business_recommendation'] = \"Keep the control variant\"\n",
        "                conclusions['confidence_level'] = 'High'\n",
        "            else:\n",
        "                conclusions['primary_conclusion'] = \"No statistically significant difference detected\"\n",
        "                conclusions['business_recommendation'] = \"Consider longer test duration or larger sample size\"\n",
        "                conclusions['confidence_level'] = 'Low'\n",
        "\n",
        "        # Add secondary findings\n",
        "        if len(summary['key_findings']) > 1:\n",
        "            conclusions['secondary_findings'] = summary['key_findings'][1:]\n",
        "\n",
        "        return conclusions\n",
        "\n",
        "    def _generate_methods_description(self):\n",
        "        \"\"\"Generate detailed methods description\"\"\"\n",
        "\n",
        "        return {\n",
        "            'frequentist_testing': \"Two-proportion z-test with Wald confidence intervals\",\n",
        "            'bayesian_analysis': \"Beta-Binomial conjugate priors with Monte Carlo simulation\",\n",
        "            'sequential_testing': \"Group sequential design with O'Brien-Fleming alpha spending\",\n",
        "            'multiple_comparisons': \"Benjamini-Hochberg false discovery rate control\",\n",
        "            'effect_size': \"Cohen's h for standardized difference between proportions\"\n",
        "        }\n",
        "\n",
        "    def _generate_limitations(self):\n",
        "        \"\"\"Generate limitations section\"\"\"\n",
        "\n",
        "        return [\n",
        "            \"Results assume random assignment and no systematic biases\",\n",
        "            \"Effect estimates are specific to the tested population and time period\",\n",
        "            \"Sequential testing boundaries are approximations for finite samples\",\n",
        "            \"Bayesian analysis uses uninformative priors\",\n",
        "            \"Multiple testing corrections may reduce statistical power\"\n",
        "        ]\n",
        "\n",
        "    # Add methods to the class\n",
        "    ab_tester_class.comprehensive_ab_analysis = comprehensive_ab_analysis\n",
        "    ab_tester_class._auto_detect_metrics = _auto_detect_metrics\n",
        "    ab_tester_class._analyze_single_metric = _analyze_single_metric\n",
        "    ab_tester_class._calculate_descriptive_stats = _calculate_descriptive_stats\n",
        "    ab_tester_class._run_frequentist_analysis = _run_frequentist_analysis\n",
        "    ab_tester_class._run_power_analysis = _run_power_analysis\n",
        "    ab_tester_class._run_sequential_simulation = _run_sequential_simulation\n",
        "    ab_tester_class._extract_metric_summary = _extract_metric_summary\n",
        "    ab_tester_class._multi_metric_analysis = _multi_metric_analysis\n",
        "    ab_tester_class._generate_executive_summary = _generate_executive_summary\n",
        "    ab_tester_class._estimate_overall_business_impact = _estimate_overall_business_impact\n",
        "    ab_tester_class._display_executive_summary = _display_executive_summary\n",
        "    ab_tester_class.generate_ab_test_report = generate_ab_test_report\n",
        "    ab_tester_class._generate_methodology_section = _generate_methodology_section\n",
        "    ab_tester_class._format_metric_results = _format_metric_results\n",
        "    ab_tester_class._generate_conclusions = _generate_conclusions\n",
        "    ab_tester_class._generate_methods_description = _generate_methods_description\n",
        "    ab_tester_class._generate_limitations = _generate_limitations\n",
        "\n",
        "# Master execution function\n",
        "def run_complete_ab_analysis(ab_tester, dataset_name='cookie_cats'):\n",
        "    \"\"\"Run the complete A/B testing analysis pipeline on your real data\"\"\"\n",
        "\n",
        "    print(\"🚀 COMPLETE A/B TESTING ANALYSIS PIPELINE\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"🎯 Using Your Real Datasets for Professional-Grade Analysis\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Add all methods from previous chunks\n",
        "    add_comprehensive_analysis_methods(ab_tester.__class__)\n",
        "\n",
        "    # Run comprehensive analysis\n",
        "    print(f\"\\n1️⃣ RUNNING COMPREHENSIVE ANALYSIS ON {dataset_name.upper()}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    comprehensive_results = ab_tester.comprehensive_ab_analysis(\n",
        "        dataset_name=dataset_name,\n",
        "        analysis_type='full',\n",
        "        confidence_level=0.95\n",
        "    )\n",
        "\n",
        "    if not comprehensive_results:\n",
        "        print(\"❌ Analysis failed\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\n2️⃣ GENERATING PROFESSIONAL REPORT\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Generate detailed report\n",
        "    report = ab_tester.generate_ab_test_report(\n",
        "        comprehensive_results,\n",
        "        include_technical_details=True\n",
        "    )\n",
        "\n",
        "    print(f\"\\n3️⃣ BUSINESS IMPACT SUMMARY\")\n",
        "    print(\"=\" * 35)\n",
        "\n",
        "    business_impact = comprehensive_results['executive_summary']['business_impact']\n",
        "    for key, value in business_impact.items():\n",
        "        print(f\"   {key.replace('_', ' ').title()}: {value}\")\n",
        "\n",
        "    print(f\"\\n🎉 ANALYSIS COMPLETE!\")\n",
        "    print(\"=\" * 25)\n",
        "    print(\"✅ Frequentist statistical testing\")\n",
        "    print(\"✅ Bayesian probability analysis\")\n",
        "    print(\"✅ Sequential testing simulation\")\n",
        "    print(\"✅ Power analysis & sample size calculation\")\n",
        "    print(\"✅ Multiple testing corrections\")\n",
        "    print(\"✅ Business impact estimation\")\n",
        "    print(\"✅ Professional reporting\")\n",
        "\n",
        "    return {\n",
        "        'comprehensive_results': comprehensive_results,\n",
        "        'report': report,\n",
        "        'dataset_analyzed': dataset_name\n",
        "    }\n",
        "\n",
        "# Quick analysis function for demos\n",
        "def quick_ab_analysis(ab_tester, dataset_name='cookie_cats'):\n",
        "    \"\"\"Run a quick A/B analysis for demos and presentations\"\"\"\n",
        "\n",
        "    print(\"⚡ QUICK A/B TESTING ANALYSIS\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Add methods\n",
        "    add_comprehensive_analysis_methods(ab_tester.__class__)\n",
        "\n",
        "    # Run quick analysis\n",
        "    results = ab_tester.comprehensive_ab_analysis(\n",
        "        dataset_name=dataset_name,\n",
        "        analysis_type='quick',\n",
        "        confidence_level=0.95\n",
        "    )\n",
        "\n",
        "    if results:\n",
        "        print(f\"\\n🎯 QUICK INSIGHTS:\")\n",
        "        for metric, summary in results['summary'].items():\n",
        "            print(f\"   📊 {metric}: {summary['relative_change']:+.1f}% change\")\n",
        "            if 'p_value' in summary:\n",
        "                sig = \"✅ Significant\" if summary['p_value'] < 0.05 else \"❌ Not significant\"\n",
        "                print(f\"      Statistical: {sig} (p={summary['p_value']:.4f})\")\n",
        "\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"🎯 ENHANCED A/B TESTING FRAMEWORK - CHUNK 6\")\n",
        "    print(\"Real Data Integration & Comprehensive Analysis\")\n",
        "    print(\"\\nUsage:\")\n",
        "    print(\"# Run complete analysis on your Cookie Cats data:\")\n",
        "    print(\"complete_results = run_complete_ab_analysis(ab_tester, 'cookie_cats')\")\n",
        "    print(\"# Or quick analysis for demos:\")\n",
        "    print(\"quick_results = quick_ab_analysis(ab_tester, 'cookie_cats')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCfqqVCujKqM",
        "outputId": "4bba3498-c14f-477b-bfa5-b8f2ac994d37"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 ENHANCED A/B TESTING FRAMEWORK - CHUNK 6\n",
            "Real Data Integration & Comprehensive Analysis\n",
            "\n",
            "Usage:\n",
            "# Run complete analysis on your Cookie Cats data:\n",
            "complete_results = run_complete_ab_analysis(ab_tester, 'cookie_cats')\n",
            "# Or quick analysis for demos:\n",
            "quick_results = quick_ab_analysis(ab_tester, 'cookie_cats')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "complete_results = run_complete_ab_analysis(ab_tester, 'cookie_cats')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enRWqnx2ked0",
        "outputId": "c73415b8-507f-44b8-bc4e-3c069e14ebaf"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 COMPLETE A/B TESTING ANALYSIS PIPELINE\n",
            "======================================================================\n",
            "🎯 Using Your Real Datasets for Professional-Grade Analysis\n",
            "======================================================================\n",
            "\n",
            "1️⃣ RUNNING COMPREHENSIVE ANALYSIS ON COOKIE_CATS\n",
            "============================================================\n",
            "🚀 COMPREHENSIVE A/B TESTING ANALYSIS\n",
            "============================================================\n",
            "🎯 Dataset: COOKIE_CATS\n",
            "📊 Analysis Type: FULL\n",
            "🔍 Confidence Level: 95%\n",
            "============================================================\n",
            "📈 Metrics to Analyze: retention_1, retention_7\n",
            "------------------------------------------------------------\n",
            "\n",
            "📊 ANALYZING METRIC 1/2: RETENTION_1\n",
            "==================================================\n",
            "🔮 BAYESIAN A/B TEST ANALYSIS\n",
            "=============================================\n",
            "Dataset: cookie_cats | Metric: retention_1\n",
            "📊 DATA SUMMARY:\n",
            "   Control: 20034/44700 conversions (44.82%)\n",
            "   Treatment: 20119/45489 conversions (44.23%)\n",
            "\n",
            "🎯 POSTERIOR ESTIMATES:\n",
            "   Control Rate: 44.82%\n",
            "   Treatment Rate: 44.23%\n",
            "   Relative Improvement: -1.3%\n",
            "\n",
            "📈 PROBABILITY ANALYSIS:\n",
            "   Probability Treatment is Better: 3.7%\n",
            "   Probability Control is Better: 96.3%\n",
            "   Probability of Practical Significance: 0.0%\n",
            "\n",
            "💰 EXPECTED LOSS (Decision Theory):\n",
            "   Loss if Choose Treatment: 0.596%\n",
            "   Loss if Choose Control: 0.005%\n",
            "\n",
            "📊 95% CREDIBLE INTERVAL (Relative Improvement):\n",
            "   Lower Bound: -2.8%\n",
            "   Upper Bound: +0.1%\n",
            "\n",
            "⚠️ RISK ASSESSMENT:\n",
            "   Risk of Negative Effect: 96.3%\n",
            "   Probability of Small Effect (<1%): 33.1%\n",
            "   Probability of Medium Effect (1-10%): 0.1%\n",
            "   Probability of Large Effect (>10%): 0.0%\n",
            "   Value at Risk (5%): -2.5%\n",
            "   Value at Risk (1%): -3.0%\n",
            "\n",
            "🎯 BAYESIAN RECOMMENDATION: 🔴 RECOMMENDATION: Keep Control (Treatment Likely Harmful)\n",
            "\n",
            "💼 BUSINESS IMPACT ESTIMATION:\n",
            "   Expected Additional Users: -533\n",
            "   95% CI Additional Users: [-533, -533]\n",
            "   Expected Revenue Impact: $-2,663\n",
            "   95% CI Revenue Impact: [$-2,663, $-2,663]\n",
            "   Probability of Positive ROI: 0.0%\n",
            "✅ Analysis complete for retention_1\n",
            "\n",
            "📊 ANALYZING METRIC 2/2: RETENTION_7\n",
            "==================================================\n",
            "🔮 BAYESIAN A/B TEST ANALYSIS\n",
            "=============================================\n",
            "Dataset: cookie_cats | Metric: retention_7\n",
            "📊 DATA SUMMARY:\n",
            "   Control: 8502/44700 conversions (19.02%)\n",
            "   Treatment: 8279/45489 conversions (18.20%)\n",
            "\n",
            "🎯 POSTERIOR ESTIMATES:\n",
            "   Control Rate: 19.02%\n",
            "   Treatment Rate: 18.20%\n",
            "   Relative Improvement: -4.3%\n",
            "\n",
            "📈 PROBABILITY ANALYSIS:\n",
            "   Probability Treatment is Better: 0.1%\n",
            "   Probability Control is Better: 99.9%\n",
            "   Probability of Practical Significance: 0.0%\n",
            "\n",
            "💰 EXPECTED LOSS (Decision Theory):\n",
            "   Loss if Choose Treatment: 0.821%\n",
            "   Loss if Choose Control: 0.000%\n",
            "\n",
            "📊 95% CREDIBLE INTERVAL (Relative Improvement):\n",
            "   Lower Bound: -6.9%\n",
            "   Upper Bound: -1.6%\n",
            "\n",
            "⚠️ RISK ASSESSMENT:\n",
            "   Risk of Negative Effect: 99.9%\n",
            "   Probability of Small Effect (<1%): 0.8%\n",
            "   Probability of Medium Effect (1-10%): 0.0%\n",
            "   Probability of Large Effect (>10%): 0.0%\n",
            "   Value at Risk (5%): -6.5%\n",
            "   Value at Risk (1%): -7.4%\n",
            "\n",
            "🎯 BAYESIAN RECOMMENDATION: 🔴 RECOMMENDATION: Keep Control (Treatment Likely Harmful)\n",
            "\n",
            "💼 BUSINESS IMPACT ESTIMATION:\n",
            "   Expected Additional Users: -740\n",
            "   95% CI Additional Users: [-740, -740]\n",
            "   Expected Revenue Impact: $-3,698\n",
            "   95% CI Revenue Impact: [$-3,698, $-3,698]\n",
            "   Probability of Positive ROI: 0.0%\n",
            "✅ Analysis complete for retention_7\n",
            "\n",
            "🔄 MULTI-METRIC ANALYSIS\n",
            "==============================\n",
            "🔄 Running multi-metric correlation analysis...\n",
            "🔬 MULTIPLE TESTING CORRECTION ANALYSIS\n",
            "==================================================\n",
            "Correction Method: Bonferroni\n",
            "Alpha Level: 0.05\n",
            "📊 ANALYSIS SUMMARY:\n",
            "   Number of Tests: 2\n",
            "   Original P-values: ['0.0744', '0.0016']\n",
            "\n",
            "📈 CORRECTION RESULTS:\n",
            "   Corrected Alpha: 0.025000\n",
            "   Significant Tests (Original): 1/2\n",
            "   Significant Tests (Corrected): 1/2\n",
            "   Expected False Discoveries: 0.05\n",
            "   Power Loss: 0.0%\n",
            "\n",
            "📋 DETAILED RESULTS:\n",
            "   retention_1:\n",
            "     Original: p=0.0744 ❌\n",
            "     Corrected: p=0.1488 ❌\n",
            "   retention_7:\n",
            "     Original: p=0.0016 ✅\n",
            "     Corrected: p=0.0031 ✅\n",
            "🔬 MULTIPLE TESTING CORRECTION ANALYSIS\n",
            "==================================================\n",
            "Correction Method: Benjamini Hochberg\n",
            "Alpha Level: 0.05\n",
            "📊 ANALYSIS SUMMARY:\n",
            "   Number of Tests: 2\n",
            "   Original P-values: ['0.0744', '0.0016']\n",
            "\n",
            "📈 CORRECTION RESULTS:\n",
            "   FDR Level: 0.05\n",
            "   Significant Tests (Original): 1/2\n",
            "   Significant Tests (Corrected): 1/2\n",
            "   Expected False Discoveries: 0.05\n",
            "   Power Loss: 0.0%\n",
            "\n",
            "📋 DETAILED RESULTS:\n",
            "   retention_1:\n",
            "     Original: p=0.0744 ❌\n",
            "     Corrected: p=0.0744 ❌\n",
            "   retention_7:\n",
            "     Original: p=0.0016 ✅\n",
            "     Corrected: p=0.0031 ✅\n",
            "\n",
            "📋 EXECUTIVE SUMMARY\n",
            "=========================\n",
            "📊 Dataset: cookie_cats\n",
            "📈 Metrics Analyzed: 2\n",
            "🔍 Statistical Confidence: High\n",
            "\n",
            "🎯 KEY FINDINGS:\n",
            "   ⚪ retention_1: No significant effect detected (-1.3%)\n",
            "   ❌ retention_7: Significant -4.3% degradation (p=0.0016)\n",
            "\n",
            "📋 RECOMMENDATIONS:\n",
            "   🛑 AVOID: 1 metric(s) show significant degradation\n",
            "   🔍 INVESTIGATE: 1 metric(s) need more data or longer testing\n",
            "\n",
            "💼 BUSINESS IMPACT:\n",
            "   Primary Metric Impact: TBD\n",
            "   Confidence Level: Medium\n",
            "   Risk Assessment: Low\n",
            "   Implementation Priority: Medium\n",
            "\n",
            "📌 NEXT STEPS:\n",
            "   📊 Consider multiple testing corrections when evaluating significance\n",
            "\n",
            "2️⃣ GENERATING PROFESSIONAL REPORT\n",
            "========================================\n",
            "📋 GENERATING A/B TEST REPORT\n",
            "========================================\n",
            "\n",
            "3️⃣ BUSINESS IMPACT SUMMARY\n",
            "===================================\n",
            "   Primary Metric Impact: TBD\n",
            "   Confidence Level: Medium\n",
            "   Risk Assessment: Low\n",
            "   Implementation Priority: Medium\n",
            "\n",
            "🎉 ANALYSIS COMPLETE!\n",
            "=========================\n",
            "✅ Frequentist statistical testing\n",
            "✅ Bayesian probability analysis\n",
            "✅ Sequential testing simulation\n",
            "✅ Power analysis & sample size calculation\n",
            "✅ Multiple testing corrections\n",
            "✅ Business impact estimation\n",
            "✅ Professional reporting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quick_results = quick_ab_analysis(ab_tester, 'cookie_cats')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj3Kb9dpkehM",
        "outputId": "be43f979-31aa-47f9-87d3-f77560110260"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚡ QUICK A/B TESTING ANALYSIS\n",
            "========================================\n",
            "🚀 COMPREHENSIVE A/B TESTING ANALYSIS\n",
            "============================================================\n",
            "🎯 Dataset: COOKIE_CATS\n",
            "📊 Analysis Type: QUICK\n",
            "🔍 Confidence Level: 95%\n",
            "============================================================\n",
            "📈 Metrics to Analyze: retention_1, retention_7\n",
            "------------------------------------------------------------\n",
            "\n",
            "📊 ANALYZING METRIC 1/2: RETENTION_1\n",
            "==================================================\n",
            "✅ Analysis complete for retention_1\n",
            "\n",
            "📊 ANALYZING METRIC 2/2: RETENTION_7\n",
            "==================================================\n",
            "✅ Analysis complete for retention_7\n",
            "\n",
            "🔄 MULTI-METRIC ANALYSIS\n",
            "==============================\n",
            "🔄 Running multi-metric correlation analysis...\n",
            "🔬 MULTIPLE TESTING CORRECTION ANALYSIS\n",
            "==================================================\n",
            "Correction Method: Bonferroni\n",
            "Alpha Level: 0.05\n",
            "📊 ANALYSIS SUMMARY:\n",
            "   Number of Tests: 2\n",
            "   Original P-values: ['0.0744', '0.0016']\n",
            "\n",
            "📈 CORRECTION RESULTS:\n",
            "   Corrected Alpha: 0.025000\n",
            "   Significant Tests (Original): 1/2\n",
            "   Significant Tests (Corrected): 1/2\n",
            "   Expected False Discoveries: 0.05\n",
            "   Power Loss: 0.0%\n",
            "\n",
            "📋 DETAILED RESULTS:\n",
            "   retention_1:\n",
            "     Original: p=0.0744 ❌\n",
            "     Corrected: p=0.1488 ❌\n",
            "   retention_7:\n",
            "     Original: p=0.0016 ✅\n",
            "     Corrected: p=0.0031 ✅\n",
            "🔬 MULTIPLE TESTING CORRECTION ANALYSIS\n",
            "==================================================\n",
            "Correction Method: Benjamini Hochberg\n",
            "Alpha Level: 0.05\n",
            "📊 ANALYSIS SUMMARY:\n",
            "   Number of Tests: 2\n",
            "   Original P-values: ['0.0744', '0.0016']\n",
            "\n",
            "📈 CORRECTION RESULTS:\n",
            "   FDR Level: 0.05\n",
            "   Significant Tests (Original): 1/2\n",
            "   Significant Tests (Corrected): 1/2\n",
            "   Expected False Discoveries: 0.05\n",
            "   Power Loss: 0.0%\n",
            "\n",
            "📋 DETAILED RESULTS:\n",
            "   retention_1:\n",
            "     Original: p=0.0744 ❌\n",
            "     Corrected: p=0.0744 ❌\n",
            "   retention_7:\n",
            "     Original: p=0.0016 ✅\n",
            "     Corrected: p=0.0031 ✅\n",
            "\n",
            "📋 EXECUTIVE SUMMARY\n",
            "=========================\n",
            "📊 Dataset: cookie_cats\n",
            "📈 Metrics Analyzed: 2\n",
            "🔍 Statistical Confidence: High\n",
            "\n",
            "🎯 KEY FINDINGS:\n",
            "   ⚪ retention_1: No significant effect detected (-1.3%)\n",
            "   ❌ retention_7: Significant -4.3% degradation (p=0.0016)\n",
            "\n",
            "📋 RECOMMENDATIONS:\n",
            "   🛑 AVOID: 1 metric(s) show significant degradation\n",
            "   🔍 INVESTIGATE: 1 metric(s) need more data or longer testing\n",
            "\n",
            "💼 BUSINESS IMPACT:\n",
            "   Primary Metric Impact: TBD\n",
            "   Confidence Level: Medium\n",
            "   Risk Assessment: Low\n",
            "   Implementation Priority: Medium\n",
            "\n",
            "📌 NEXT STEPS:\n",
            "   📊 Consider multiple testing corrections when evaluating significance\n",
            "\n",
            "🎯 QUICK INSIGHTS:\n",
            "   📊 retention_1: -1.3% change\n",
            "      Statistical: ❌ Not significant (p=0.0744)\n",
            "   📊 retention_7: -4.3% change\n",
            "      Statistical: ✅ Significant (p=0.0016)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3AJAHOnik_Mv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}